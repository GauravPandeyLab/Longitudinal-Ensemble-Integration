{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susmaa01/Documents/eipy/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, f1_score, fbeta_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import eipy.ei as e\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, Callback\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense, Bidirectional, GRU, Dropout, LayerNormalization, BatchNormalization, SimpleRNN\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorboard import notebook\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import inspect\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import longitudinal_tadpole.pipeline as p\n",
    "from eipy.multiclass_metrics import alt_nested_threshold_fmax\n",
    "from eipy.multiclass_metrics import decide_with_thresholds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "import longitudinal_tadpole.pipeline as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "with open(f\"/Users/susmaa01/Documents/eipy/longitudinal_tadpole/tadpole_data/tadpole_data_time_imptn_norm_thrshld30.pickle\", \"rb\") as file:\n",
    "    data_nested_dict = pkl.load(file)\n",
    "with open(f\"/Users/susmaa01/Documents/eipy/longitudinal_tadpole/tadpole_data/tadpole_labels_time_imptn_norm_thrshld30.pickle\", \"rb\") as file:\n",
    "    labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = []\n",
    "for i in range(5):\n",
    "    with open(f\"/Users/susmaa01/Documents/eipy/longitudinal_tadpole/base_predictions/multiclass/data_at_n_w_labels_at_n/no_sampling/split_{i}.pkl\", \"rb\") as file:\n",
    "        split = pkl.load(file)\n",
    "        bps.append(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SERIES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(y):\n",
    "    labels_across_time = np.eye(3)[y]\n",
    "\n",
    "    return labels_across_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights_for_t(training_labels):\n",
    "    class_weights_for_labels = []\n",
    "    for t in range(training_labels.shape[1]):\n",
    "        bin_counts_per_t = 1 / np.bincount(training_labels[:,t])\n",
    "        norm_bin_counts_per_t = bin_counts_per_t/np.sum(bin_counts_per_t)\n",
    "        class_weights_t = dict(zip(range(3), norm_bin_counts_per_t))\n",
    "        class_weights_for_labels.append(class_weights_t)\n",
    "    return class_weights_for_labels\n",
    "    # mapped_array = [np.array([class_weights_for_labels[t][entry] for entry in training_labels[:,t]]) for t in range(training_labels.shape[1])]\n",
    "    # mapped_array = np.stack(mapped_array, axis=1)\n",
    "    # return tf.constant(mapped_array, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinal categorical crossentropy. Weighs error by how many classes output was off by. weights range from 1 to 2. assigns class weights across time.\n",
    "# https://stats.stackexchange.com/questions/87826/machine-learning-with-ordered-labels\n",
    "#gamma = d(MCI,CN) - d(MCI,Dementia) = d(MCI,CN) - 1\n",
    "\n",
    "def occ_loss(gamma=0):\n",
    "    global class_weights\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_ord = tf.argmax(y_true, axis=-1)\n",
    "        y_pred_ord = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "        losses_over_time = []\n",
    "        for t in range(y_true.shape[1]):\n",
    "            y_true_ord_t = y_true_ord[:,t]\n",
    "            \n",
    "            class_weights_t = class_weights[t]\n",
    "            w_c_t = tf.gather(tf.constant(list(class_weights_t.values()), dtype=tf.float32),\n",
    "                                y_true_ord_t)\n",
    "\n",
    "            if gamma=='none':\n",
    "                loss = tf.keras.losses.categorical_crossentropy(y_true[:,t], y_pred[:,t]) * w_c_t\n",
    "            else:\n",
    "                y_true_ord_gamma = y_true_ord_t + tf.cast(y_true_ord_t != 0, tf.int64) * gamma\n",
    "                y_pred_ord_gamma = y_pred_ord[:,t] + tf.cast(y_pred_ord[:,t] != 0, tf.int64) * gamma\n",
    "                w_o_t = tf.cast(tf.abs(y_true_ord_gamma - y_pred_ord_gamma) / (2 + gamma), dtype='float32') + 1\n",
    "    \n",
    "                loss = tf.keras.losses.categorical_crossentropy(y_true[:,t], y_pred[:,t]) * w_o_t * w_c_t\n",
    "\n",
    "            losses_over_time.append(loss)\n",
    "        return tf.reduce_mean(tf.stack(losses_over_time, axis=-1), axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell represents the RNN cell will be used {'GRU', 'biGRU', 'LSTM', 'biLSTM'}\n",
    "# drout represents the drop out rate will be used {0, 0.1, 0.2, 0.3, 0.4, 0.5}\n",
    "# L2 represents the L2 regularization {0.1, 0.001, 0.00001, 0.0000001}\n",
    "\n",
    "def build_RNN(units, cell, drout, L2, deep=True, reg_layer='batchnorm', activation='relu', gamma=0):\n",
    "    model = Sequential()\n",
    "    \n",
    "    params_dict_1 = {'units': units,\n",
    "                     'activity_regularizer': l2(L2),\n",
    "                     'dropout': drout,\n",
    "                     'recurrent_dropout': drout,\n",
    "                     'return_sequences': True}\n",
    "    params_dict_2 = {'units': units // 2,\n",
    "                     'activity_regularizer': l2(L2),\n",
    "                     'dropout': drout,\n",
    "                     'recurrent_dropout': drout,\n",
    "                     'return_sequences': True}\n",
    "    \n",
    "\n",
    "    if cell =='RNN':\n",
    "        model.add(SimpleRNN(**params_dict_1))\n",
    "    elif cell == 'biGRU':\n",
    "        model.add(Bidirectional(GRU(**params_dict_1)))\n",
    "    elif cell == 'biLSTM':\n",
    "        model.add(Bidirectional(LSTM(**params_dict_1)))\n",
    "    elif cell == 'GRU':\n",
    "        model.add(GRU(**params_dict_1))\n",
    "    elif cell == 'LSTM':\n",
    "        model.add(LSTM(**params_dict_1))\n",
    "    \n",
    "    \n",
    "    if deep:\n",
    "        model.add(Dropout(drout))\n",
    "        if reg_layer==\"batchnorm\":\n",
    "            model.add(BatchNormalization())\n",
    "        \n",
    "        if cell == 'RNN':\n",
    "            model.add(SimpleRNN(**params_dict_2))\n",
    "        if cell == 'biGRU':\n",
    "            model.add(Bidirectional(GRU(**params_dict_2)))\n",
    "        elif cell == 'biLSTM':\n",
    "            model.add(Bidirectional(LSTM(**params_dict_2)))\n",
    "        elif cell == 'GRU':\n",
    "            model.add(GRU(**params_dict_2))\n",
    "        elif cell == 'LSTM':\n",
    "            model.add(LSTM(**params_dict_2))\n",
    "        \n",
    "    # model.add(Dropout(drout))\n",
    "    # if reg_layer==\"batchnorm\":\n",
    "    #     model.add(BatchNormalization())\n",
    "    \n",
    "    # MLP Classification model    \n",
    "    model.add(Dense(units // 2 , activation=activation))\n",
    "    model.add(Dropout(drout))\n",
    "    if reg_layer==\"batchnorm\":\n",
    "        model.add(BatchNormalization())        \n",
    "    \n",
    "    model.add(Dense(units // 4  , activation=activation))\n",
    "    model.add(Dropout(drout))\n",
    "    if reg_layer==\"batchnorm\":\n",
    "        model.add(BatchNormalization())\n",
    "    #to force overfitting\n",
    "    # model.add(Dense(units // 8  , activation='relu'))\n",
    "    # model.add(Dense(units // 16  , activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss=occ_loss(gamma=gamma), optimizer='adam') # loss=occ_loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dem_prev(label_seq):\n",
    "    return [np.sum(y==2) for y in label_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thresh_argmax(y_pred, thresh):\n",
    "    if y_pred[1] > thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        if y_pred[0] > y_pred[2]:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresh(y_preds, y_trues, class_to_optimize='avg'):\n",
    "    y_decision_argmax = [np.argmax(y) for y in y_preds]\n",
    "    if class_to_optimize=='avg':\n",
    "        fmax = f1_score(y_trues, y_decision_argmax, average='macro')\n",
    "    else:\n",
    "        fmax = f1_score(y_trues, y_decision_argmax, average=None)[class_to_optimize]\n",
    "    tmax = 0\n",
    "    for t in np.unique(np.array(y_preds)[:,1]):\n",
    "        y_decision = [compute_thresh_argmax(y,thresh=t) for y in y_preds]\n",
    "        if class_to_optimize == 'avg':\n",
    "            f = f1_score(y_trues, y_decision, average='macro')\n",
    "        else:\n",
    "            f = f1_score(y_trues, y_decision, average=None)[class_to_optimize]\n",
    "        if f > fmax:\n",
    "            fmax = f\n",
    "            tmax = t\n",
    "    return tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X,y):\n",
    "    sampler = RandomOverSampler()\n",
    "    X_flat = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "    X_flat_y = np.concatenate([X_flat, y], axis=1)\n",
    "    \n",
    "    X_y_resampled, _ = sampler.fit_resample(X_flat_y, dem_prev(y))\n",
    "    \n",
    "    X_resampled = X_y_resampled[:,:-y.shape[1]]\n",
    "    X_resampled = X_resampled.reshape(X_resampled.shape[0], X.shape[1], X.shape[2])\n",
    "    \n",
    "    y_resampled = X_y_resampled[:,-y.shape[1]:].astype(int)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_data(dfs):\n",
    "    #reformat labels\n",
    "    labels_across_time = np.column_stack([df['labels'].values for df in dfs])\n",
    "    labels_across_time = np.eye(3)[labels_across_time]\n",
    "    \n",
    "    # reformat data\n",
    "    RNN_training_data_fold = [df.drop(columns=[\"labels\"], axis=1, level=0) for df in dfs]\n",
    "    data_arrays_per_timepoint = [df.to_numpy() for df in RNN_training_data_fold]\n",
    "    tensor_3d = np.stack(data_arrays_per_timepoint, axis=1)\n",
    "\n",
    "    return tensor_3d, labels_across_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_restandardize(data):\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    #for restandardizing bl class 2 columns to be all -1\n",
    "    means[means==0] = 1\n",
    "    stds[stds == 0] = 1\n",
    "\n",
    "    restandardized_data = (data-means)/stds\n",
    "\n",
    "    return restandardized_data, means, stds\n",
    "\n",
    "def restandardize(data, means, stds):\n",
    "\n",
    "    return (data-means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train lstms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use data up to time point n, \n",
    "#e.g., when n=3 means use data from t=0,1,2 and predict on label from t=3\n",
    "cell_list = [\"LSTM\"]##, \"GRU\"]#, 'RNN', \"biLSTM\", \"biGRU\"]\n",
    "def train_eval_RNNs(train, test, seed, cells=cell_list, decision='argmax', random_bl=False, sampling=None, gamma=0):\n",
    "    global f_scores_test\n",
    "    global p_scores_test\n",
    "    global r_scores_test\n",
    "    global y_test_predictions\n",
    "    # global f_scores_train\n",
    "    for cell in cells:\n",
    "        y_preds_test = []\n",
    "        y_tests = []\n",
    "        \n",
    "        y_preds_train = []\n",
    "        y_trains = []\n",
    "\n",
    "        y_preds_val = []\n",
    "        y_vals = []\n",
    "        \n",
    "        for fold, dfs in enumerate(train):\n",
    "            if random_bl==False:\n",
    "                real=\"Real\"\n",
    "            else:\n",
    "                real=\"Random\"\n",
    "            print(real, cell, \"seed\",seed+1, \"fold\", fold+1, \"gamma=\",gamma)\n",
    "            \n",
    "            X_train, y_train = reformat_data(dfs)\n",
    "            X_test, y_test = reformat_data(test[fold])\n",
    "\n",
    "\n",
    "            X_train, X_test = X_train[:, :-1, :], X_test[:, :-1, :] #data excluding last time point\n",
    "            y_train, y_test = y_train[:, 1:, :], y_test[:, 1:, :] #labels excluding baseline\n",
    "\n",
    "            #for removing bad timepoint\n",
    "            # X_train, X_test = X_train[:, :-1, :], X_test[:, :-1, :] #data excluding m24\n",
    "            # y_train, y_test = np.delete(y_train, -2, axis=1), np.delete(y_test, -2, axis=1)\n",
    "\n",
    "            #restandardize to have mean=0, std=1 (for tanh)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.09,\n",
    "                                                                stratify=dem_prev(y_train), random_state=seed**2)\n",
    "            X_train, means, stds = fit_restandardize(X_train)\n",
    "            X_test, X_val = restandardize(X_test, means=means, stds=stds), restandardize(X_val, means=means, stds=stds)\n",
    "            \n",
    "\n",
    "            \n",
    "            # duplicate any sample that has dementia in its label sequence\n",
    "            if sampling == 'oversampling':\n",
    "                dem_rows = np.where(np.any(y_train[:,:2] == 2, axis=1))[0]\n",
    "                X_dem, y_dem = X_train[dem_rows], y_train[dem_rows]\n",
    "\n",
    "                X_train = np.concatenate([X_train, X_dem], axis=0)\n",
    "                y_train = np.concatenate([y_train, y_dem], axis=0)\n",
    "            elif sampling == 'dem_prev':\n",
    "                X_train, y_train = resample(X_train, np.argmax(y_train, axis=-1))\n",
    "                y_train = ohe(y_train)\n",
    "            \n",
    "            y_trains.append(y_train)\n",
    "            y_tests.append(y_test)\n",
    "            y_vals.append(y_val)\n",
    "\n",
    "            \n",
    "            y_train_ord = np.argmax(y_train, axis=-1)\n",
    "            global class_weights\n",
    "            class_weights = [dict(zip(range(3), compute_class_weight(class_weight='balanced', classes=[0,1,2], y=y_train_ord[:,t]))) for t in range(y_train_ord.shape[1])]\n",
    "            # class_weights = get_class_weights_for_t(y_train_ord)\n",
    "            \n",
    "            model = build_RNN(units=64, cell=cell, drout=0.2, deep=True, L2=0.00,\n",
    "                               activation='tanh', reg_layer='batchnorm', gamma=gamma)\n",
    "            \n",
    "            early_stop = EarlyStopping(\n",
    "                monitor='val_loss', patience=30, verbose=1,\n",
    "                restore_best_weights=True, start_from_epoch=10)\n",
    "            \n",
    "            \n",
    "            if random_bl:\n",
    "                np.random.shuffle(y_train)\n",
    "                np.random.shuffle(y_val)\n",
    "\n",
    "            #fit model\n",
    "            model.fit(X_train, y_train, epochs=2000, validation_data=[X_val, y_val],\n",
    "                       verbose=1, callbacks=[early_stop])\n",
    "\n",
    "            y_preds_train.append(model.predict(X_train))\n",
    "            y_preds_test.append(model.predict(X_test))\n",
    "            y_preds_val.append(model.predict(X_val))\n",
    "        \n",
    "        y_pred_train = np.concatenate(y_preds_train, axis=0)\n",
    "        y_train = np.concatenate(y_trains, axis=0)\n",
    "\n",
    "        y_pred_test = np.concatenate(y_preds_test, axis=0)\n",
    "        y_test = np.concatenate(y_tests, axis=0)\n",
    "       \n",
    "        y_pred_val = np.concatenate(y_preds_val, axis=0)\n",
    "        y_val = np.concatenate(y_vals, axis=0)\n",
    "\n",
    "        if decision == \"argmax\": # for doing traditional decision making\n",
    "            y_test_ord = np.argmax(y_test, axis=-1)\n",
    "            f_scores_cell_seed_across_time_test = np.stack([f1_score(y_test_ord[:,i], np.array([np.argmax(y_hat) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "            p_scores_cell_seed_across_time_test = np.stack([precision_score(y_test_ord[:,i], np.array([np.argmax(y_hat) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "            r_scores_cell_seed_across_time_test = np.stack([recall_score(y_test_ord[:,i], np.array([np.argmax(y_hat) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "\n",
    "\n",
    "        elif decision == 'threshmax':\n",
    "            y_train_ord = np.argmax(y_train, axis=-1)\n",
    "            y_test_ord = np.argmax(y_test, axis=-1)\n",
    "            y_val_ord = np.argmax(y_val, axis=-1)\n",
    "            \n",
    "            y_not_test_ord = np.concatenate([y_train_ord, y_val_ord], axis=0)\n",
    "            y_pred_not_test = np.concatenate([y_pred_train, y_pred_val], axis=0)\n",
    "\n",
    "\n",
    "            thresholds = [find_thresh(y_trues=y_not_test_ord[:,i], y_preds=y_pred_not_test[:,i,:]) for i in range(y_not_test_ord.shape[1])]\n",
    "            f_scores_cell_seed_across_time_test = np.stack([f1_score(y_test_ord[:,i], np.array([compute_thresh_argmax(y_hat, thresholds[i]) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "            p_scores_cell_seed_across_time_test = np.stack([precision_score(y_test_ord[:,i], np.array([compute_thresh_argmax(y_hat, thresholds[i]) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "            r_scores_cell_seed_across_time_test = np.stack([recall_score(y_test_ord[:,i], np.array([compute_thresh_argmax(y_hat, thresholds[i]) for y_hat in y_pred_test[:,i,:]]), average=None) for i in range(y_test.shape[1])])\n",
    "        \n",
    "        f_scores_test[f'{real} {cell}'].append(f_scores_cell_seed_across_time_test)\n",
    "        p_scores_test[f'{real} {cell}'].append(p_scores_cell_seed_across_time_test)\n",
    "        r_scores_test[f'{real} {cell}'].append(r_scores_cell_seed_across_time_test)\n",
    "\n",
    "        y_test_predictions[f'{real} {cell}'].append(y_pred_test)\n",
    "            \n",
    "            # f_scores_cell_seed_across_time_train = np.stack([fbeta_score(y_train[:,i], np.array([np.argmax(y_hat) for y_hat in y_pred_train[:,i,:]]), average=None, beta=1) for i in range(y_train.shape[1])])\n",
    "            # f_scores_train[cell].append(f_scores_cell_seed_across_time_train)\n",
    "            \n",
    "            # y_pred_argmax = [np.argmax(y_hat) for y_hat in y_pred]\n",
    "            # f_scores[cell].append(f1_score(y_test, y_pred_argmax, average=None))\n",
    "\n",
    "        # else: # for deciding with nested fmax scheme\n",
    "        #     X_not_test = np.concatenate([X_train, X_val], axis=0)\n",
    "        #     y_not_test = np.concatenate([y_train, y_val], axis=0)\n",
    "        #     y_not_test = np.array([np.argmax(ohe_label, axis=-1) for ohe_label in y_not_test]) # convert back to ordinal\n",
    "        #     threshold_pair = alt_nested_threshold_fmax(y_not_test, model.predict(X_not_test))[1]\n",
    "        #     y_decision = decide_with_thresholds(y_pred=y_pred, t_pair=threshold_pair)\n",
    "        #     f_scores_test[cell].append([f1_score(y_test, y_decision, average=None), threshold_pair])\n",
    "        print(f_scores_test)\n",
    "        # print(f_scores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real LSTM seed 1 fold 1 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.3346 - val_loss: 1.4864\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9935 - val_loss: 1.4814\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8513 - val_loss: 1.4428\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7961 - val_loss: 1.4438\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8008 - val_loss: 1.4474\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6960 - val_loss: 1.4165\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7135 - val_loss: 1.4174\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6705 - val_loss: 1.4202\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6550 - val_loss: 1.4225\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6404 - val_loss: 1.4295\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6163 - val_loss: 1.4784\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6945 - val_loss: 1.4590\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5729 - val_loss: 1.4510\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5898 - val_loss: 1.4437\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5889 - val_loss: 1.4775\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6507 - val_loss: 1.5039\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5945 - val_loss: 1.5203\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5503 - val_loss: 1.5096\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6037 - val_loss: 1.4864\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5231 - val_loss: 1.4575\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5538 - val_loss: 1.4289\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5480 - val_loss: 1.4644\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5317 - val_loss: 1.4611\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4795 - val_loss: 1.4511\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5211 - val_loss: 1.4669\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5247 - val_loss: 1.4561\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4881 - val_loss: 1.4543\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4972 - val_loss: 1.4491\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4713 - val_loss: 1.4678\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4463 - val_loss: 1.5183\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4617 - val_loss: 1.5047\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4265 - val_loss: 1.5097\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4727 - val_loss: 1.4996\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4399 - val_loss: 1.4925\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4586 - val_loss: 1.4856\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4388 - val_loss: 1.4998\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4048 - val_loss: 1.4793\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5388 - val_loss: 1.4805\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4413 - val_loss: 1.5203\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5024 - val_loss: 1.5135\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4921 - val_loss: 1.4848\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4910 - val_loss: 1.4999\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4884 - val_loss: 1.5126\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4428 - val_loss: 1.5260\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4723 - val_loss: 1.5474\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4511 - val_loss: 1.5675\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4446 - val_loss: 1.5680\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4459 - val_loss: 1.5595\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3678 - val_loss: 1.5345\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3741 - val_loss: 1.5406\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3284 - val_loss: 1.5309\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 2 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.1627 - val_loss: 1.3711\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0271 - val_loss: 1.4501\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8530 - val_loss: 1.4663\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7992 - val_loss: 1.4486\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7639 - val_loss: 1.4513\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7537 - val_loss: 1.4214\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7508 - val_loss: 1.4399\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7592 - val_loss: 1.4407\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7452 - val_loss: 1.4273\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6477 - val_loss: 1.4253\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6896 - val_loss: 1.3948\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6786 - val_loss: 1.4128\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6339 - val_loss: 1.4623\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6779 - val_loss: 1.4767\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6564 - val_loss: 1.4633\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6402 - val_loss: 1.4261\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6244 - val_loss: 1.4199\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6416 - val_loss: 1.4962\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6266 - val_loss: 1.4724\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6386 - val_loss: 1.5020\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6147 - val_loss: 1.4897\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6026 - val_loss: 1.4842\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5277 - val_loss: 1.4388\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5938 - val_loss: 1.3913\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5701 - val_loss: 1.4198\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5684 - val_loss: 1.4018\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6129 - val_loss: 1.3588\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5485 - val_loss: 1.3540\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6157 - val_loss: 1.3774\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5543 - val_loss: 1.3668\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5047 - val_loss: 1.3626\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5532 - val_loss: 1.4130\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5113 - val_loss: 1.3960\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4928 - val_loss: 1.3663\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5191 - val_loss: 1.3766\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5052 - val_loss: 1.3965\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5143 - val_loss: 1.3713\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4882 - val_loss: 1.3864\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5287 - val_loss: 1.3787\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5211 - val_loss: 1.3689\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5052 - val_loss: 1.3694\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4502 - val_loss: 1.3487\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4491 - val_loss: 1.3486\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4455 - val_loss: 1.3608\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4826 - val_loss: 1.3777\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4908 - val_loss: 1.3774\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5214 - val_loss: 1.3582\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4120 - val_loss: 1.3434\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4819 - val_loss: 1.3581\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4331 - val_loss: 1.3501\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4498 - val_loss: 1.3409\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4237 - val_loss: 1.3698\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4290 - val_loss: 1.3684\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3843 - val_loss: 1.3674\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3496 - val_loss: 1.3638\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4267 - val_loss: 1.3777\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3572 - val_loss: 1.4027\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4158 - val_loss: 1.4316\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4737 - val_loss: 1.4398\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3808 - val_loss: 1.4136\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3516 - val_loss: 1.4220\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3281 - val_loss: 1.4211\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3263 - val_loss: 1.4077\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3471 - val_loss: 1.3705\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3864 - val_loss: 1.3745\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3774 - val_loss: 1.4055\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3348 - val_loss: 1.3827\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3146 - val_loss: 1.3707\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3252 - val_loss: 1.3699\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3306 - val_loss: 1.3831\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3559 - val_loss: 1.4026\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3049 - val_loss: 1.3989\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3434 - val_loss: 1.4206\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3171 - val_loss: 1.4066\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3300 - val_loss: 1.3994\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3213 - val_loss: 1.3690\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3938 - val_loss: 1.3886\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2708 - val_loss: 1.4168\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2792 - val_loss: 1.4391\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2971 - val_loss: 1.4940\n",
      "Epoch 81/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2554 - val_loss: 1.4402\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.4025 - val_loss: 1.3464\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9498 - val_loss: 1.2956\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7765 - val_loss: 1.3356\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9229 - val_loss: 1.3403\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8194 - val_loss: 1.3040\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7932 - val_loss: 1.3088\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7568 - val_loss: 1.3145\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6769 - val_loss: 1.3242\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6568 - val_loss: 1.3366\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7167 - val_loss: 1.3378\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7250 - val_loss: 1.3220\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5882 - val_loss: 1.3112\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6408 - val_loss: 1.3216\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5694 - val_loss: 1.3144\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6774 - val_loss: 1.3154\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6076 - val_loss: 1.3369\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5651 - val_loss: 1.4055\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6875 - val_loss: 1.4078\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5814 - val_loss: 1.4518\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5877 - val_loss: 1.4231\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5092 - val_loss: 1.3763\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5268 - val_loss: 1.3343\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5246 - val_loss: 1.3197\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5120 - val_loss: 1.3416\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4738 - val_loss: 1.3583\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5821 - val_loss: 1.3465\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5119 - val_loss: 1.3537\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4958 - val_loss: 1.3215\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5007 - val_loss: 1.3272\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4837 - val_loss: 1.3213\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4352 - val_loss: 1.3495\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4544 - val_loss: 1.3396\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4331 - val_loss: 1.3261\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4423 - val_loss: 1.3197\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4846 - val_loss: 1.3319\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4834 - val_loss: 1.3403\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4149 - val_loss: 1.3629\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4379 - val_loss: 1.3667\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4191 - val_loss: 1.3817\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3707 - val_loss: 1.3586\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4329 - val_loss: 1.3429\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3493 - val_loss: 1.3490\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.4102 - val_loss: 1.5059\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0687 - val_loss: 1.5105\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0057 - val_loss: 1.5526\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8672 - val_loss: 1.5584\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9013 - val_loss: 1.5497\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8826 - val_loss: 1.5298\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8851 - val_loss: 1.5097\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8275 - val_loss: 1.5229\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7533 - val_loss: 1.5079\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8294 - val_loss: 1.5107\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7261 - val_loss: 1.5049\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7746 - val_loss: 1.5160\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7724 - val_loss: 1.5227\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6714 - val_loss: 1.5705\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7929 - val_loss: 1.5192\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7406 - val_loss: 1.5314\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6603 - val_loss: 1.5255\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7917 - val_loss: 1.5005\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7259 - val_loss: 1.5203\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7576 - val_loss: 1.5166\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6838 - val_loss: 1.5167\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5880 - val_loss: 1.5348\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6091 - val_loss: 1.5335\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6104 - val_loss: 1.5491\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5787 - val_loss: 1.5589\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6023 - val_loss: 1.5469\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5155 - val_loss: 1.5097\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5862 - val_loss: 1.5025\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6543 - val_loss: 1.5186\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6421 - val_loss: 1.5195\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5701 - val_loss: 1.5405\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6320 - val_loss: 1.5256\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5655 - val_loss: 1.5087\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5747 - val_loss: 1.5148\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6084 - val_loss: 1.5122\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5016 - val_loss: 1.5168\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5945 - val_loss: 1.5071\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5604 - val_loss: 1.5302\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5046 - val_loss: 1.5398\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5615 - val_loss: 1.5641\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3946 - val_loss: 1.5760\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5924 - val_loss: 1.5721\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5518 - val_loss: 1.5637\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5081 - val_loss: 1.5505\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5303 - val_loss: 1.5826\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5462 - val_loss: 1.5763\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5348 - val_loss: 1.5749\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6105 - val_loss: 1.5776\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= 0\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.3451 - val_loss: 1.4430\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8774 - val_loss: 1.4174\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9595 - val_loss: 1.4278\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7553 - val_loss: 1.4025\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8133 - val_loss: 1.4164\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6993 - val_loss: 1.3697\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6788 - val_loss: 1.3821\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6796 - val_loss: 1.3797\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6730 - val_loss: 1.3695\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6495 - val_loss: 1.3867\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6756 - val_loss: 1.3845\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6728 - val_loss: 1.3900\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6289 - val_loss: 1.3892\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5930 - val_loss: 1.3965\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5942 - val_loss: 1.4125\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4861 - val_loss: 1.3958\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5249 - val_loss: 1.4198\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4652 - val_loss: 1.4260\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5090 - val_loss: 1.4065\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4876 - val_loss: 1.4227\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4493 - val_loss: 1.4253\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4640 - val_loss: 1.4306\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5239 - val_loss: 1.4471\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3880 - val_loss: 1.4380\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4047 - val_loss: 1.4519\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3931 - val_loss: 1.4363\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4481 - val_loss: 1.4362\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3835 - val_loss: 1.4631\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3176 - val_loss: 1.4581\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3575 - val_loss: 1.4821\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3571 - val_loss: 1.5072\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3620 - val_loss: 1.4728\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2995 - val_loss: 1.4634\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3255 - val_loss: 1.4686\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2984 - val_loss: 1.4956\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2668 - val_loss: 1.4841\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1897 - val_loss: 1.4889\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2597 - val_loss: 1.4865\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2264 - val_loss: 1.4988\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2040 - val_loss: 1.4947\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2077 - val_loss: 1.5076\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]])]}\n",
      "Real LSTM seed 1 fold 1 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.1712 - val_loss: 1.4075\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9089 - val_loss: 1.3973\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7957 - val_loss: 1.3882\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7207 - val_loss: 1.4392\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8250 - val_loss: 1.4288\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7453 - val_loss: 1.4219\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6735 - val_loss: 1.4124\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6678 - val_loss: 1.4190\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6525 - val_loss: 1.4207\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6562 - val_loss: 1.4421\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6956 - val_loss: 1.4429\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6590 - val_loss: 1.4258\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5191 - val_loss: 1.4564\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5898 - val_loss: 1.4161\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5492 - val_loss: 1.3976\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5608 - val_loss: 1.3980\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5729 - val_loss: 1.4257\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5877 - val_loss: 1.4438\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5673 - val_loss: 1.4495\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5899 - val_loss: 1.4448\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5579 - val_loss: 1.4380\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5185 - val_loss: 1.4368\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4771 - val_loss: 1.4695\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5174 - val_loss: 1.4466\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5152 - val_loss: 1.4587\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4130 - val_loss: 1.5001\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4603 - val_loss: 1.4459\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4714 - val_loss: 1.4854\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4332 - val_loss: 1.4626\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4506 - val_loss: 1.4587\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4806 - val_loss: 1.4622\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5102 - val_loss: 1.4664\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3872 - val_loss: 1.5115\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4552 - val_loss: 1.4619\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4554 - val_loss: 1.4563\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3938 - val_loss: 1.4308\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4502 - val_loss: 1.4433\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3802 - val_loss: 1.5292\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3616 - val_loss: 1.5044\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3981 - val_loss: 1.5027\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3847 - val_loss: 1.5266\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3391 - val_loss: 1.5508\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3110 - val_loss: 1.6270\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3236 - val_loss: 1.6237\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3141 - val_loss: 1.6290\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 2 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.2981 - val_loss: 1.4576\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7932 - val_loss: 1.3667\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7728 - val_loss: 1.3873\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7149 - val_loss: 1.4006\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6545 - val_loss: 1.4372\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5967 - val_loss: 1.4270\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7376 - val_loss: 1.4434\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7234 - val_loss: 1.4019\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7219 - val_loss: 1.4293\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6581 - val_loss: 1.3948\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5974 - val_loss: 1.3430\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6129 - val_loss: 1.3544\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6461 - val_loss: 1.3872\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6682 - val_loss: 1.3914\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5684 - val_loss: 1.4083\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5850 - val_loss: 1.4052\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5937 - val_loss: 1.4120\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6615 - val_loss: 1.4265\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5505 - val_loss: 1.4380\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4768 - val_loss: 1.4610\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4745 - val_loss: 1.4594\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4988 - val_loss: 1.4439\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4758 - val_loss: 1.4038\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4574 - val_loss: 1.4006\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4922 - val_loss: 1.3995\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4962 - val_loss: 1.4088\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4766 - val_loss: 1.3972\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5269 - val_loss: 1.4012\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5108 - val_loss: 1.4392\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4263 - val_loss: 1.4258\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4815 - val_loss: 1.4079\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4259 - val_loss: 1.4540\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4406 - val_loss: 1.4691\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4060 - val_loss: 1.4991\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4751 - val_loss: 1.4644\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4070 - val_loss: 1.4669\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4341 - val_loss: 1.4968\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4284 - val_loss: 1.4539\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4280 - val_loss: 1.4549\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3628 - val_loss: 1.4592\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4189 - val_loss: 1.4636\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.4326 - val_loss: 1.4224\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0492 - val_loss: 1.4327\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8234 - val_loss: 1.3909\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7539 - val_loss: 1.3886\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8285 - val_loss: 1.3890\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8420 - val_loss: 1.3923\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7498 - val_loss: 1.4211\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6020 - val_loss: 1.4192\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7250 - val_loss: 1.4042\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6562 - val_loss: 1.3976\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6969 - val_loss: 1.4357\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6138 - val_loss: 1.4426\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6427 - val_loss: 1.4356\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6241 - val_loss: 1.4347\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6175 - val_loss: 1.4631\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5827 - val_loss: 1.4686\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6191 - val_loss: 1.4456\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6329 - val_loss: 1.4322\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4434 - val_loss: 1.4439\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5420 - val_loss: 1.4847\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4818 - val_loss: 1.4821\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5403 - val_loss: 1.4374\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4563 - val_loss: 1.4249\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5391 - val_loss: 1.4441\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4549 - val_loss: 1.4996\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5510 - val_loss: 1.4787\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5028 - val_loss: 1.4654\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4612 - val_loss: 1.4591\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4899 - val_loss: 1.4160\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5498 - val_loss: 1.4133\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4763 - val_loss: 1.4164\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4486 - val_loss: 1.4267\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4557 - val_loss: 1.4538\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4193 - val_loss: 1.4186\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4923 - val_loss: 1.4376\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4197 - val_loss: 1.4807\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4943 - val_loss: 1.4624\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4555 - val_loss: 1.4528\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4195 - val_loss: 1.4379\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3878 - val_loss: 1.4314\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4106 - val_loss: 1.4544\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3685 - val_loss: 1.4522\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3785 - val_loss: 1.4502\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4488 - val_loss: 1.4585\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3749 - val_loss: 1.4319\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3497 - val_loss: 1.4253\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3565 - val_loss: 1.4760\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4120 - val_loss: 1.4984\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3500 - val_loss: 1.5519\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3541 - val_loss: 1.5340\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3466 - val_loss: 1.5154\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3343 - val_loss: 1.4868\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3248 - val_loss: 1.4671\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3514 - val_loss: 1.4820\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3452 - val_loss: 1.4711\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3036 - val_loss: 1.4537\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3240 - val_loss: 1.4486\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3805 - val_loss: 1.4611\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2938 - val_loss: 1.4109\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3209 - val_loss: 1.4145\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2765 - val_loss: 1.4011\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2830 - val_loss: 1.4231\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3212 - val_loss: 1.4536\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2704 - val_loss: 1.4743\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2809 - val_loss: 1.4678\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2648 - val_loss: 1.5483\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3098 - val_loss: 1.5885\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2704 - val_loss: 1.5438\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3077 - val_loss: 1.4950\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2821 - val_loss: 1.4857\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2374 - val_loss: 1.4937\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2655 - val_loss: 1.5113\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3091 - val_loss: 1.5195\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2141 - val_loss: 1.5267\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2017 - val_loss: 1.5224\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1619 - val_loss: 1.4972\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2015 - val_loss: 1.4728\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2571 - val_loss: 1.4463\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1405 - val_loss: 1.4783\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1946 - val_loss: 1.4737\n",
      "Epoch 81/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1648 - val_loss: 1.4918\n",
      "Epoch 82/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1394 - val_loss: 1.5006\n",
      "Epoch 83/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1611 - val_loss: 1.4961\n",
      "Epoch 84/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1314 - val_loss: 1.4983\n",
      "Epoch 85/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1062 - val_loss: 1.4997\n",
      "Epoch 86/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0973 - val_loss: 1.5037\n",
      "Epoch 87/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0957 - val_loss: 1.5240\n",
      "Epoch 88/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1429 - val_loss: 1.5682\n",
      "Epoch 89/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1040 - val_loss: 1.5892\n",
      "Epoch 90/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1038 - val_loss: 1.5449\n",
      "Epoch 91/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0665 - val_loss: 1.5382\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.1991 - val_loss: 1.5198\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8925 - val_loss: 1.5598\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8254 - val_loss: 1.5266\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7007 - val_loss: 1.5285\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7204 - val_loss: 1.5710\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6800 - val_loss: 1.5460\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6945 - val_loss: 1.5252\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5800 - val_loss: 1.5387\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6277 - val_loss: 1.5464\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6091 - val_loss: 1.5428\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5673 - val_loss: 1.5469\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5053 - val_loss: 1.5424\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5982 - val_loss: 1.5395\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4960 - val_loss: 1.5481\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5816 - val_loss: 1.5377\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5538 - val_loss: 1.5325\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5182 - val_loss: 1.5206\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5416 - val_loss: 1.5143\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5378 - val_loss: 1.5120\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5123 - val_loss: 1.5232\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5413 - val_loss: 1.5083\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4801 - val_loss: 1.5020\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5275 - val_loss: 1.5124\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5075 - val_loss: 1.5009\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4967 - val_loss: 1.4963\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4618 - val_loss: 1.5139\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4674 - val_loss: 1.5155\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4638 - val_loss: 1.5271\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3881 - val_loss: 1.5674\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3978 - val_loss: 1.5843\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3486 - val_loss: 1.5450\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4401 - val_loss: 1.5601\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4534 - val_loss: 1.5787\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4078 - val_loss: 1.5858\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4213 - val_loss: 1.5938\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3671 - val_loss: 1.6067\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4280 - val_loss: 1.6144\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3952 - val_loss: 1.6303\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3876 - val_loss: 1.6223\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3720 - val_loss: 1.6087\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3276 - val_loss: 1.6329\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2971 - val_loss: 1.6607\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3487 - val_loss: 1.6584\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3704 - val_loss: 1.6900\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3217 - val_loss: 1.6752\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3228 - val_loss: 1.7154\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3076 - val_loss: 1.7319\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3809 - val_loss: 1.7209\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2779 - val_loss: 1.7652\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2536 - val_loss: 1.7389\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3125 - val_loss: 1.7041\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2702 - val_loss: 1.6988\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2595 - val_loss: 1.7077\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2939 - val_loss: 1.7119\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2638 - val_loss: 1.6923\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= 1\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.4444 - val_loss: 1.3752\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1378 - val_loss: 1.3615\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8046 - val_loss: 1.4049\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8158 - val_loss: 1.3995\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9254 - val_loss: 1.3861\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7563 - val_loss: 1.3864\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6260 - val_loss: 1.3638\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7011 - val_loss: 1.3639\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7683 - val_loss: 1.3738\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7825 - val_loss: 1.3615\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7421 - val_loss: 1.3897\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5656 - val_loss: 1.3775\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5441 - val_loss: 1.3594\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6441 - val_loss: 1.3762\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5917 - val_loss: 1.3916\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5963 - val_loss: 1.3945\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6032 - val_loss: 1.3832\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5292 - val_loss: 1.3726\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6025 - val_loss: 1.4051\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4923 - val_loss: 1.4103\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5173 - val_loss: 1.4142\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5127 - val_loss: 1.3970\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4471 - val_loss: 1.4228\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5000 - val_loss: 1.4220\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4539 - val_loss: 1.4113\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4792 - val_loss: 1.4099\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4223 - val_loss: 1.3835\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4224 - val_loss: 1.4023\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4266 - val_loss: 1.4221\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3257 - val_loss: 1.4299\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3974 - val_loss: 1.4324\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4346 - val_loss: 1.4499\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3950 - val_loss: 1.4674\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3916 - val_loss: 1.4915\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3383 - val_loss: 1.4796\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3035 - val_loss: 1.4798\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2957 - val_loss: 1.4941\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2923 - val_loss: 1.4909\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2752 - val_loss: 1.5316\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3140 - val_loss: 1.5356\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3191 - val_loss: 1.5380\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2831 - val_loss: 1.5308\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2565 - val_loss: 1.5596\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]])]}\n",
      "Real LSTM seed 1 fold 1 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.3038 - val_loss: 1.4528\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9315 - val_loss: 1.4863\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6758 - val_loss: 1.4872\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8203 - val_loss: 1.5027\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7776 - val_loss: 1.4991\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6878 - val_loss: 1.5064\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6806 - val_loss: 1.5015\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7839 - val_loss: 1.4609\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6832 - val_loss: 1.4741\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6508 - val_loss: 1.4768\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6901 - val_loss: 1.4575\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5703 - val_loss: 1.4504\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6345 - val_loss: 1.4623\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6692 - val_loss: 1.4668\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5852 - val_loss: 1.4535\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5401 - val_loss: 1.5066\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5815 - val_loss: 1.4697\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5823 - val_loss: 1.4773\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5568 - val_loss: 1.5375\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5386 - val_loss: 1.5488\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5185 - val_loss: 1.5546\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5543 - val_loss: 1.5587\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4710 - val_loss: 1.5541\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5222 - val_loss: 1.5611\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5108 - val_loss: 1.5775\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4852 - val_loss: 1.5941\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4450 - val_loss: 1.5919\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4513 - val_loss: 1.5885\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4825 - val_loss: 1.5744\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4032 - val_loss: 1.5814\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3875 - val_loss: 1.5940\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4460 - val_loss: 1.5924\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3726 - val_loss: 1.5716\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3753 - val_loss: 1.5644\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4165 - val_loss: 1.5886\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4463 - val_loss: 1.5578\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3907 - val_loss: 1.5549\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4161 - val_loss: 1.5562\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4000 - val_loss: 1.5866\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3599 - val_loss: 1.6012\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3817 - val_loss: 1.5719\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3637 - val_loss: 1.5862\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 2 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 2.2437 - val_loss: 1.3253\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0089 - val_loss: 1.3580\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9118 - val_loss: 1.3607\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7773 - val_loss: 1.4055\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7693 - val_loss: 1.4178\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7706 - val_loss: 1.4237\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7745 - val_loss: 1.3992\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7716 - val_loss: 1.4046\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7111 - val_loss: 1.4579\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6439 - val_loss: 1.4381\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5677 - val_loss: 1.4214\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7480 - val_loss: 1.3830\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6461 - val_loss: 1.3538\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5984 - val_loss: 1.3722\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6400 - val_loss: 1.3890\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6238 - val_loss: 1.3747\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6332 - val_loss: 1.3921\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5548 - val_loss: 1.3881\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5197 - val_loss: 1.4003\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5099 - val_loss: 1.4107\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5240 - val_loss: 1.3950\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5409 - val_loss: 1.3672\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4541 - val_loss: 1.3714\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4830 - val_loss: 1.3662\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4998 - val_loss: 1.3730\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4890 - val_loss: 1.3862\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4726 - val_loss: 1.3785\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4093 - val_loss: 1.3503\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4699 - val_loss: 1.3790\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4770 - val_loss: 1.4000\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3804 - val_loss: 1.4025\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3637 - val_loss: 1.3319\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3812 - val_loss: 1.3695\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3891 - val_loss: 1.3766\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3972 - val_loss: 1.3185\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4276 - val_loss: 1.3285\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3562 - val_loss: 1.3655\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3843 - val_loss: 1.3424\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3373 - val_loss: 1.3376\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3382 - val_loss: 1.3468\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3041 - val_loss: 1.3216\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3109 - val_loss: 1.3582\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3861 - val_loss: 1.3807\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3594 - val_loss: 1.3831\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2971 - val_loss: 1.3725\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2792 - val_loss: 1.3593\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3140 - val_loss: 1.3333\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2719 - val_loss: 1.4495\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2831 - val_loss: 1.4183\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2267 - val_loss: 1.4210\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2184 - val_loss: 1.4133\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2309 - val_loss: 1.4643\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2560 - val_loss: 1.4723\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2584 - val_loss: 1.4362\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2816 - val_loss: 1.4724\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2060 - val_loss: 1.5499\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2185 - val_loss: 1.5016\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2950 - val_loss: 1.4508\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1812 - val_loss: 1.4899\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1360 - val_loss: 1.4821\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1155 - val_loss: 1.4929\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1183 - val_loss: 1.4944\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2064 - val_loss: 1.4870\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1621 - val_loss: 1.5806\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1500 - val_loss: 1.4808\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.2863 - val_loss: 1.3685\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0211 - val_loss: 1.4012\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9300 - val_loss: 1.4222\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8625 - val_loss: 1.4194\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7947 - val_loss: 1.3748\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8287 - val_loss: 1.3774\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8125 - val_loss: 1.3756\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7008 - val_loss: 1.3797\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7284 - val_loss: 1.3728\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7024 - val_loss: 1.3858\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6395 - val_loss: 1.4174\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6534 - val_loss: 1.4155\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7392 - val_loss: 1.4256\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5785 - val_loss: 1.4089\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6532 - val_loss: 1.4208\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5739 - val_loss: 1.4421\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6549 - val_loss: 1.4453\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5789 - val_loss: 1.4182\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5479 - val_loss: 1.4373\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5688 - val_loss: 1.4650\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5885 - val_loss: 1.4742\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5939 - val_loss: 1.4646\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5953 - val_loss: 1.4363\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5625 - val_loss: 1.4465\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5604 - val_loss: 1.4488\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5794 - val_loss: 1.4449\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5470 - val_loss: 1.4339\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5383 - val_loss: 1.4277\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5578 - val_loss: 1.4448\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5232 - val_loss: 1.4395\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5135 - val_loss: 1.4247\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5244 - val_loss: 1.4233\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5122 - val_loss: 1.4198\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5502 - val_loss: 1.3943\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4526 - val_loss: 1.4046\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5021 - val_loss: 1.4142\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4663 - val_loss: 1.4191\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4684 - val_loss: 1.4123\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4787 - val_loss: 1.4037\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4586 - val_loss: 1.4138\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4628 - val_loss: 1.4016\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4501 - val_loss: 1.4076\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4571 - val_loss: 1.4090\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4149 - val_loss: 1.3946\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3924 - val_loss: 1.3933\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3475 - val_loss: 1.3985\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4147 - val_loss: 1.4149\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3257 - val_loss: 1.4148\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3247 - val_loss: 1.4255\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3392 - val_loss: 1.4021\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3662 - val_loss: 1.3814\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3999 - val_loss: 1.3941\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3003 - val_loss: 1.3596\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3173 - val_loss: 1.3529\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3365 - val_loss: 1.3666\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2840 - val_loss: 1.3760\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3278 - val_loss: 1.3859\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3101 - val_loss: 1.3979\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3458 - val_loss: 1.3979\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2580 - val_loss: 1.4185\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2305 - val_loss: 1.4264\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2671 - val_loss: 1.3928\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2893 - val_loss: 1.3963\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3021 - val_loss: 1.3826\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2272 - val_loss: 1.3839\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2606 - val_loss: 1.3576\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1948 - val_loss: 1.3728\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2198 - val_loss: 1.4318\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2145 - val_loss: 1.4228\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2868 - val_loss: 1.4345\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2819 - val_loss: 1.4791\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2080 - val_loss: 1.4659\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2512 - val_loss: 1.4405\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1162 - val_loss: 1.4330\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1993 - val_loss: 1.4375\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1098 - val_loss: 1.4512\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1915 - val_loss: 1.4786\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1440 - val_loss: 1.4722\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1721 - val_loss: 1.4739\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1796 - val_loss: 1.4437\n",
      "Epoch 81/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1238 - val_loss: 1.4437\n",
      "Epoch 82/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1587 - val_loss: 1.4455\n",
      "Epoch 83/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0989 - val_loss: 1.4428\n",
      "Epoch 84/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0676 - val_loss: 1.4384\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.4782 - val_loss: 1.5361\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1166 - val_loss: 1.5163\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8951 - val_loss: 1.5212\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8870 - val_loss: 1.5258\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8422 - val_loss: 1.5278\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7471 - val_loss: 1.4906\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7809 - val_loss: 1.4846\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6729 - val_loss: 1.5004\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8151 - val_loss: 1.4949\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7177 - val_loss: 1.5046\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6623 - val_loss: 1.5195\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7337 - val_loss: 1.5156\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6728 - val_loss: 1.5050\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7143 - val_loss: 1.5131\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7357 - val_loss: 1.5489\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5801 - val_loss: 1.5217\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6269 - val_loss: 1.5238\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5299 - val_loss: 1.5148\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6568 - val_loss: 1.5111\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5799 - val_loss: 1.5084\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6086 - val_loss: 1.4933\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5742 - val_loss: 1.5030\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5488 - val_loss: 1.4953\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6509 - val_loss: 1.4957\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5386 - val_loss: 1.4947\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5250 - val_loss: 1.5365\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5470 - val_loss: 1.5514\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5908 - val_loss: 1.5587\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5313 - val_loss: 1.5774\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5723 - val_loss: 1.5780\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5411 - val_loss: 1.5794\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5590 - val_loss: 1.5762\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5417 - val_loss: 1.5819\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4868 - val_loss: 1.5655\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5935 - val_loss: 1.5551\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5104 - val_loss: 1.5752\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5072 - val_loss: 1.5842\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5304 - val_loss: 1.5827\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5223 - val_loss: 1.5746\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5377 - val_loss: 1.5807\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4504 - val_loss: 1.6049\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4931 - val_loss: 1.5835\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4005 - val_loss: 1.5692\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4022 - val_loss: 1.5881\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4829 - val_loss: 1.5845\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4051 - val_loss: 1.5770\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3819 - val_loss: 1.5841\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4503 - val_loss: 1.6004\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4057 - val_loss: 1.5950\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4016 - val_loss: 1.5901\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3443 - val_loss: 1.5969\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= 2\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 20ms/step - loss: 2.1404 - val_loss: 1.3779\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0233 - val_loss: 1.4035\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7219 - val_loss: 1.4125\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7377 - val_loss: 1.3972\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7557 - val_loss: 1.3986\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6975 - val_loss: 1.3845\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6568 - val_loss: 1.3792\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6064 - val_loss: 1.3709\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6596 - val_loss: 1.3699\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6678 - val_loss: 1.3789\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6030 - val_loss: 1.3765\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6197 - val_loss: 1.3781\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5456 - val_loss: 1.3966\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5397 - val_loss: 1.4043\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5092 - val_loss: 1.3983\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5260 - val_loss: 1.4014\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5054 - val_loss: 1.4080\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4901 - val_loss: 1.3711\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4958 - val_loss: 1.3788\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4821 - val_loss: 1.3965\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5440 - val_loss: 1.4028\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5054 - val_loss: 1.3951\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4758 - val_loss: 1.3875\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4855 - val_loss: 1.3903\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4324 - val_loss: 1.3902\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4655 - val_loss: 1.4219\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4237 - val_loss: 1.4437\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4162 - val_loss: 1.4179\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4400 - val_loss: 1.3995\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4179 - val_loss: 1.4148\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4047 - val_loss: 1.4349\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4232 - val_loss: 1.4437\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3486 - val_loss: 1.4362\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3611 - val_loss: 1.4306\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3562 - val_loss: 1.4539\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3791 - val_loss: 1.4578\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3617 - val_loss: 1.4743\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3138 - val_loss: 1.4578\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3145 - val_loss: 1.4296\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3419 - val_loss: 1.4048\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2692 - val_loss: 1.4063\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3570 - val_loss: 1.4093\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2950 - val_loss: 1.3959\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3041 - val_loss: 1.4261\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2581 - val_loss: 1.4277\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3006 - val_loss: 1.4023\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2463 - val_loss: 1.4307\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2575 - val_loss: 1.4037\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]])]}\n",
      "Real LSTM seed 1 fold 1 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.2783 - val_loss: 1.4439\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8666 - val_loss: 1.4077\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8355 - val_loss: 1.4266\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7779 - val_loss: 1.4090\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7372 - val_loss: 1.4107\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7286 - val_loss: 1.4226\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7202 - val_loss: 1.4705\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6790 - val_loss: 1.4885\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6654 - val_loss: 1.4560\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6594 - val_loss: 1.4558\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6557 - val_loss: 1.4581\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5859 - val_loss: 1.4396\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5563 - val_loss: 1.4650\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6194 - val_loss: 1.4736\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5848 - val_loss: 1.4813\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6514 - val_loss: 1.4895\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6429 - val_loss: 1.5147\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5919 - val_loss: 1.5084\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6034 - val_loss: 1.5136\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5374 - val_loss: 1.5169\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4961 - val_loss: 1.5319\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5353 - val_loss: 1.5420\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5060 - val_loss: 1.5420\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5438 - val_loss: 1.5334\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5514 - val_loss: 1.5985\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4687 - val_loss: 1.6015\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4791 - val_loss: 1.5830\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5021 - val_loss: 1.6076\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4676 - val_loss: 1.5595\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4617 - val_loss: 1.5759\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5100 - val_loss: 1.5672\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4021 - val_loss: 1.5696\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4516 - val_loss: 1.5797\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4281 - val_loss: 1.5755\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4528 - val_loss: 1.5059\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4290 - val_loss: 1.5142\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3822 - val_loss: 1.5336\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3636 - val_loss: 1.5457\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3668 - val_loss: 1.5569\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3858 - val_loss: 1.6872\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3817 - val_loss: 1.7175\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4065 - val_loss: 1.6667\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 2 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.2375 - val_loss: 1.4123\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9370 - val_loss: 1.3936\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8894 - val_loss: 1.3812\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7143 - val_loss: 1.3960\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6947 - val_loss: 1.4045\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6225 - val_loss: 1.3965\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6870 - val_loss: 1.4046\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6832 - val_loss: 1.3950\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6871 - val_loss: 1.3749\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5760 - val_loss: 1.3793\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6195 - val_loss: 1.3675\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7145 - val_loss: 1.3925\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5859 - val_loss: 1.3927\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5941 - val_loss: 1.3890\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6434 - val_loss: 1.3979\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5625 - val_loss: 1.3312\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5594 - val_loss: 1.3955\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5725 - val_loss: 1.4026\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5261 - val_loss: 1.4283\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4921 - val_loss: 1.4385\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5555 - val_loss: 1.3730\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4972 - val_loss: 1.3663\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4690 - val_loss: 1.3436\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4354 - val_loss: 1.3607\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5289 - val_loss: 1.4272\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4010 - val_loss: 1.4702\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4524 - val_loss: 1.4036\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4728 - val_loss: 1.3911\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3762 - val_loss: 1.4262\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4234 - val_loss: 1.4207\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4593 - val_loss: 1.4121\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4585 - val_loss: 1.3978\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3824 - val_loss: 1.4230\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4220 - val_loss: 1.4147\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4433 - val_loss: 1.4023\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3634 - val_loss: 1.4017\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3918 - val_loss: 1.4437\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3958 - val_loss: 1.4401\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4034 - val_loss: 1.4538\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2818 - val_loss: 1.4724\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3895 - val_loss: 1.5091\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3897 - val_loss: 1.4655\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3494 - val_loss: 1.4647\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3140 - val_loss: 1.4385\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2954 - val_loss: 1.4241\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3463 - val_loss: 1.4606\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.1414 - val_loss: 1.3557\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8960 - val_loss: 1.3649\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8755 - val_loss: 1.3622\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7220 - val_loss: 1.3981\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7757 - val_loss: 1.3930\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7149 - val_loss: 1.3822\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7688 - val_loss: 1.3804\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6592 - val_loss: 1.3932\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5956 - val_loss: 1.3863\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5949 - val_loss: 1.3676\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6208 - val_loss: 1.3755\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5761 - val_loss: 1.3578\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5747 - val_loss: 1.3564\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5137 - val_loss: 1.3586\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6509 - val_loss: 1.3667\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6183 - val_loss: 1.3844\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5628 - val_loss: 1.3809\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5918 - val_loss: 1.3698\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6352 - val_loss: 1.3866\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5765 - val_loss: 1.4076\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5437 - val_loss: 1.3600\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5867 - val_loss: 1.3612\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5259 - val_loss: 1.3597\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5726 - val_loss: 1.3594\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4286 - val_loss: 1.3548\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5072 - val_loss: 1.3775\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4661 - val_loss: 1.3677\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4561 - val_loss: 1.3583\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4899 - val_loss: 1.3506\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4816 - val_loss: 1.3393\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4287 - val_loss: 1.3484\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4806 - val_loss: 1.3511\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4537 - val_loss: 1.3680\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4336 - val_loss: 1.3686\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3843 - val_loss: 1.3531\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4423 - val_loss: 1.3451\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3969 - val_loss: 1.3227\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4231 - val_loss: 1.3327\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4089 - val_loss: 1.3499\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4223 - val_loss: 1.3462\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4513 - val_loss: 1.3513\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4375 - val_loss: 1.3697\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4021 - val_loss: 1.3828\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3575 - val_loss: 1.3941\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3555 - val_loss: 1.3841\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3655 - val_loss: 1.3884\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3766 - val_loss: 1.4284\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4231 - val_loss: 1.4005\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3854 - val_loss: 1.3996\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3722 - val_loss: 1.3920\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3742 - val_loss: 1.3777\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3610 - val_loss: 1.3675\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2666 - val_loss: 1.3687\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3238 - val_loss: 1.3833\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3165 - val_loss: 1.3946\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3871 - val_loss: 1.4061\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3437 - val_loss: 1.4139\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3358 - val_loss: 1.4210\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3243 - val_loss: 1.4175\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3168 - val_loss: 1.4211\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2844 - val_loss: 1.4279\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3057 - val_loss: 1.4368\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2639 - val_loss: 1.4303\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2602 - val_loss: 1.4307\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2295 - val_loss: 1.4284\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2417 - val_loss: 1.4331\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2876 - val_loss: 1.4352\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.5888 - val_loss: 1.5019\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0535 - val_loss: 1.5493\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0031 - val_loss: 1.5285\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9508 - val_loss: 1.5063\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9963 - val_loss: 1.5079\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7606 - val_loss: 1.4948\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8400 - val_loss: 1.5068\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7434 - val_loss: 1.5107\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7513 - val_loss: 1.5059\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7214 - val_loss: 1.5129\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6939 - val_loss: 1.5326\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7159 - val_loss: 1.5134\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7105 - val_loss: 1.5312\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6859 - val_loss: 1.5408\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7070 - val_loss: 1.5377\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6236 - val_loss: 1.5171\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6465 - val_loss: 1.5347\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7015 - val_loss: 1.5258\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6554 - val_loss: 1.5416\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6623 - val_loss: 1.5484\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5774 - val_loss: 1.5500\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5703 - val_loss: 1.5311\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6121 - val_loss: 1.5207\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6397 - val_loss: 1.5373\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6130 - val_loss: 1.5590\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6842 - val_loss: 1.5629\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5868 - val_loss: 1.5753\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6148 - val_loss: 1.5755\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5731 - val_loss: 1.5677\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5516 - val_loss: 1.5721\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5502 - val_loss: 1.5722\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6231 - val_loss: 1.5770\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5407 - val_loss: 1.5628\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4806 - val_loss: 1.5598\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5471 - val_loss: 1.5658\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5553 - val_loss: 1.5931\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5065 - val_loss: 1.5997\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5363 - val_loss: 1.6045\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5364 - val_loss: 1.6068\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4899 - val_loss: 1.6065\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4670 - val_loss: 1.5464\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4759 - val_loss: 1.5418\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= 3\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 751ms/step - loss: 2.4680 - val_loss: 1.3940\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9821 - val_loss: 1.4066\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8444 - val_loss: 1.4483\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8377 - val_loss: 1.4317\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8273 - val_loss: 1.4079\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7736 - val_loss: 1.4121\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6783 - val_loss: 1.4121\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9091 - val_loss: 1.4207\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7116 - val_loss: 1.4223\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6249 - val_loss: 1.4396\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6616 - val_loss: 1.4306\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7076 - val_loss: 1.4195\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6960 - val_loss: 1.4196\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6738 - val_loss: 1.4344\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6042 - val_loss: 1.4186\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6011 - val_loss: 1.4218\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5766 - val_loss: 1.4469\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6036 - val_loss: 1.4435\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5475 - val_loss: 1.4709\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5374 - val_loss: 1.4651\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5975 - val_loss: 1.4644\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4854 - val_loss: 1.4348\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5209 - val_loss: 1.4268\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5054 - val_loss: 1.4131\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4715 - val_loss: 1.3940\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5282 - val_loss: 1.4023\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5911 - val_loss: 1.4124\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4311 - val_loss: 1.4169\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4060 - val_loss: 1.4495\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4053 - val_loss: 1.4446\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4619 - val_loss: 1.4590\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4087 - val_loss: 1.4648\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3669 - val_loss: 1.4825\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4176 - val_loss: 1.4753\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4694 - val_loss: 1.4626\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3763 - val_loss: 1.4819\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4402 - val_loss: 1.4899\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3170 - val_loss: 1.5012\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3006 - val_loss: 1.5219\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3486 - val_loss: 1.5213\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3578 - val_loss: 1.5628\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3323 - val_loss: 1.5316\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3910 - val_loss: 1.5651\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3415 - val_loss: 1.5787\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3156 - val_loss: 1.5531\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2916 - val_loss: 1.5239\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2314 - val_loss: 1.5347\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2258 - val_loss: 1.5307\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3118 - val_loss: 1.5386\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1866 - val_loss: 1.5253\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1870 - val_loss: 1.5162\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1945 - val_loss: 1.5124\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1887 - val_loss: 1.5152\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2132 - val_loss: 1.5526\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1313 - val_loss: 1.6667\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]])]}\n",
      "Real LSTM seed 1 fold 1 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.4051 - val_loss: 1.4033\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0311 - val_loss: 1.3726\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7015 - val_loss: 1.3792\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7975 - val_loss: 1.4329\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6443 - val_loss: 1.4284\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6530 - val_loss: 1.4288\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6382 - val_loss: 1.4342\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7023 - val_loss: 1.4420\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5854 - val_loss: 1.4262\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6242 - val_loss: 1.4314\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5353 - val_loss: 1.4363\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6001 - val_loss: 1.4633\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5649 - val_loss: 1.4443\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5575 - val_loss: 1.4589\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5806 - val_loss: 1.4723\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4974 - val_loss: 1.4670\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5158 - val_loss: 1.4782\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5638 - val_loss: 1.4812\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5091 - val_loss: 1.4902\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4839 - val_loss: 1.4899\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5065 - val_loss: 1.5102\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4743 - val_loss: 1.4778\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4866 - val_loss: 1.4932\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5184 - val_loss: 1.5000\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4998 - val_loss: 1.5128\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4280 - val_loss: 1.5121\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5364 - val_loss: 1.5375\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4078 - val_loss: 1.5925\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4595 - val_loss: 1.5506\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4530 - val_loss: 1.5489\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4295 - val_loss: 1.5804\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3680 - val_loss: 1.5771\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3957 - val_loss: 1.6277\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4010 - val_loss: 1.5650\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3843 - val_loss: 1.6255\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3611 - val_loss: 1.6145\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4032 - val_loss: 1.6615\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4154 - val_loss: 1.6496\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3695 - val_loss: 1.6385\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3704 - val_loss: 1.6482\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3380 - val_loss: 1.6618\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Real LSTM seed 1 fold 2 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.2684 - val_loss: 1.4408\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8636 - val_loss: 1.4568\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7770 - val_loss: 1.4694\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7191 - val_loss: 1.4587\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7181 - val_loss: 1.4431\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7362 - val_loss: 1.4158\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6736 - val_loss: 1.4228\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6415 - val_loss: 1.4389\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6380 - val_loss: 1.4269\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6075 - val_loss: 1.4391\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5796 - val_loss: 1.4571\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5888 - val_loss: 1.4181\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5494 - val_loss: 1.4102\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5957 - val_loss: 1.3879\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5439 - val_loss: 1.4141\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5464 - val_loss: 1.4045\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5259 - val_loss: 1.3864\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5980 - val_loss: 1.3550\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4902 - val_loss: 1.3802\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5523 - val_loss: 1.3772\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5304 - val_loss: 1.4146\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5104 - val_loss: 1.4137\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4756 - val_loss: 1.3867\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4892 - val_loss: 1.3790\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4548 - val_loss: 1.3887\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4812 - val_loss: 1.3665\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4054 - val_loss: 1.3569\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5070 - val_loss: 1.3325\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4651 - val_loss: 1.3265\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4685 - val_loss: 1.3362\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4820 - val_loss: 1.3720\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4421 - val_loss: 1.3803\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4733 - val_loss: 1.3717\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3751 - val_loss: 1.3616\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4118 - val_loss: 1.3541\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4560 - val_loss: 1.3628\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4321 - val_loss: 1.3848\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4103 - val_loss: 1.3879\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3853 - val_loss: 1.3983\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4391 - val_loss: 1.4571\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4196 - val_loss: 1.4093\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4240 - val_loss: 1.3894\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3501 - val_loss: 1.4375\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3280 - val_loss: 1.4291\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3585 - val_loss: 1.4290\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3440 - val_loss: 1.4511\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3187 - val_loss: 1.4398\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3280 - val_loss: 1.4299\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3026 - val_loss: 1.4741\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3503 - val_loss: 1.4645\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3294 - val_loss: 1.4806\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3370 - val_loss: 1.4711\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 4s/step - loss: 1.3254 - val_loss: 1.4268\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3276 - val_loss: 1.3837\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2853 - val_loss: 1.3594\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3125 - val_loss: 1.3692\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3335 - val_loss: 1.3685\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3022 - val_loss: 1.3185\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2678 - val_loss: 1.3527\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2698 - val_loss: 1.3767\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2383 - val_loss: 1.3746\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2592 - val_loss: 1.4666\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2416 - val_loss: 1.4652\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1785 - val_loss: 1.4232\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2314 - val_loss: 1.4182\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2394 - val_loss: 1.4675\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2452 - val_loss: 1.4059\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2139 - val_loss: 1.3405\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2320 - val_loss: 1.5087\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2562 - val_loss: 1.4702\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2125 - val_loss: 1.4426\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2184 - val_loss: 1.4613\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1580 - val_loss: 1.4520\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1422 - val_loss: 1.3940\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1431 - val_loss: 1.3728\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1439 - val_loss: 1.3851\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2102 - val_loss: 1.3898\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1972 - val_loss: 1.4456\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1743 - val_loss: 1.3984\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1510 - val_loss: 1.4038\n",
      "Epoch 81/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1257 - val_loss: 1.4342\n",
      "Epoch 82/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0974 - val_loss: 1.4908\n",
      "Epoch 83/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1317 - val_loss: 1.4854\n",
      "Epoch 84/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1596 - val_loss: 1.4374\n",
      "Epoch 85/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1700 - val_loss: 1.4293\n",
      "Epoch 86/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1200 - val_loss: 1.4518\n",
      "Epoch 87/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1088 - val_loss: 1.4670\n",
      "Epoch 88/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0764 - val_loss: 1.4880\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.5157 - val_loss: 1.3806\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0093 - val_loss: 1.3914\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8611 - val_loss: 1.3688\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9435 - val_loss: 1.3853\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8213 - val_loss: 1.3817\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8294 - val_loss: 1.4144\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8285 - val_loss: 1.3989\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6780 - val_loss: 1.3908\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6772 - val_loss: 1.4055\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7406 - val_loss: 1.4069\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7200 - val_loss: 1.4111\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6705 - val_loss: 1.4145\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6278 - val_loss: 1.4102\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6354 - val_loss: 1.4200\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6775 - val_loss: 1.4377\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6360 - val_loss: 1.4335\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5989 - val_loss: 1.4017\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7154 - val_loss: 1.4028\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5404 - val_loss: 1.4064\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5150 - val_loss: 1.4017\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6195 - val_loss: 1.4061\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5003 - val_loss: 1.4163\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5364 - val_loss: 1.4064\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5083 - val_loss: 1.4141\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5423 - val_loss: 1.3965\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5251 - val_loss: 1.4242\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4740 - val_loss: 1.4186\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5682 - val_loss: 1.4160\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4784 - val_loss: 1.4124\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4970 - val_loss: 1.3948\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5020 - val_loss: 1.3936\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4971 - val_loss: 1.3910\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4569 - val_loss: 1.4461\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4591 - val_loss: 1.4144\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4866 - val_loss: 1.4141\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4322 - val_loss: 1.3988\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4701 - val_loss: 1.3944\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4545 - val_loss: 1.4119\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4486 - val_loss: 1.4170\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4024 - val_loss: 1.4144\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4203 - val_loss: 1.4233\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3874 - val_loss: 1.3872\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4077 - val_loss: 1.4018\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3508 - val_loss: 1.3904\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3880 - val_loss: 1.4291\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4292 - val_loss: 1.4469\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3313 - val_loss: 1.4514\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4107 - val_loss: 1.4606\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3331 - val_loss: 1.4719\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3914 - val_loss: 1.4878\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3132 - val_loss: 1.4612\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3009 - val_loss: 1.4716\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3103 - val_loss: 1.4785\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2688 - val_loss: 1.4880\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2572 - val_loss: 1.5108\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3156 - val_loss: 1.5082\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2317 - val_loss: 1.5111\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2437 - val_loss: 1.5290\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2882 - val_loss: 1.5048\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3293 - val_loss: 1.5647\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2987 - val_loss: 1.5355\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2514 - val_loss: 1.4835\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2688 - val_loss: 1.4991\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2261 - val_loss: 1.4902\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2366 - val_loss: 1.4469\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2033 - val_loss: 1.4689\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2361 - val_loss: 1.4823\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2273 - val_loss: 1.4940\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1988 - val_loss: 1.5173\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1780 - val_loss: 1.4824\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1374 - val_loss: 1.5084\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1897 - val_loss: 1.4902\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 2.4901 - val_loss: 1.5568\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0298 - val_loss: 1.5306\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9161 - val_loss: 1.5223\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8614 - val_loss: 1.5221\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8037 - val_loss: 1.5275\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7413 - val_loss: 1.5486\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7357 - val_loss: 1.5388\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7380 - val_loss: 1.5438\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7039 - val_loss: 1.5560\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6976 - val_loss: 1.5555\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6484 - val_loss: 1.5577\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7674 - val_loss: 1.5555\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6884 - val_loss: 1.5522\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6334 - val_loss: 1.5602\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5888 - val_loss: 1.5889\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6833 - val_loss: 1.5857\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6055 - val_loss: 1.5866\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5998 - val_loss: 1.5872\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5551 - val_loss: 1.5998\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5675 - val_loss: 1.5905\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5795 - val_loss: 1.6021\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5723 - val_loss: 1.6102\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5866 - val_loss: 1.6162\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5355 - val_loss: 1.6100\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5851 - val_loss: 1.6111\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5146 - val_loss: 1.6034\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5398 - val_loss: 1.6081\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4420 - val_loss: 1.6000\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5133 - val_loss: 1.5878\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4782 - val_loss: 1.5926\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4996 - val_loss: 1.5988\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4447 - val_loss: 1.6137\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4325 - val_loss: 1.6139\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4058 - val_loss: 1.6279\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3903 - val_loss: 1.6355\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4013 - val_loss: 1.6404\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4940 - val_loss: 1.6575\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4245 - val_loss: 1.6671\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3429 - val_loss: 1.6745\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4472 - val_loss: 1.6780\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3814 - val_loss: 1.6478\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3896 - val_loss: 1.6513\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4111 - val_loss: 1.6408\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= 4\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.1471 - val_loss: 1.3327\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8118 - val_loss: 1.3581\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7983 - val_loss: 1.4125\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7801 - val_loss: 1.4657\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7849 - val_loss: 1.4285\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7136 - val_loss: 1.4098\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7894 - val_loss: 1.4087\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6440 - val_loss: 1.3993\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6674 - val_loss: 1.3898\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7050 - val_loss: 1.3893\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6301 - val_loss: 1.3805\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6301 - val_loss: 1.3721\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6015 - val_loss: 1.3724\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5574 - val_loss: 1.3702\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5410 - val_loss: 1.3697\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5559 - val_loss: 1.3659\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5798 - val_loss: 1.3651\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5360 - val_loss: 1.3501\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5986 - val_loss: 1.3409\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6165 - val_loss: 1.3389\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5215 - val_loss: 1.3446\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5556 - val_loss: 1.3439\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4811 - val_loss: 1.3514\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4993 - val_loss: 1.3843\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4350 - val_loss: 1.3715\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4120 - val_loss: 1.3710\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4380 - val_loss: 1.4064\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4930 - val_loss: 1.4250\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4034 - val_loss: 1.4071\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4645 - val_loss: 1.4000\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4060 - val_loss: 1.4108\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3572 - val_loss: 1.4351\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4221 - val_loss: 1.4620\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4338 - val_loss: 1.4493\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3819 - val_loss: 1.3839\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3864 - val_loss: 1.3572\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3964 - val_loss: 1.3486\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3603 - val_loss: 1.3709\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3504 - val_loss: 1.4476\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3132 - val_loss: 1.4190\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3122 - val_loss: 1.3701\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3026 - val_loss: 1.4059\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2991 - val_loss: 1.4213\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3085 - val_loss: 1.4495\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2844 - val_loss: 1.4854\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3363 - val_loss: 1.5086\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2929 - val_loss: 1.4778\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2810 - val_loss: 1.4415\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2251 - val_loss: 1.4706\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1873 - val_loss: 1.4882\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.2665 - val_loss: 1.8191\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0510 - val_loss: 1.8149\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8795 - val_loss: 1.8457\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9154 - val_loss: 1.8530\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9017 - val_loss: 1.8425\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7748 - val_loss: 1.8616\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7917 - val_loss: 1.8848\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8522 - val_loss: 1.8951\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6755 - val_loss: 1.9023\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6638 - val_loss: 1.9163\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7330 - val_loss: 1.9097\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6449 - val_loss: 1.9466\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7299 - val_loss: 1.9590\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5264 - val_loss: 1.9799\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6459 - val_loss: 1.9901\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6089 - val_loss: 1.9728\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6911 - val_loss: 1.9382\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6323 - val_loss: 1.8784\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5288 - val_loss: 1.9263\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5551 - val_loss: 1.9763\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4722 - val_loss: 1.9309\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6231 - val_loss: 1.8713\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5323 - val_loss: 1.8070\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5390 - val_loss: 1.8121\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5675 - val_loss: 1.8698\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4734 - val_loss: 1.9137\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4824 - val_loss: 1.9221\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5088 - val_loss: 1.8971\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4081 - val_loss: 1.9060\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4132 - val_loss: 1.9357\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4038 - val_loss: 1.9340\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4839 - val_loss: 1.9595\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4459 - val_loss: 1.9706\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3649 - val_loss: 1.9775\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3502 - val_loss: 1.9977\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4933 - val_loss: 2.0761\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3841 - val_loss: 2.0894\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4355 - val_loss: 2.1024\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3846 - val_loss: 2.1476\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3200 - val_loss: 2.1759\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3410 - val_loss: 2.1823\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3210 - val_loss: 2.1256\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3234 - val_loss: 2.1145\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3310 - val_loss: 2.0897\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3064 - val_loss: 2.1377\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3268 - val_loss: 2.1476\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2493 - val_loss: 2.1609\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2785 - val_loss: 2.2731\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2430 - val_loss: 2.2709\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2896 - val_loss: 2.2571\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2444 - val_loss: 2.1752\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2126 - val_loss: 2.2009\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2285 - val_loss: 2.2609\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 2 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.2400 - val_loss: 1.5726\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8692 - val_loss: 1.5396\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7448 - val_loss: 1.5273\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7648 - val_loss: 1.5715\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7704 - val_loss: 1.5547\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6952 - val_loss: 1.5996\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7126 - val_loss: 1.6030\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6353 - val_loss: 1.5869\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6475 - val_loss: 1.5971\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6230 - val_loss: 1.5619\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7081 - val_loss: 1.5842\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6933 - val_loss: 1.6317\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6700 - val_loss: 1.6417\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6084 - val_loss: 1.6137\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5914 - val_loss: 1.6033\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6605 - val_loss: 1.5969\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6188 - val_loss: 1.6170\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6035 - val_loss: 1.6314\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5205 - val_loss: 1.6296\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5521 - val_loss: 1.6413\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5615 - val_loss: 1.6204\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5553 - val_loss: 1.5961\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4695 - val_loss: 1.5707\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5486 - val_loss: 1.5649\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5085 - val_loss: 1.5609\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4494 - val_loss: 1.5897\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4258 - val_loss: 1.5670\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4710 - val_loss: 1.5567\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4541 - val_loss: 1.5417\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4269 - val_loss: 1.5202\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4660 - val_loss: 1.5848\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4134 - val_loss: 1.5953\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4080 - val_loss: 1.5949\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4841 - val_loss: 1.5887\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3503 - val_loss: 1.5801\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3861 - val_loss: 1.6118\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4051 - val_loss: 1.5701\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4162 - val_loss: 1.6085\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3753 - val_loss: 1.5935\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3756 - val_loss: 1.5993\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3253 - val_loss: 1.6017\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3694 - val_loss: 1.6319\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3361 - val_loss: 1.5990\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3599 - val_loss: 1.5956\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3519 - val_loss: 1.5972\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3614 - val_loss: 1.5703\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2735 - val_loss: 1.5729\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2635 - val_loss: 1.5919\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2340 - val_loss: 1.6225\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2623 - val_loss: 1.5780\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2453 - val_loss: 1.5684\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2468 - val_loss: 1.6103\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2632 - val_loss: 1.5883\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2763 - val_loss: 1.6310\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2309 - val_loss: 1.6292\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2072 - val_loss: 1.6312\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2445 - val_loss: 1.6657\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2042 - val_loss: 1.7132\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2357 - val_loss: 1.6682\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1950 - val_loss: 1.6576\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.1676 - val_loss: 1.6353\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8405 - val_loss: 1.6650\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7643 - val_loss: 1.6594\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7060 - val_loss: 1.6720\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7017 - val_loss: 1.6446\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6499 - val_loss: 1.6020\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5836 - val_loss: 1.5795\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7695 - val_loss: 1.6016\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6366 - val_loss: 1.5803\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6037 - val_loss: 1.5920\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5696 - val_loss: 1.6227\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5413 - val_loss: 1.5973\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5332 - val_loss: 1.6471\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5402 - val_loss: 1.6598\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5413 - val_loss: 1.6900\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5471 - val_loss: 1.7003\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5722 - val_loss: 1.6999\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5004 - val_loss: 1.6889\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5088 - val_loss: 1.6855\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4572 - val_loss: 1.6789\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5300 - val_loss: 1.6825\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4812 - val_loss: 1.6740\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4452 - val_loss: 1.6957\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4490 - val_loss: 1.6833\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4028 - val_loss: 1.6511\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4189 - val_loss: 1.6164\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4671 - val_loss: 1.6456\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4429 - val_loss: 1.6454\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4580 - val_loss: 1.6568\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4153 - val_loss: 1.7053\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4141 - val_loss: 1.6875\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4013 - val_loss: 1.6716\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4341 - val_loss: 1.7112\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4301 - val_loss: 1.7082\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3685 - val_loss: 1.7395\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3667 - val_loss: 1.7405\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3859 - val_loss: 1.7542\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3306 - val_loss: 1.7254\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3344 - val_loss: 1.7010\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3448 - val_loss: 1.7534\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4164 - val_loss: 1.7449\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3877 - val_loss: 1.6627\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.4763 - val_loss: 1.5185\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8951 - val_loss: 1.5186\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8498 - val_loss: 1.5218\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8831 - val_loss: 1.5204\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8008 - val_loss: 1.5458\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7780 - val_loss: 1.5458\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6951 - val_loss: 1.5403\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6662 - val_loss: 1.5523\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6613 - val_loss: 1.5926\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6422 - val_loss: 1.5855\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7113 - val_loss: 1.5887\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6249 - val_loss: 1.5476\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6748 - val_loss: 1.5323\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6159 - val_loss: 1.5203\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6428 - val_loss: 1.5405\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5428 - val_loss: 1.5401\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5727 - val_loss: 1.5195\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5977 - val_loss: 1.4541\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5533 - val_loss: 1.4668\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6591 - val_loss: 1.4623\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5747 - val_loss: 1.4485\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5285 - val_loss: 1.4989\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5258 - val_loss: 1.5087\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5580 - val_loss: 1.4922\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5359 - val_loss: 1.4302\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5224 - val_loss: 1.4645\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4987 - val_loss: 1.4883\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5082 - val_loss: 1.5020\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4239 - val_loss: 1.5044\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4742 - val_loss: 1.5292\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5357 - val_loss: 1.5368\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4358 - val_loss: 1.5291\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4657 - val_loss: 1.5303\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4663 - val_loss: 1.5008\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4715 - val_loss: 1.5343\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3684 - val_loss: 1.5549\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3891 - val_loss: 1.5784\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3808 - val_loss: 1.5898\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3829 - val_loss: 1.5913\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3851 - val_loss: 1.5855\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3754 - val_loss: 1.5432\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4922 - val_loss: 1.5469\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4355 - val_loss: 1.5716\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4457 - val_loss: 1.7096\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4470 - val_loss: 1.6658\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3991 - val_loss: 1.6102\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3767 - val_loss: 1.6474\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3983 - val_loss: 1.6672\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3802 - val_loss: 1.6906\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4510 - val_loss: 1.7065\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3851 - val_loss: 1.7488\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4086 - val_loss: 1.7129\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4072 - val_loss: 1.7255\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3998 - val_loss: 1.6914\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3093 - val_loss: 1.6856\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 5 gamma= 0\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 2.2725 - val_loss: 1.5889\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9824 - val_loss: 1.6225\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8892 - val_loss: 1.6000\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8371 - val_loss: 1.5712\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7523 - val_loss: 1.5870\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8074 - val_loss: 1.5544\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7096 - val_loss: 1.5675\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6628 - val_loss: 1.5402\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6378 - val_loss: 1.5441\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6736 - val_loss: 1.5570\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6331 - val_loss: 1.5620\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6475 - val_loss: 1.5442\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6468 - val_loss: 1.5310\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6963 - val_loss: 1.5392\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6476 - val_loss: 1.5107\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6459 - val_loss: 1.5065\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5855 - val_loss: 1.5522\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5798 - val_loss: 1.5689\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5958 - val_loss: 1.5753\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5309 - val_loss: 1.5794\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5107 - val_loss: 1.5414\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5227 - val_loss: 1.5652\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5402 - val_loss: 1.5389\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5160 - val_loss: 1.5705\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5611 - val_loss: 1.5368\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4896 - val_loss: 1.5340\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4457 - val_loss: 1.5106\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5390 - val_loss: 1.5173\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4564 - val_loss: 1.5252\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4004 - val_loss: 1.5139\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4829 - val_loss: 1.5355\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4660 - val_loss: 1.5341\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4628 - val_loss: 1.5650\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4634 - val_loss: 1.5733\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4529 - val_loss: 1.5602\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3639 - val_loss: 1.5453\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4352 - val_loss: 1.5298\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3571 - val_loss: 1.5491\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3555 - val_loss: 1.5694\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3314 - val_loss: 1.5491\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3636 - val_loss: 1.5711\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3325 - val_loss: 1.5546\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3170 - val_loss: 1.5689\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2602 - val_loss: 1.5501\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3395 - val_loss: 1.5622\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3642 - val_loss: 1.5356\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 2.1776 - val_loss: 1.8101\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8978 - val_loss: 1.8262\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8533 - val_loss: 1.8213\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7406 - val_loss: 1.8670\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7531 - val_loss: 1.8567\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7941 - val_loss: 1.8614\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7068 - val_loss: 1.8289\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7048 - val_loss: 1.8660\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7665 - val_loss: 1.8733\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6551 - val_loss: 1.8949\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6872 - val_loss: 1.8719\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5960 - val_loss: 1.8775\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7627 - val_loss: 1.9059\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6201 - val_loss: 1.8907\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6371 - val_loss: 1.8867\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5612 - val_loss: 1.9123\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5680 - val_loss: 1.9273\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6209 - val_loss: 1.9064\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6201 - val_loss: 1.8926\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5835 - val_loss: 1.8348\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5148 - val_loss: 1.8600\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5515 - val_loss: 1.8954\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5053 - val_loss: 1.9030\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5342 - val_loss: 1.9122\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5501 - val_loss: 1.9079\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4604 - val_loss: 1.9024\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4748 - val_loss: 1.9033\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5473 - val_loss: 1.9206\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4589 - val_loss: 1.9338\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4564 - val_loss: 1.9387\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4771 - val_loss: 1.9182\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4807 - val_loss: 1.9408\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4287 - val_loss: 1.9418\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4333 - val_loss: 1.9686\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4638 - val_loss: 1.9708\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4426 - val_loss: 1.9691\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4940 - val_loss: 1.9453\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4354 - val_loss: 2.0020\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3868 - val_loss: 2.0064\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3932 - val_loss: 2.0102\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3946 - val_loss: 1.9896\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4292 - val_loss: 2.0101\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3670 - val_loss: 2.0403\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3685 - val_loss: 2.0444\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4021 - val_loss: 2.0422\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3230 - val_loss: 2.0291\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3413 - val_loss: 1.9880\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4100 - val_loss: 1.9984\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3165 - val_loss: 2.0675\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3687 - val_loss: 2.1451\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Real LSTM seed 2 fold 2 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.5090 - val_loss: 1.5149\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0998 - val_loss: 1.4833\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0167 - val_loss: 1.5661\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9207 - val_loss: 1.5778\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7832 - val_loss: 1.5649\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7381 - val_loss: 1.5655\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6897 - val_loss: 1.5508\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6865 - val_loss: 1.5382\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7281 - val_loss: 1.5959\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7156 - val_loss: 1.6003\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7383 - val_loss: 1.5801\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6985 - val_loss: 1.5746\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6518 - val_loss: 1.5758\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6652 - val_loss: 1.5729\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5868 - val_loss: 1.5467\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6449 - val_loss: 1.5804\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5967 - val_loss: 1.5922\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6487 - val_loss: 1.5544\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6174 - val_loss: 1.5544\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5410 - val_loss: 1.6231\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5868 - val_loss: 1.6091\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4831 - val_loss: 1.5702\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5212 - val_loss: 1.5857\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5613 - val_loss: 1.5870\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4505 - val_loss: 1.6039\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5518 - val_loss: 1.5980\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5345 - val_loss: 1.5765\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5225 - val_loss: 1.5969\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4760 - val_loss: 1.6057\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4585 - val_loss: 1.6082\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3978 - val_loss: 1.5839\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3842 - val_loss: 1.5853\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4720 - val_loss: 1.5738\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4561 - val_loss: 1.6007\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3997 - val_loss: 1.6001\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3811 - val_loss: 1.5925\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3912 - val_loss: 1.5964\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4110 - val_loss: 1.5991\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3425 - val_loss: 1.5516\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3550 - val_loss: 1.5884\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3928 - val_loss: 1.5899\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3418 - val_loss: 1.5958\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2865 - val_loss: 1.6128\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3458 - val_loss: 1.6514\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3288 - val_loss: 1.5873\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.3244 - val_loss: 1.6855\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9391 - val_loss: 1.6584\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8327 - val_loss: 1.6809\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8153 - val_loss: 1.6418\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7000 - val_loss: 1.6145\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7337 - val_loss: 1.6122\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7025 - val_loss: 1.6138\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6250 - val_loss: 1.6419\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6707 - val_loss: 1.6614\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5791 - val_loss: 1.6966\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6751 - val_loss: 1.6900\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6281 - val_loss: 1.6972\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5970 - val_loss: 1.6918\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5271 - val_loss: 1.7039\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6594 - val_loss: 1.6922\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5451 - val_loss: 1.6887\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5937 - val_loss: 1.6810\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5789 - val_loss: 1.6728\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4853 - val_loss: 1.6035\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5129 - val_loss: 1.6187\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6290 - val_loss: 1.6467\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5682 - val_loss: 1.6612\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5197 - val_loss: 1.6698\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5771 - val_loss: 1.6802\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5153 - val_loss: 1.6654\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6297 - val_loss: 1.6744\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4831 - val_loss: 1.6670\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5233 - val_loss: 1.6656\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4868 - val_loss: 1.6517\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4758 - val_loss: 1.7229\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4831 - val_loss: 1.7311\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5248 - val_loss: 1.7260\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4147 - val_loss: 1.7320\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4394 - val_loss: 1.7455\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4311 - val_loss: 1.7641\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3791 - val_loss: 1.7854\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4120 - val_loss: 1.7870\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4467 - val_loss: 1.7952\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4314 - val_loss: 1.8203\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4280 - val_loss: 1.8124\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4078 - val_loss: 1.7957\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4007 - val_loss: 1.7881\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3519 - val_loss: 1.7922\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3753 - val_loss: 1.8001\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4530 - val_loss: 1.8097\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3974 - val_loss: 1.8093\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3595 - val_loss: 1.8067\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4069 - val_loss: 1.7686\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3391 - val_loss: 1.7623\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.1639 - val_loss: 1.5129\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8229 - val_loss: 1.5264\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7718 - val_loss: 1.5480\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7056 - val_loss: 1.5445\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8242 - val_loss: 1.5282\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8064 - val_loss: 1.5388\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7005 - val_loss: 1.5568\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6820 - val_loss: 1.5573\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6019 - val_loss: 1.5824\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5909 - val_loss: 1.5740\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6417 - val_loss: 1.5251\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6252 - val_loss: 1.5531\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6130 - val_loss: 1.5535\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5617 - val_loss: 1.6112\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5840 - val_loss: 1.5872\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5426 - val_loss: 1.6155\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5635 - val_loss: 1.6148\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5076 - val_loss: 1.6150\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5352 - val_loss: 1.6159\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4970 - val_loss: 1.6296\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5456 - val_loss: 1.6609\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4511 - val_loss: 1.6848\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5039 - val_loss: 1.6822\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4781 - val_loss: 1.6827\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4637 - val_loss: 1.6442\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5436 - val_loss: 1.6654\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4771 - val_loss: 1.6397\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4009 - val_loss: 1.6243\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4521 - val_loss: 1.5611\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3812 - val_loss: 1.5593\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4248 - val_loss: 1.5573\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3452 - val_loss: 1.5755\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3836 - val_loss: 1.5923\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3409 - val_loss: 1.6672\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3761 - val_loss: 1.6490\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3301 - val_loss: 1.6551\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3850 - val_loss: 1.6516\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3801 - val_loss: 1.6399\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3425 - val_loss: 1.6380\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3359 - val_loss: 1.6504\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3249 - val_loss: 1.6642\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Real LSTM seed 2 fold 5 gamma= 1\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.2478 - val_loss: 1.5991\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9884 - val_loss: 1.5748\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9385 - val_loss: 1.5740\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8303 - val_loss: 1.5963\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7621 - val_loss: 1.6187\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7006 - val_loss: 1.6195\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7586 - val_loss: 1.5854\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7744 - val_loss: 1.5922\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7280 - val_loss: 1.5631\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7106 - val_loss: 1.5642\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6405 - val_loss: 1.5518\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5982 - val_loss: 1.6006\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6134 - val_loss: 1.6067\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6233 - val_loss: 1.6093\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5812 - val_loss: 1.6181\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6285 - val_loss: 1.6290\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5381 - val_loss: 1.5978\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6076 - val_loss: 1.5995\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4815 - val_loss: 1.6076\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4668 - val_loss: 1.6103\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5398 - val_loss: 1.6039\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6463 - val_loss: 1.6092\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5365 - val_loss: 1.6419\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5107 - val_loss: 1.6294\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4962 - val_loss: 1.6666\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5574 - val_loss: 1.6490\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4663 - val_loss: 1.6549\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4611 - val_loss: 1.6501\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4368 - val_loss: 1.6520\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4294 - val_loss: 1.6263\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4003 - val_loss: 1.6223\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4399 - val_loss: 1.6199\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4035 - val_loss: 1.6719\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3973 - val_loss: 1.6373\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3614 - val_loss: 1.6406\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4316 - val_loss: 1.6481\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3511 - val_loss: 1.6333\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4035 - val_loss: 1.6365\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3858 - val_loss: 1.6584\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3201 - val_loss: 1.6711\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3286 - val_loss: 1.6622\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.5263 - val_loss: 1.9431\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9573 - val_loss: 1.8440\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8145 - val_loss: 1.8338\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9092 - val_loss: 1.8320\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7649 - val_loss: 1.8365\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7205 - val_loss: 1.8481\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6452 - val_loss: 1.8332\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6030 - val_loss: 1.8404\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6473 - val_loss: 1.8459\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6116 - val_loss: 1.8447\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5665 - val_loss: 1.7954\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5690 - val_loss: 1.8051\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6569 - val_loss: 1.8268\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6264 - val_loss: 1.8373\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5101 - val_loss: 1.8822\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4842 - val_loss: 1.9040\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5665 - val_loss: 1.9061\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5255 - val_loss: 1.9523\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5593 - val_loss: 1.9541\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6223 - val_loss: 1.9423\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5317 - val_loss: 1.9545\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4953 - val_loss: 1.9441\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5472 - val_loss: 1.9612\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4050 - val_loss: 1.9852\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5140 - val_loss: 2.0148\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4136 - val_loss: 2.0129\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4131 - val_loss: 2.0428\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4260 - val_loss: 2.0460\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4239 - val_loss: 2.0500\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4077 - val_loss: 2.0472\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3462 - val_loss: 2.0761\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3819 - val_loss: 2.0844\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4417 - val_loss: 2.1162\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4064 - val_loss: 2.0628\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3191 - val_loss: 2.0526\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3907 - val_loss: 2.0642\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4240 - val_loss: 2.0808\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3209 - val_loss: 2.1100\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3149 - val_loss: 2.1183\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3268 - val_loss: 2.1489\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3079 - val_loss: 2.1665\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 2 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 2.2253 - val_loss: 1.5652\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8983 - val_loss: 1.5292\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8564 - val_loss: 1.5404\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8319 - val_loss: 1.6164\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8070 - val_loss: 1.6362\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7318 - val_loss: 1.6231\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6811 - val_loss: 1.6292\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6968 - val_loss: 1.6492\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6121 - val_loss: 1.6089\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6645 - val_loss: 1.5760\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5513 - val_loss: 1.5609\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6715 - val_loss: 1.5468\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5648 - val_loss: 1.5696\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6119 - val_loss: 1.5811\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5597 - val_loss: 1.5923\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5718 - val_loss: 1.5875\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5384 - val_loss: 1.6253\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5352 - val_loss: 1.6176\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5647 - val_loss: 1.6203\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4680 - val_loss: 1.6338\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4886 - val_loss: 1.5951\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4603 - val_loss: 1.5922\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4691 - val_loss: 1.5990\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4288 - val_loss: 1.5955\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4992 - val_loss: 1.5763\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4728 - val_loss: 1.5485\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4549 - val_loss: 1.5503\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3735 - val_loss: 1.5536\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4587 - val_loss: 1.5363\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4557 - val_loss: 1.5352\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4410 - val_loss: 1.5607\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4327 - val_loss: 1.5325\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3802 - val_loss: 1.5696\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3810 - val_loss: 1.5655\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3383 - val_loss: 1.5271\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3570 - val_loss: 1.6199\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4408 - val_loss: 1.6035\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3365 - val_loss: 1.5876\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3147 - val_loss: 1.6126\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3608 - val_loss: 1.5886\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3795 - val_loss: 1.6764\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3930 - val_loss: 1.6481\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2834 - val_loss: 1.5653\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3636 - val_loss: 1.5516\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3697 - val_loss: 1.6057\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2500 - val_loss: 1.5947\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3032 - val_loss: 1.5977\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2590 - val_loss: 1.5806\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2666 - val_loss: 1.6090\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2772 - val_loss: 1.6111\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2776 - val_loss: 1.6341\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2902 - val_loss: 1.7295\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2424 - val_loss: 1.7088\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2684 - val_loss: 1.6857\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2685 - val_loss: 1.6474\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2345 - val_loss: 1.6956\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2088 - val_loss: 1.7420\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2120 - val_loss: 1.7321\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2351 - val_loss: 1.7248\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2512 - val_loss: 1.8087\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1963 - val_loss: 1.8135\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1719 - val_loss: 1.8490\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2335 - val_loss: 1.7703\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1792 - val_loss: 1.7610\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1553 - val_loss: 1.7411\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 2.6775 - val_loss: 1.6700\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1671 - val_loss: 1.6772\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0153 - val_loss: 1.6610\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7779 - val_loss: 1.6399\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8902 - val_loss: 1.6345\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7186 - val_loss: 1.6531\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6394 - val_loss: 1.6808\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7672 - val_loss: 1.6749\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6247 - val_loss: 1.6837\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6581 - val_loss: 1.6806\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7680 - val_loss: 1.6803\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5919 - val_loss: 1.6489\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6463 - val_loss: 1.6683\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7005 - val_loss: 1.6779\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5888 - val_loss: 1.6630\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5826 - val_loss: 1.6755\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6718 - val_loss: 1.7075\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5923 - val_loss: 1.7083\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5385 - val_loss: 1.6789\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5000 - val_loss: 1.6575\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6214 - val_loss: 1.6557\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5568 - val_loss: 1.6845\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5494 - val_loss: 1.7060\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5282 - val_loss: 1.7132\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5476 - val_loss: 1.7193\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4814 - val_loss: 1.7327\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5250 - val_loss: 1.7301\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6108 - val_loss: 1.7403\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4621 - val_loss: 1.7621\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4759 - val_loss: 1.7545\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4675 - val_loss: 1.7517\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4672 - val_loss: 1.7461\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4836 - val_loss: 1.7477\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4010 - val_loss: 1.7640\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4807 - val_loss: 1.7686\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4205 - val_loss: 1.7656\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4470 - val_loss: 1.7602\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4815 - val_loss: 1.7249\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4337 - val_loss: 1.7181\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4231 - val_loss: 1.7414\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4008 - val_loss: 1.7519\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4044 - val_loss: 1.7583\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.4961 - val_loss: 1.5345\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0419 - val_loss: 1.5214\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9142 - val_loss: 1.5074\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8627 - val_loss: 1.5074\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8473 - val_loss: 1.5041\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7841 - val_loss: 1.4916\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6957 - val_loss: 1.5197\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6680 - val_loss: 1.5919\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7603 - val_loss: 1.6054\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6474 - val_loss: 1.5997\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7355 - val_loss: 1.6041\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6545 - val_loss: 1.5736\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7313 - val_loss: 1.5727\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6709 - val_loss: 1.5769\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6696 - val_loss: 1.6187\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6427 - val_loss: 1.6172\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6013 - val_loss: 1.5786\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6376 - val_loss: 1.6041\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5676 - val_loss: 1.6129\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5828 - val_loss: 1.6077\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5866 - val_loss: 1.6028\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5836 - val_loss: 1.5943\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5707 - val_loss: 1.5744\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5642 - val_loss: 1.5778\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5578 - val_loss: 1.6047\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6206 - val_loss: 1.6006\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5072 - val_loss: 1.6149\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4799 - val_loss: 1.6030\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5128 - val_loss: 1.5944\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5067 - val_loss: 1.6098\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5874 - val_loss: 1.6043\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5224 - val_loss: 1.6080\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5698 - val_loss: 1.6012\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5578 - val_loss: 1.5877\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5088 - val_loss: 1.5790\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4895 - val_loss: 1.5835\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5224 - val_loss: 1.5905\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4769 - val_loss: 1.5979\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4719 - val_loss: 1.5774\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4657 - val_loss: 1.5800\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4429 - val_loss: 1.5998\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4622 - val_loss: 1.5831\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4900 - val_loss: 1.5892\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 5 gamma= 2\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.3538 - val_loss: 1.6285\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9975 - val_loss: 1.6180\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9665 - val_loss: 1.5994\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8101 - val_loss: 1.5749\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8269 - val_loss: 1.5951\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8552 - val_loss: 1.6229\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7747 - val_loss: 1.5851\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7257 - val_loss: 1.5866\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7108 - val_loss: 1.5834\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6577 - val_loss: 1.5984\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6404 - val_loss: 1.6136\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5771 - val_loss: 1.6130\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6617 - val_loss: 1.5996\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6169 - val_loss: 1.5975\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6504 - val_loss: 1.5607\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6277 - val_loss: 1.5616\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5885 - val_loss: 1.5525\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5634 - val_loss: 1.5447\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5764 - val_loss: 1.5720\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5735 - val_loss: 1.6235\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5407 - val_loss: 1.6290\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4622 - val_loss: 1.6253\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5708 - val_loss: 1.6427\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4624 - val_loss: 1.6491\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4942 - val_loss: 1.6667\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5192 - val_loss: 1.6521\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5069 - val_loss: 1.6463\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4570 - val_loss: 1.6585\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4475 - val_loss: 1.6387\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4126 - val_loss: 1.6408\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3933 - val_loss: 1.6562\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3919 - val_loss: 1.6713\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3976 - val_loss: 1.6944\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3069 - val_loss: 1.7071\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3485 - val_loss: 1.7172\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3843 - val_loss: 1.7264\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3267 - val_loss: 1.7191\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3087 - val_loss: 1.7252\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2880 - val_loss: 1.7312\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2948 - val_loss: 1.7211\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2538 - val_loss: 1.7302\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2190 - val_loss: 1.7289\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2781 - val_loss: 1.6881\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3090 - val_loss: 1.6911\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2130 - val_loss: 1.6651\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2172 - val_loss: 1.7031\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1896 - val_loss: 1.7134\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1586 - val_loss: 1.7485\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.1827 - val_loss: 1.7833\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9289 - val_loss: 1.7047\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8405 - val_loss: 1.7646\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7137 - val_loss: 1.7877\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8215 - val_loss: 1.8336\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8298 - val_loss: 1.8011\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6951 - val_loss: 1.8315\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7707 - val_loss: 1.8252\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7849 - val_loss: 1.8096\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6089 - val_loss: 1.8160\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6250 - val_loss: 1.8233\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6749 - val_loss: 1.8413\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7492 - val_loss: 1.8611\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6672 - val_loss: 1.9192\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6608 - val_loss: 1.9758\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7002 - val_loss: 1.9807\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6437 - val_loss: 2.0074\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6180 - val_loss: 1.9867\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5434 - val_loss: 1.9996\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6520 - val_loss: 1.9828\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5966 - val_loss: 2.0111\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5562 - val_loss: 2.0094\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5371 - val_loss: 1.9957\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6079 - val_loss: 2.0427\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4423 - val_loss: 2.0290\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5992 - val_loss: 2.0246\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6335 - val_loss: 2.0274\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5352 - val_loss: 1.9744\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5334 - val_loss: 1.9352\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4787 - val_loss: 1.9472\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5325 - val_loss: 1.9440\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4911 - val_loss: 1.9946\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5415 - val_loss: 1.9998\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4800 - val_loss: 2.0284\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5206 - val_loss: 2.0739\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5859 - val_loss: 2.0904\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5208 - val_loss: 2.1041\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4504 - val_loss: 2.0945\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5323 - val_loss: 2.0702\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5400 - val_loss: 2.0716\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4500 - val_loss: 2.0101\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 2 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.2822 - val_loss: 1.6340\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0339 - val_loss: 1.6199\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9259 - val_loss: 1.6146\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8051 - val_loss: 1.6392\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8238 - val_loss: 1.6285\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8410 - val_loss: 1.6430\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7833 - val_loss: 1.6009\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7520 - val_loss: 1.6076\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7303 - val_loss: 1.6337\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7243 - val_loss: 1.6343\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7148 - val_loss: 1.6385\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7714 - val_loss: 1.6577\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7859 - val_loss: 1.6472\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6035 - val_loss: 1.6273\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6767 - val_loss: 1.5618\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6148 - val_loss: 1.5820\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6513 - val_loss: 1.5891\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6155 - val_loss: 1.5729\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6229 - val_loss: 1.5305\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5952 - val_loss: 1.5436\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5894 - val_loss: 1.5685\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5237 - val_loss: 1.6040\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5466 - val_loss: 1.6091\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5958 - val_loss: 1.5694\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5275 - val_loss: 1.5422\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6045 - val_loss: 1.5439\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5004 - val_loss: 1.5517\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5170 - val_loss: 1.5617\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4971 - val_loss: 1.6269\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5663 - val_loss: 1.6493\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5279 - val_loss: 1.6396\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5403 - val_loss: 1.6056\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4613 - val_loss: 1.5671\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4909 - val_loss: 1.5627\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4320 - val_loss: 1.5358\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4190 - val_loss: 1.5337\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4511 - val_loss: 1.5245\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4377 - val_loss: 1.5247\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4386 - val_loss: 1.5251\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3745 - val_loss: 1.5341\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4453 - val_loss: 1.5357\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4060 - val_loss: 1.5333\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4130 - val_loss: 1.5468\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3272 - val_loss: 1.5745\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4099 - val_loss: 1.5621\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3423 - val_loss: 1.5507\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3351 - val_loss: 1.5443\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3464 - val_loss: 1.5522\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3671 - val_loss: 1.5651\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2974 - val_loss: 1.5586\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3259 - val_loss: 1.5512\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3056 - val_loss: 1.5537\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2740 - val_loss: 1.5551\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3095 - val_loss: 1.5589\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2721 - val_loss: 1.5654\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2733 - val_loss: 1.5563\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2368 - val_loss: 1.5750\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2687 - val_loss: 1.5618\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2384 - val_loss: 1.5874\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2301 - val_loss: 1.5817\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2775 - val_loss: 1.5788\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2061 - val_loss: 1.6263\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2363 - val_loss: 1.6066\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2754 - val_loss: 1.5863\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2517 - val_loss: 1.5945\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1747 - val_loss: 1.6304\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1929 - val_loss: 1.5847\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.6703 - val_loss: 1.6299\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0862 - val_loss: 1.6227\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8548 - val_loss: 1.6158\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9381 - val_loss: 1.6155\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8279 - val_loss: 1.5990\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7151 - val_loss: 1.6061\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7571 - val_loss: 1.6255\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7660 - val_loss: 1.6193\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7169 - val_loss: 1.6048\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7200 - val_loss: 1.6206\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7087 - val_loss: 1.6431\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6657 - val_loss: 1.6267\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6970 - val_loss: 1.6592\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6666 - val_loss: 1.6679\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6226 - val_loss: 1.6642\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5888 - val_loss: 1.6699\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6327 - val_loss: 1.6566\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5862 - val_loss: 1.6582\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5892 - val_loss: 1.6689\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5317 - val_loss: 1.6619\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5624 - val_loss: 1.6661\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4951 - val_loss: 1.6889\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5983 - val_loss: 1.6789\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5681 - val_loss: 1.6792\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5661 - val_loss: 1.6820\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5285 - val_loss: 1.6731\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5601 - val_loss: 1.6239\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5562 - val_loss: 1.5956\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4931 - val_loss: 1.5935\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4082 - val_loss: 1.5944\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4901 - val_loss: 1.5991\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5538 - val_loss: 1.6091\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4919 - val_loss: 1.6019\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4837 - val_loss: 1.5995\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4640 - val_loss: 1.5880\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5080 - val_loss: 1.5875\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4764 - val_loss: 1.5929\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5106 - val_loss: 1.5861\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4576 - val_loss: 1.5854\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3756 - val_loss: 1.5979\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4102 - val_loss: 1.5955\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3895 - val_loss: 1.5916\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4857 - val_loss: 1.6118\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4552 - val_loss: 1.5915\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4424 - val_loss: 1.5926\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3094 - val_loss: 1.6039\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3590 - val_loss: 1.5982\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3890 - val_loss: 1.6249\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3372 - val_loss: 1.6192\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3551 - val_loss: 1.5885\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3819 - val_loss: 1.6040\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3777 - val_loss: 1.6090\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3369 - val_loss: 1.6350\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3463 - val_loss: 1.6116\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3274 - val_loss: 1.6314\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3858 - val_loss: 1.5892\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3397 - val_loss: 1.5939\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3473 - val_loss: 1.6061\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3217 - val_loss: 1.6192\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2822 - val_loss: 1.6318\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2736 - val_loss: 1.6469\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3437 - val_loss: 1.6774\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2254 - val_loss: 1.6609\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2680 - val_loss: 1.6636\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2969 - val_loss: 1.6948\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2147 - val_loss: 1.6822\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2246 - val_loss: 1.6508\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2421 - val_loss: 1.7748\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2926 - val_loss: 1.7726\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 2.4643 - val_loss: 1.4788\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0902 - val_loss: 1.4902\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8599 - val_loss: 1.5292\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8589 - val_loss: 1.5145\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7164 - val_loss: 1.4962\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7608 - val_loss: 1.4939\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6968 - val_loss: 1.4633\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7537 - val_loss: 1.4975\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7309 - val_loss: 1.5129\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6828 - val_loss: 1.5114\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6970 - val_loss: 1.5073\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7497 - val_loss: 1.4952\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7727 - val_loss: 1.4965\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6983 - val_loss: 1.4982\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7428 - val_loss: 1.5083\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6976 - val_loss: 1.5347\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5875 - val_loss: 1.5408\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6351 - val_loss: 1.5627\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5642 - val_loss: 1.5789\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5704 - val_loss: 1.5840\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6086 - val_loss: 1.6863\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6372 - val_loss: 1.6169\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5716 - val_loss: 1.6040\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5548 - val_loss: 1.6033\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5885 - val_loss: 1.5959\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5458 - val_loss: 1.6254\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5769 - val_loss: 1.6432\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6076 - val_loss: 1.6505\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6088 - val_loss: 1.5886\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5187 - val_loss: 1.5713\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4808 - val_loss: 1.6422\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5576 - val_loss: 1.6882\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5000 - val_loss: 1.6846\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5157 - val_loss: 1.6700\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4907 - val_loss: 1.6690\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4991 - val_loss: 1.7075\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5095 - val_loss: 1.6840\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4966 - val_loss: 1.6742\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4789 - val_loss: 1.6787\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4640 - val_loss: 1.6706\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4761 - val_loss: 1.6749\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4715 - val_loss: 1.6862\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 5 gamma= 3\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.2800 - val_loss: 1.5794\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8167 - val_loss: 1.5535\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8596 - val_loss: 1.5616\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8152 - val_loss: 1.5664\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7256 - val_loss: 1.5866\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6990 - val_loss: 1.5786\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6965 - val_loss: 1.5872\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6349 - val_loss: 1.5962\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6222 - val_loss: 1.5838\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6067 - val_loss: 1.5736\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6810 - val_loss: 1.5798\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5926 - val_loss: 1.5913\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5288 - val_loss: 1.5884\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5817 - val_loss: 1.5892\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4804 - val_loss: 1.6099\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4919 - val_loss: 1.6055\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4801 - val_loss: 1.6434\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4755 - val_loss: 1.6297\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5018 - val_loss: 1.6168\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5493 - val_loss: 1.6150\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5247 - val_loss: 1.6586\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4528 - val_loss: 1.6327\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5321 - val_loss: 1.5936\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3853 - val_loss: 1.5847\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4024 - val_loss: 1.6288\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3566 - val_loss: 1.6186\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4196 - val_loss: 1.6690\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3659 - val_loss: 1.6892\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4020 - val_loss: 1.6343\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3783 - val_loss: 1.5917\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3529 - val_loss: 1.6346\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3723 - val_loss: 1.6689\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2987 - val_loss: 1.6533\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3783 - val_loss: 1.6610\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3193 - val_loss: 1.6447\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2952 - val_loss: 1.6547\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2448 - val_loss: 1.6652\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2295 - val_loss: 1.6753\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2575 - val_loss: 1.6691\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2065 - val_loss: 1.6590\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1953 - val_loss: 1.6318\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.3981 - val_loss: 1.7244\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9168 - val_loss: 1.7444\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9464 - val_loss: 1.7401\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8822 - val_loss: 1.7280\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7575 - val_loss: 1.7509\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6858 - val_loss: 1.8158\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7260 - val_loss: 1.8488\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7267 - val_loss: 1.8755\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7337 - val_loss: 1.8723\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7497 - val_loss: 1.9079\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6444 - val_loss: 1.9101\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5895 - val_loss: 1.8830\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7324 - val_loss: 1.8914\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5930 - val_loss: 1.9088\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5992 - val_loss: 1.9399\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5791 - val_loss: 1.9172\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5382 - val_loss: 1.9587\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6741 - val_loss: 1.9881\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5718 - val_loss: 2.0104\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5365 - val_loss: 2.0001\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5354 - val_loss: 1.9956\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5291 - val_loss: 2.0015\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6028 - val_loss: 1.9553\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5745 - val_loss: 1.9863\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5334 - val_loss: 2.0250\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4871 - val_loss: 2.0301\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4733 - val_loss: 2.0487\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4523 - val_loss: 2.0752\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4571 - val_loss: 2.1283\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5073 - val_loss: 2.1345\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4851 - val_loss: 2.1337\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4742 - val_loss: 2.1411\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4806 - val_loss: 2.1533\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4345 - val_loss: 2.1599\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4185 - val_loss: 2.1859\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4750 - val_loss: 2.1499\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4058 - val_loss: 2.1999\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3788 - val_loss: 2.1709\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4094 - val_loss: 2.1779\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4162 - val_loss: 2.1859\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3769 - val_loss: 2.1978\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3809 - val_loss: 2.1979\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 2 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.3543 - val_loss: 1.5937\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9416 - val_loss: 1.6368\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8881 - val_loss: 1.6784\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8659 - val_loss: 1.6587\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7569 - val_loss: 1.6366\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7175 - val_loss: 1.6685\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6632 - val_loss: 1.6733\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7015 - val_loss: 1.6671\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6305 - val_loss: 1.6245\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6969 - val_loss: 1.6218\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6932 - val_loss: 1.6310\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6471 - val_loss: 1.6510\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5893 - val_loss: 1.6789\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5897 - val_loss: 1.6957\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5181 - val_loss: 1.6637\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5631 - val_loss: 1.6445\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5633 - val_loss: 1.6785\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5579 - val_loss: 1.7037\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4970 - val_loss: 1.6602\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5088 - val_loss: 1.6506\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6077 - val_loss: 1.6529\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4864 - val_loss: 1.6404\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5855 - val_loss: 1.6273\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5060 - val_loss: 1.6693\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5424 - val_loss: 1.7036\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5438 - val_loss: 1.7520\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4664 - val_loss: 1.6920\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4660 - val_loss: 1.6600\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4576 - val_loss: 1.6387\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4555 - val_loss: 1.6166\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4968 - val_loss: 1.6188\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4865 - val_loss: 1.6173\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4596 - val_loss: 1.6300\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3982 - val_loss: 1.6320\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4039 - val_loss: 1.6210\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4400 - val_loss: 1.6348\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4113 - val_loss: 1.6450\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4136 - val_loss: 1.6043\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4115 - val_loss: 1.6624\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3982 - val_loss: 1.6695\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4423 - val_loss: 1.6395\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3751 - val_loss: 1.5993\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4041 - val_loss: 1.6007\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4592 - val_loss: 1.6204\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3992 - val_loss: 1.6104\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3925 - val_loss: 1.6005\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3381 - val_loss: 1.5816\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3860 - val_loss: 1.6104\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3239 - val_loss: 1.6270\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3731 - val_loss: 1.6218\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3670 - val_loss: 1.6269\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2955 - val_loss: 1.6298\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3227 - val_loss: 1.5887\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2850 - val_loss: 1.5972\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2798 - val_loss: 1.5892\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3300 - val_loss: 1.6067\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2884 - val_loss: 1.6153\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2502 - val_loss: 1.6245\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2922 - val_loss: 1.6097\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2439 - val_loss: 1.5995\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2633 - val_loss: 1.6150\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2514 - val_loss: 1.6526\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2840 - val_loss: 1.6178\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3106 - val_loss: 1.6277\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2499 - val_loss: 1.6271\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1851 - val_loss: 1.6420\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1998 - val_loss: 1.6796\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1865 - val_loss: 1.6857\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2110 - val_loss: 1.7078\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2788 - val_loss: 1.6773\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1873 - val_loss: 1.6656\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2086 - val_loss: 1.7051\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2118 - val_loss: 1.6874\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1558 - val_loss: 1.6976\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1732 - val_loss: 1.6337\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1839 - val_loss: 1.6886\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1904 - val_loss: 1.6308\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.2189 - val_loss: 1.6066\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8383 - val_loss: 1.6217\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9252 - val_loss: 1.6422\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8484 - val_loss: 1.6236\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7421 - val_loss: 1.6374\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7125 - val_loss: 1.6517\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6849 - val_loss: 1.6547\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7114 - val_loss: 1.6642\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7321 - val_loss: 1.6773\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6893 - val_loss: 1.6732\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7676 - val_loss: 1.6690\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6844 - val_loss: 1.6692\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6911 - val_loss: 1.6843\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6822 - val_loss: 1.7024\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6753 - val_loss: 1.6998\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6098 - val_loss: 1.7038\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6407 - val_loss: 1.7294\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6577 - val_loss: 1.7489\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5624 - val_loss: 1.7487\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5938 - val_loss: 1.7137\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7191 - val_loss: 1.7024\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6446 - val_loss: 1.7123\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5863 - val_loss: 1.7037\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6162 - val_loss: 1.7255\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5687 - val_loss: 1.7355\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5877 - val_loss: 1.7334\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5627 - val_loss: 1.7318\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6331 - val_loss: 1.7241\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6057 - val_loss: 1.7229\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5365 - val_loss: 1.7060\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5402 - val_loss: 1.7125\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5943 - val_loss: 1.7337\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5756 - val_loss: 1.7495\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5078 - val_loss: 1.7309\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5641 - val_loss: 1.7160\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5194 - val_loss: 1.7426\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5357 - val_loss: 1.7372\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4857 - val_loss: 1.7401\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5409 - val_loss: 1.7462\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4778 - val_loss: 1.7472\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5363 - val_loss: 1.7266\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.6793 - val_loss: 1.4957\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1713 - val_loss: 1.4949\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0155 - val_loss: 1.4686\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9004 - val_loss: 1.4642\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9617 - val_loss: 1.5078\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8948 - val_loss: 1.5124\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9715 - val_loss: 1.5064\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7057 - val_loss: 1.4812\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8016 - val_loss: 1.4944\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7784 - val_loss: 1.5034\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7615 - val_loss: 1.5008\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7998 - val_loss: 1.5248\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6877 - val_loss: 1.5153\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7618 - val_loss: 1.6158\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7163 - val_loss: 1.6173\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7316 - val_loss: 1.6143\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6358 - val_loss: 1.6185\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7265 - val_loss: 1.6208\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6649 - val_loss: 1.6165\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6778 - val_loss: 1.6270\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6058 - val_loss: 1.6607\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5858 - val_loss: 1.6603\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6026 - val_loss: 1.6767\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6978 - val_loss: 1.6691\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5912 - val_loss: 1.6842\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6560 - val_loss: 1.7050\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6461 - val_loss: 1.7045\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5994 - val_loss: 1.6348\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5114 - val_loss: 1.6339\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4940 - val_loss: 1.7134\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5358 - val_loss: 1.7129\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5876 - val_loss: 1.7114\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5569 - val_loss: 1.7183\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5568 - val_loss: 1.7033\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5492 - val_loss: 1.7414\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5632 - val_loss: 1.7261\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5502 - val_loss: 1.7325\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5229 - val_loss: 1.7412\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5340 - val_loss: 1.7277\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5677 - val_loss: 1.7116\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5187 - val_loss: 1.6643\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 2 fold 5 gamma= 4\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 2.0577 - val_loss: 1.6321\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8127 - val_loss: 1.6316\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7820 - val_loss: 1.6069\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7853 - val_loss: 1.6299\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6713 - val_loss: 1.6277\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7054 - val_loss: 1.5876\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6856 - val_loss: 1.5957\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7778 - val_loss: 1.5973\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6450 - val_loss: 1.6069\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6033 - val_loss: 1.6042\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5998 - val_loss: 1.6121\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6459 - val_loss: 1.6201\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5780 - val_loss: 1.6336\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5224 - val_loss: 1.6271\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5336 - val_loss: 1.6066\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4879 - val_loss: 1.6265\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5236 - val_loss: 1.6282\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4919 - val_loss: 1.6245\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5243 - val_loss: 1.6300\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4926 - val_loss: 1.6439\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4764 - val_loss: 1.6365\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4813 - val_loss: 1.6466\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4423 - val_loss: 1.6564\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4752 - val_loss: 1.6526\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3744 - val_loss: 1.6476\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3746 - val_loss: 1.6928\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3324 - val_loss: 1.6419\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3888 - val_loss: 1.6315\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3016 - val_loss: 1.6027\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2901 - val_loss: 1.5851\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3479 - val_loss: 1.6033\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3206 - val_loss: 1.5862\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3421 - val_loss: 1.5981\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3828 - val_loss: 1.6227\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3516 - val_loss: 1.6376\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3220 - val_loss: 1.6356\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2490 - val_loss: 1.6368\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2561 - val_loss: 1.6411\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2245 - val_loss: 1.6743\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2314 - val_loss: 1.6704\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2786 - val_loss: 1.6778\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2427 - val_loss: 1.6373\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1744 - val_loss: 1.6377\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2126 - val_loss: 1.7166\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1513 - val_loss: 1.6906\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1688 - val_loss: 1.7723\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1515 - val_loss: 1.8379\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1849 - val_loss: 1.7691\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1436 - val_loss: 1.7351\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1424 - val_loss: 1.7261\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1066 - val_loss: 1.6605\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1316 - val_loss: 1.7507\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0950 - val_loss: 1.7880\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1189 - val_loss: 1.7543\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1010 - val_loss: 1.7545\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0681 - val_loss: 1.8245\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0873 - val_loss: 1.7763\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0523 - val_loss: 1.8923\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0716 - val_loss: 1.8999\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0848 - val_loss: 1.9023\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.6543 - val_loss: 1.5030\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0858 - val_loss: 1.5176\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9193 - val_loss: 1.4726\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8874 - val_loss: 1.5313\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7959 - val_loss: 1.5253\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7369 - val_loss: 1.5302\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8502 - val_loss: 1.5262\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8120 - val_loss: 1.5323\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7321 - val_loss: 1.5446\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7002 - val_loss: 1.5647\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6807 - val_loss: 1.5317\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6579 - val_loss: 1.5287\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6909 - val_loss: 1.5306\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6089 - val_loss: 1.5366\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6083 - val_loss: 1.5312\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5884 - val_loss: 1.5028\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6142 - val_loss: 1.4799\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6447 - val_loss: 1.4844\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6493 - val_loss: 1.4719\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5490 - val_loss: 1.5138\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5345 - val_loss: 1.5441\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6006 - val_loss: 1.5451\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6076 - val_loss: 1.5621\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5776 - val_loss: 1.5285\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5004 - val_loss: 1.5188\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6019 - val_loss: 1.5137\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4910 - val_loss: 1.5133\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4938 - val_loss: 1.5159\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5135 - val_loss: 1.5294\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5202 - val_loss: 1.5223\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4976 - val_loss: 1.5083\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3983 - val_loss: 1.4936\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4753 - val_loss: 1.4752\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4590 - val_loss: 1.5018\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4382 - val_loss: 1.4822\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3905 - val_loss: 1.5010\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4698 - val_loss: 1.5440\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4614 - val_loss: 1.5745\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4326 - val_loss: 1.5450\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3640 - val_loss: 1.5589\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4229 - val_loss: 1.5581\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3959 - val_loss: 1.5373\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4145 - val_loss: 1.5244\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4453 - val_loss: 1.5316\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3924 - val_loss: 1.5371\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3481 - val_loss: 1.5587\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3494 - val_loss: 1.5769\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3161 - val_loss: 1.6182\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3357 - val_loss: 1.5894\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 2.0307 - val_loss: 1.3758\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7238 - val_loss: 1.3651\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7121 - val_loss: 1.3500\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6461 - val_loss: 1.3748\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6174 - val_loss: 1.3502\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5689 - val_loss: 1.3598\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5781 - val_loss: 1.3586\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5949 - val_loss: 1.3723\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5675 - val_loss: 1.3529\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5148 - val_loss: 1.3677\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5400 - val_loss: 1.3619\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5214 - val_loss: 1.3704\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5064 - val_loss: 1.3612\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4637 - val_loss: 1.3708\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4639 - val_loss: 1.3847\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4563 - val_loss: 1.4100\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5021 - val_loss: 1.4394\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4482 - val_loss: 1.4410\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4415 - val_loss: 1.4232\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5139 - val_loss: 1.4317\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4413 - val_loss: 1.4318\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4774 - val_loss: 1.4289\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4127 - val_loss: 1.4346\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4199 - val_loss: 1.4496\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4462 - val_loss: 1.4341\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3893 - val_loss: 1.4124\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3649 - val_loss: 1.4050\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3650 - val_loss: 1.4112\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3505 - val_loss: 1.3950\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3074 - val_loss: 1.4210\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3009 - val_loss: 1.4621\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3729 - val_loss: 1.4362\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3232 - val_loss: 1.4368\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3689 - val_loss: 1.4352\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2944 - val_loss: 1.4651\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3052 - val_loss: 1.4862\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2904 - val_loss: 1.5240\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2729 - val_loss: 1.5057\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2850 - val_loss: 1.4671\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3220 - val_loss: 1.4863\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2344 - val_loss: 1.5083\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2195 - val_loss: 1.5001\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1897 - val_loss: 1.5017\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Real LSTM seed 3 fold 3 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 2.2890 - val_loss: 1.4872\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8866 - val_loss: 1.4911\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8384 - val_loss: 1.4814\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8677 - val_loss: 1.4877\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7736 - val_loss: 1.4882\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7130 - val_loss: 1.5141\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7702 - val_loss: 1.5124\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7664 - val_loss: 1.5055\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6381 - val_loss: 1.5024\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6060 - val_loss: 1.5070\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5720 - val_loss: 1.5098\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6395 - val_loss: 1.4813\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6250 - val_loss: 1.5237\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5795 - val_loss: 1.5035\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5139 - val_loss: 1.5519\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6595 - val_loss: 1.5584\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6187 - val_loss: 1.5627\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6343 - val_loss: 1.5308\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5226 - val_loss: 1.5212\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5767 - val_loss: 1.5228\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5198 - val_loss: 1.5103\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5268 - val_loss: 1.5240\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6024 - val_loss: 1.5704\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5469 - val_loss: 1.5400\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5568 - val_loss: 1.5366\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5686 - val_loss: 1.5239\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4976 - val_loss: 1.5369\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4934 - val_loss: 1.5465\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5006 - val_loss: 1.5470\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4333 - val_loss: 1.5589\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4694 - val_loss: 1.5545\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4448 - val_loss: 1.5564\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3986 - val_loss: 1.5705\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4452 - val_loss: 1.5701\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4031 - val_loss: 1.5978\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4471 - val_loss: 1.5522\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4142 - val_loss: 1.5938\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4178 - val_loss: 1.5716\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4306 - val_loss: 1.6126\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3851 - val_loss: 1.6037\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3805 - val_loss: 1.5935\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4432 - val_loss: 1.5714\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Real LSTM seed 3 fold 4 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 2.1349 - val_loss: 1.4169\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9793 - val_loss: 1.4425\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9181 - val_loss: 1.4823\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9355 - val_loss: 1.3958\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8345 - val_loss: 1.4069\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8466 - val_loss: 1.4961\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8289 - val_loss: 1.4408\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7654 - val_loss: 1.4437\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7626 - val_loss: 1.4059\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7231 - val_loss: 1.3906\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6819 - val_loss: 1.3647\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7221 - val_loss: 1.3534\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7788 - val_loss: 1.3457\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7248 - val_loss: 1.3267\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6713 - val_loss: 1.3131\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6937 - val_loss: 1.3231\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6651 - val_loss: 1.3232\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6320 - val_loss: 1.2912\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6070 - val_loss: 1.2882\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6494 - val_loss: 1.2876\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5422 - val_loss: 1.3115\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5554 - val_loss: 1.3653\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5748 - val_loss: 1.3547\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6187 - val_loss: 1.3781\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5365 - val_loss: 1.3848\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5444 - val_loss: 1.4007\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5497 - val_loss: 1.4006\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5322 - val_loss: 1.3832\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5836 - val_loss: 1.3620\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5262 - val_loss: 1.3563\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5070 - val_loss: 1.3767\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5073 - val_loss: 1.3747\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5994 - val_loss: 1.3810\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4550 - val_loss: 1.3629\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4899 - val_loss: 1.3519\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4894 - val_loss: 1.3807\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5033 - val_loss: 1.3644\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4135 - val_loss: 1.3781\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5220 - val_loss: 1.3922\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4693 - val_loss: 1.3778\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4792 - val_loss: 1.3926\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4127 - val_loss: 1.4004\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5054 - val_loss: 1.3979\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4035 - val_loss: 1.3765\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4172 - val_loss: 1.3732\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4057 - val_loss: 1.3825\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4077 - val_loss: 1.3807\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4812 - val_loss: 1.3859\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4893 - val_loss: 1.3997\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4065 - val_loss: 1.4246\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 5 gamma= 0\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 2.6721 - val_loss: 1.5687\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1778 - val_loss: 1.5557\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0439 - val_loss: 1.5813\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8518 - val_loss: 1.5171\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8363 - val_loss: 1.5400\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8129 - val_loss: 1.5445\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7977 - val_loss: 1.6108\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7085 - val_loss: 1.6127\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7442 - val_loss: 1.5658\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6835 - val_loss: 1.5911\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8064 - val_loss: 1.6135\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6616 - val_loss: 1.5715\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6859 - val_loss: 1.5645\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6930 - val_loss: 1.6459\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7582 - val_loss: 1.6009\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6678 - val_loss: 1.6104\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6356 - val_loss: 1.6330\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6390 - val_loss: 1.6029\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5580 - val_loss: 1.6930\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5384 - val_loss: 1.7307\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5535 - val_loss: 1.6969\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5298 - val_loss: 1.6875\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5645 - val_loss: 1.6948\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5049 - val_loss: 1.7339\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4843 - val_loss: 1.6819\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4598 - val_loss: 1.7568\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5268 - val_loss: 1.7760\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4646 - val_loss: 1.7402\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4523 - val_loss: 1.7804\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4526 - val_loss: 1.7451\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4660 - val_loss: 1.8016\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4020 - val_loss: 1.7968\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3393 - val_loss: 1.8114\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3650 - val_loss: 1.7793\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4089 - val_loss: 1.7672\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3428 - val_loss: 1.7905\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3044 - val_loss: 1.8852\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3184 - val_loss: 1.9019\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2950 - val_loss: 1.9280\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2999 - val_loss: 1.9573\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2848 - val_loss: 1.9304\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2706 - val_loss: 1.9360\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2596 - val_loss: 1.9441\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.4293 - val_loss: 1.4528\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1332 - val_loss: 1.4626\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9959 - val_loss: 1.4621\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0210 - val_loss: 1.5023\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1068 - val_loss: 1.5067\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9239 - val_loss: 1.5073\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8434 - val_loss: 1.4749\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8709 - val_loss: 1.5037\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8304 - val_loss: 1.4926\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8411 - val_loss: 1.5002\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7638 - val_loss: 1.5201\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6587 - val_loss: 1.5209\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8016 - val_loss: 1.5281\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7405 - val_loss: 1.5446\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7161 - val_loss: 1.5484\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8414 - val_loss: 1.5413\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6658 - val_loss: 1.5486\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7077 - val_loss: 1.5400\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6791 - val_loss: 1.5624\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7888 - val_loss: 1.5592\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7248 - val_loss: 1.5668\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6400 - val_loss: 1.5726\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6024 - val_loss: 1.5800\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5695 - val_loss: 1.5658\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5862 - val_loss: 1.5827\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5912 - val_loss: 1.6061\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5908 - val_loss: 1.5934\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5077 - val_loss: 1.6121\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5438 - val_loss: 1.6237\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5824 - val_loss: 1.6308\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5390 - val_loss: 1.6191\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5466 - val_loss: 1.6116\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5141 - val_loss: 1.6054\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4976 - val_loss: 1.5613\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4580 - val_loss: 1.5679\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5035 - val_loss: 1.5416\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4652 - val_loss: 1.5419\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4551 - val_loss: 1.5356\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4992 - val_loss: 1.5273\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4778 - val_loss: 1.5204\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5966 - val_loss: 1.5425\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 2.0163 - val_loss: 1.3640\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8633 - val_loss: 1.3759\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7607 - val_loss: 1.3823\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7314 - val_loss: 1.4100\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6710 - val_loss: 1.4244\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7823 - val_loss: 1.4514\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7894 - val_loss: 1.4516\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7182 - val_loss: 1.4478\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5551 - val_loss: 1.3970\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6295 - val_loss: 1.3916\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6038 - val_loss: 1.3860\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5904 - val_loss: 1.3983\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5800 - val_loss: 1.4052\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6154 - val_loss: 1.4055\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6123 - val_loss: 1.3880\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6031 - val_loss: 1.3967\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6191 - val_loss: 1.4239\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5680 - val_loss: 1.4129\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6013 - val_loss: 1.4606\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5746 - val_loss: 1.4322\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5610 - val_loss: 1.4272\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5901 - val_loss: 1.4302\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5780 - val_loss: 1.4055\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5608 - val_loss: 1.3895\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5313 - val_loss: 1.3930\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5451 - val_loss: 1.4070\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5285 - val_loss: 1.4002\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5410 - val_loss: 1.4049\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4873 - val_loss: 1.4033\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4664 - val_loss: 1.4024\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5148 - val_loss: 1.4227\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4717 - val_loss: 1.4189\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4947 - val_loss: 1.4224\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4473 - val_loss: 1.4276\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4414 - val_loss: 1.4342\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4218 - val_loss: 1.4275\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4356 - val_loss: 1.4374\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4510 - val_loss: 1.4335\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3505 - val_loss: 1.4357\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4158 - val_loss: 1.4657\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4197 - val_loss: 1.4866\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 3 fold 3 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 2.3150 - val_loss: 1.4839\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8589 - val_loss: 1.4767\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9410 - val_loss: 1.4925\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8547 - val_loss: 1.4869\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7030 - val_loss: 1.4847\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8147 - val_loss: 1.4765\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7120 - val_loss: 1.4815\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6594 - val_loss: 1.4899\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6901 - val_loss: 1.4894\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7808 - val_loss: 1.4873\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6910 - val_loss: 1.4915\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6338 - val_loss: 1.5026\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6575 - val_loss: 1.5261\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5878 - val_loss: 1.5275\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5147 - val_loss: 1.5367\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6296 - val_loss: 1.5252\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5811 - val_loss: 1.5247\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5110 - val_loss: 1.5357\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5461 - val_loss: 1.5369\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5257 - val_loss: 1.5216\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5411 - val_loss: 1.5538\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4454 - val_loss: 1.5256\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4551 - val_loss: 1.5341\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5304 - val_loss: 1.5601\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5085 - val_loss: 1.5366\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5144 - val_loss: 1.5248\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5373 - val_loss: 1.5286\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4863 - val_loss: 1.5627\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5045 - val_loss: 1.5855\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4888 - val_loss: 1.5647\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4730 - val_loss: 1.5661\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4578 - val_loss: 1.5687\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4188 - val_loss: 1.5677\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4511 - val_loss: 1.5542\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4720 - val_loss: 1.5494\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4865 - val_loss: 1.5499\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4239 - val_loss: 1.5316\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4034 - val_loss: 1.5385\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4150 - val_loss: 1.5410\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4410 - val_loss: 1.5444\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4547 - val_loss: 1.5196\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 4 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.3578 - val_loss: 1.4318\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8781 - val_loss: 1.4339\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7527 - val_loss: 1.4014\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7570 - val_loss: 1.3278\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7397 - val_loss: 1.3211\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6367 - val_loss: 1.3231\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6918 - val_loss: 1.3296\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6596 - val_loss: 1.3511\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7163 - val_loss: 1.3257\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6289 - val_loss: 1.3151\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6349 - val_loss: 1.3176\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5542 - val_loss: 1.3137\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6253 - val_loss: 1.2946\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6452 - val_loss: 1.3108\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6619 - val_loss: 1.2992\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5980 - val_loss: 1.3135\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6098 - val_loss: 1.3171\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5676 - val_loss: 1.3168\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5870 - val_loss: 1.3275\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6204 - val_loss: 1.3218\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5239 - val_loss: 1.3243\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5580 - val_loss: 1.3246\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5484 - val_loss: 1.3122\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5088 - val_loss: 1.3310\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4949 - val_loss: 1.3329\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5178 - val_loss: 1.3331\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5072 - val_loss: 1.3339\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5236 - val_loss: 1.3341\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4395 - val_loss: 1.3381\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5009 - val_loss: 1.3734\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4654 - val_loss: 1.3738\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4669 - val_loss: 1.3389\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5237 - val_loss: 1.3405\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4446 - val_loss: 1.3459\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4495 - val_loss: 1.3441\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4498 - val_loss: 1.3477\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4518 - val_loss: 1.3385\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4623 - val_loss: 1.3395\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4609 - val_loss: 1.3426\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4402 - val_loss: 1.3485\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4439 - val_loss: 1.3103\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4373 - val_loss: 1.3135\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4158 - val_loss: 1.3334\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Real LSTM seed 3 fold 5 gamma= 1\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 2.2579 - val_loss: 1.6227\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9273 - val_loss: 1.5842\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9584 - val_loss: 1.5744\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7758 - val_loss: 1.5762\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7954 - val_loss: 1.6427\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7120 - val_loss: 1.6402\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6971 - val_loss: 1.6487\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6641 - val_loss: 1.6886\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6124 - val_loss: 1.6638\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6444 - val_loss: 1.6940\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5532 - val_loss: 1.7208\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6350 - val_loss: 1.7181\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5827 - val_loss: 1.7263\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5529 - val_loss: 1.7518\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5307 - val_loss: 1.7445\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5718 - val_loss: 1.7079\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5145 - val_loss: 1.6896\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5432 - val_loss: 1.7188\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5094 - val_loss: 1.7427\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4778 - val_loss: 1.7211\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4607 - val_loss: 1.7731\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4272 - val_loss: 1.7848\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4567 - val_loss: 1.8465\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4237 - val_loss: 1.8560\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4642 - val_loss: 1.8791\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3954 - val_loss: 1.9272\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4038 - val_loss: 1.9074\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3820 - val_loss: 1.9179\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4056 - val_loss: 1.9468\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4000 - val_loss: 2.0014\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3688 - val_loss: 2.0076\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3340 - val_loss: 1.9897\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3369 - val_loss: 2.0101\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2974 - val_loss: 2.0313\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3044 - val_loss: 2.0751\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2940 - val_loss: 2.0837\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3368 - val_loss: 2.0758\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2743 - val_loss: 2.0683\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2902 - val_loss: 2.0701\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2287 - val_loss: 2.0909\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2341 - val_loss: 2.1630\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2310 - val_loss: 2.1754\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2687 - val_loss: 2.1670\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2273 - val_loss: 2.1534\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2317 - val_loss: 2.1580\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1670 - val_loss: 2.1569\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1847 - val_loss: 2.2027\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.4310 - val_loss: 1.5721\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8784 - val_loss: 1.5544\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9488 - val_loss: 1.5258\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8656 - val_loss: 1.5326\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7729 - val_loss: 1.5318\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7708 - val_loss: 1.5208\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6967 - val_loss: 1.5324\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7756 - val_loss: 1.5216\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7090 - val_loss: 1.5629\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7290 - val_loss: 1.5817\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7070 - val_loss: 1.5844\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6850 - val_loss: 1.5745\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7021 - val_loss: 1.5611\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6918 - val_loss: 1.5564\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5938 - val_loss: 1.5505\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6095 - val_loss: 1.5550\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6951 - val_loss: 1.5743\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5294 - val_loss: 1.5623\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5358 - val_loss: 1.5521\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5504 - val_loss: 1.5428\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5852 - val_loss: 1.5067\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5772 - val_loss: 1.5358\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5289 - val_loss: 1.5356\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5690 - val_loss: 1.5444\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5527 - val_loss: 1.5888\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5537 - val_loss: 1.5825\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5646 - val_loss: 1.5894\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4826 - val_loss: 1.6237\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5095 - val_loss: 1.6008\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5093 - val_loss: 1.5883\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5169 - val_loss: 1.5390\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4014 - val_loss: 1.5420\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4827 - val_loss: 1.5696\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4402 - val_loss: 1.5669\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4508 - val_loss: 1.5752\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4761 - val_loss: 1.5621\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3932 - val_loss: 1.5536\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4029 - val_loss: 1.5716\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4305 - val_loss: 1.6038\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3839 - val_loss: 1.6241\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4180 - val_loss: 1.6351\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4200 - val_loss: 1.6163\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3621 - val_loss: 1.6010\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3773 - val_loss: 1.6068\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3711 - val_loss: 1.5498\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3953 - val_loss: 1.5786\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3813 - val_loss: 1.5844\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3327 - val_loss: 1.6002\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3221 - val_loss: 1.6121\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3543 - val_loss: 1.6285\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3237 - val_loss: 1.6500\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.3106 - val_loss: 1.3503\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9458 - val_loss: 1.3777\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9823 - val_loss: 1.4141\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7822 - val_loss: 1.4089\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7768 - val_loss: 1.3833\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8819 - val_loss: 1.3677\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7239 - val_loss: 1.3827\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6586 - val_loss: 1.3671\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7078 - val_loss: 1.3897\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7605 - val_loss: 1.3923\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6787 - val_loss: 1.3928\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6369 - val_loss: 1.4005\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6969 - val_loss: 1.3914\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6783 - val_loss: 1.4230\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6662 - val_loss: 1.4242\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6903 - val_loss: 1.4101\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6091 - val_loss: 1.4125\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5793 - val_loss: 1.4144\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5298 - val_loss: 1.4128\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6288 - val_loss: 1.4191\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5597 - val_loss: 1.4142\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5924 - val_loss: 1.3985\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5676 - val_loss: 1.4323\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5052 - val_loss: 1.4280\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4895 - val_loss: 1.4202\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5162 - val_loss: 1.4323\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5497 - val_loss: 1.4519\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5570 - val_loss: 1.4516\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5128 - val_loss: 1.4538\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4715 - val_loss: 1.4748\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4278 - val_loss: 1.4750\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4265 - val_loss: 1.4788\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4393 - val_loss: 1.4846\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4543 - val_loss: 1.4816\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5088 - val_loss: 1.5081\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4794 - val_loss: 1.4860\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4562 - val_loss: 1.5109\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4416 - val_loss: 1.4800\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3886 - val_loss: 1.4647\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3512 - val_loss: 1.4708\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3593 - val_loss: 1.5125\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3780 - val_loss: 1.4721\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4099 - val_loss: 1.5015\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Real LSTM seed 3 fold 3 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.1438 - val_loss: 1.5898\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0211 - val_loss: 1.5374\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7584 - val_loss: 1.5390\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8196 - val_loss: 1.5513\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7060 - val_loss: 1.5678\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7421 - val_loss: 1.5754\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7149 - val_loss: 1.5642\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7083 - val_loss: 1.5470\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6196 - val_loss: 1.5532\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6434 - val_loss: 1.5899\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6110 - val_loss: 1.5723\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6370 - val_loss: 1.6116\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5993 - val_loss: 1.6122\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5462 - val_loss: 1.6134\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6134 - val_loss: 1.5864\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5320 - val_loss: 1.6185\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5023 - val_loss: 1.6112\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4850 - val_loss: 1.5943\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6045 - val_loss: 1.5976\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6134 - val_loss: 1.6092\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5725 - val_loss: 1.6145\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4843 - val_loss: 1.6269\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4416 - val_loss: 1.6191\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4656 - val_loss: 1.6351\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4365 - val_loss: 1.6555\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3769 - val_loss: 1.6552\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4991 - val_loss: 1.6512\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5520 - val_loss: 1.6271\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4640 - val_loss: 1.6280\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4302 - val_loss: 1.6553\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4025 - val_loss: 1.6358\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3842 - val_loss: 1.6512\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3807 - val_loss: 1.6203\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3755 - val_loss: 1.6163\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3135 - val_loss: 1.6107\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3274 - val_loss: 1.5887\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3804 - val_loss: 1.6091\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2771 - val_loss: 1.6132\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3859 - val_loss: 1.6548\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3464 - val_loss: 1.6902\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3150 - val_loss: 1.6652\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 3 fold 4 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.3616 - val_loss: 1.3581\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9577 - val_loss: 1.3702\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8710 - val_loss: 1.3615\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7091 - val_loss: 1.3666\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7650 - val_loss: 1.3299\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6980 - val_loss: 1.3364\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6556 - val_loss: 1.3428\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6889 - val_loss: 1.3524\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6096 - val_loss: 1.3201\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6756 - val_loss: 1.2937\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6478 - val_loss: 1.3159\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6602 - val_loss: 1.3313\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6536 - val_loss: 1.3227\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5651 - val_loss: 1.3448\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6126 - val_loss: 1.3327\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6078 - val_loss: 1.3272\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5562 - val_loss: 1.3163\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6013 - val_loss: 1.3012\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5194 - val_loss: 1.3101\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5470 - val_loss: 1.3128\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6003 - val_loss: 1.2940\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4884 - val_loss: 1.3193\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6147 - val_loss: 1.3425\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5664 - val_loss: 1.3258\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5527 - val_loss: 1.3313\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5431 - val_loss: 1.3274\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5335 - val_loss: 1.3097\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5251 - val_loss: 1.3909\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5226 - val_loss: 1.3738\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5191 - val_loss: 1.3436\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4813 - val_loss: 1.3050\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5211 - val_loss: 1.3017\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4779 - val_loss: 1.2816\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4198 - val_loss: 1.2648\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4355 - val_loss: 1.2841\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4784 - val_loss: 1.2885\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4351 - val_loss: 1.2765\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4409 - val_loss: 1.2780\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4157 - val_loss: 1.2797\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5035 - val_loss: 1.2789\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3984 - val_loss: 1.2743\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4185 - val_loss: 1.2785\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3775 - val_loss: 1.2858\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4111 - val_loss: 1.2768\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3874 - val_loss: 1.2754\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3445 - val_loss: 1.2791\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4302 - val_loss: 1.2952\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3237 - val_loss: 1.3078\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4696 - val_loss: 1.3249\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3787 - val_loss: 1.3123\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3787 - val_loss: 1.3123\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3025 - val_loss: 1.3069\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3371 - val_loss: 1.3061\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2906 - val_loss: 1.3128\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3174 - val_loss: 1.3164\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3124 - val_loss: 1.2997\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2805 - val_loss: 1.3077\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2924 - val_loss: 1.2992\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3368 - val_loss: 1.3035\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2661 - val_loss: 1.3024\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3279 - val_loss: 1.2991\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3089 - val_loss: 1.3340\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3396 - val_loss: 1.3248\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2441 - val_loss: 1.3087\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 5 gamma= 2\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 2.3023 - val_loss: 1.4547\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8842 - val_loss: 1.5904\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7265 - val_loss: 1.5753\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7983 - val_loss: 1.5877\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7546 - val_loss: 1.6092\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7194 - val_loss: 1.6267\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6577 - val_loss: 1.5894\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6644 - val_loss: 1.6255\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6973 - val_loss: 1.6116\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6251 - val_loss: 1.6243\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6038 - val_loss: 1.6393\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6144 - val_loss: 1.6452\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5626 - val_loss: 1.6777\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5379 - val_loss: 1.6936\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5242 - val_loss: 1.7070\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5226 - val_loss: 1.7204\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5620 - val_loss: 1.7008\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4951 - val_loss: 1.7261\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4440 - val_loss: 1.7499\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4551 - val_loss: 1.7542\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4837 - val_loss: 1.7415\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4388 - val_loss: 1.7505\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4649 - val_loss: 1.6945\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4116 - val_loss: 1.7191\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4210 - val_loss: 1.7379\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4100 - val_loss: 1.7537\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3685 - val_loss: 1.7684\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3560 - val_loss: 1.8795\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3633 - val_loss: 1.8466\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3197 - val_loss: 1.8818\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3276 - val_loss: 1.9164\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3715 - val_loss: 1.9284\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3190 - val_loss: 1.9656\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2820 - val_loss: 1.9490\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2679 - val_loss: 1.9684\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2247 - val_loss: 2.0250\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2114 - val_loss: 2.0212\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2644 - val_loss: 2.0662\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2810 - val_loss: 2.0695\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2541 - val_loss: 2.0911\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2538 - val_loss: 2.1466\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 2.3652 - val_loss: 1.5686\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9640 - val_loss: 1.5463\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7857 - val_loss: 1.5102\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9203 - val_loss: 1.4730\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8252 - val_loss: 1.4976\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7658 - val_loss: 1.5330\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7266 - val_loss: 1.5158\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7900 - val_loss: 1.5083\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6711 - val_loss: 1.4733\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8035 - val_loss: 1.4810\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6879 - val_loss: 1.4777\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7029 - val_loss: 1.4737\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6553 - val_loss: 1.4651\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6395 - val_loss: 1.5263\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7484 - val_loss: 1.4727\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6352 - val_loss: 1.4611\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6102 - val_loss: 1.4546\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6005 - val_loss: 1.4843\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5605 - val_loss: 1.4819\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5537 - val_loss: 1.4935\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5389 - val_loss: 1.4883\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6022 - val_loss: 1.4592\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5488 - val_loss: 1.4611\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5219 - val_loss: 1.4487\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5942 - val_loss: 1.5120\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5209 - val_loss: 1.4999\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5796 - val_loss: 1.4988\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4895 - val_loss: 1.4811\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5025 - val_loss: 1.4699\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5487 - val_loss: 1.4699\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5189 - val_loss: 1.4547\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5055 - val_loss: 1.4650\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4627 - val_loss: 1.4550\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4874 - val_loss: 1.4469\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4086 - val_loss: 1.4546\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4845 - val_loss: 1.4592\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4407 - val_loss: 1.4829\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4720 - val_loss: 1.4829\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4078 - val_loss: 1.4896\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4703 - val_loss: 1.5424\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4583 - val_loss: 1.5188\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4677 - val_loss: 1.5027\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4149 - val_loss: 1.4730\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3623 - val_loss: 1.4666\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4153 - val_loss: 1.4384\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4503 - val_loss: 1.4416\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4136 - val_loss: 1.4430\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4298 - val_loss: 1.4817\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3542 - val_loss: 1.4697\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3347 - val_loss: 1.4739\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4293 - val_loss: 1.4643\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3636 - val_loss: 1.4631\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3449 - val_loss: 1.4876\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2946 - val_loss: 1.5387\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2857 - val_loss: 1.5033\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3055 - val_loss: 1.4992\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3071 - val_loss: 1.5047\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2846 - val_loss: 1.5153\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3339 - val_loss: 1.5166\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3159 - val_loss: 1.5070\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3117 - val_loss: 1.4960\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2772 - val_loss: 1.5001\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3416 - val_loss: 1.5444\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1683 - val_loss: 1.5665\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2592 - val_loss: 1.5767\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2416 - val_loss: 1.6399\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2289 - val_loss: 1.6633\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2125 - val_loss: 1.5930\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2070 - val_loss: 1.5805\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2071 - val_loss: 1.5707\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2011 - val_loss: 1.5784\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1600 - val_loss: 1.6371\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1663 - val_loss: 1.6351\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1885 - val_loss: 1.6276\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1716 - val_loss: 1.6346\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 2.5261 - val_loss: 1.4033\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0278 - val_loss: 1.3944\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9528 - val_loss: 1.4219\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7602 - val_loss: 1.3953\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7909 - val_loss: 1.3850\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6883 - val_loss: 1.3850\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7560 - val_loss: 1.3969\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7336 - val_loss: 1.3968\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6833 - val_loss: 1.4118\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5896 - val_loss: 1.3940\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6944 - val_loss: 1.4197\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6563 - val_loss: 1.4074\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6418 - val_loss: 1.4058\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5654 - val_loss: 1.3922\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5912 - val_loss: 1.3767\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5426 - val_loss: 1.3700\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5703 - val_loss: 1.3598\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6156 - val_loss: 1.3894\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6011 - val_loss: 1.3782\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5422 - val_loss: 1.4073\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5996 - val_loss: 1.4133\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5656 - val_loss: 1.3992\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5196 - val_loss: 1.4268\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5058 - val_loss: 1.4118\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5333 - val_loss: 1.3985\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4670 - val_loss: 1.4292\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5469 - val_loss: 1.4033\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5321 - val_loss: 1.4045\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4450 - val_loss: 1.4530\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5168 - val_loss: 1.4666\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4796 - val_loss: 1.4852\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4181 - val_loss: 1.4661\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4665 - val_loss: 1.4654\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4487 - val_loss: 1.4711\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4783 - val_loss: 1.4843\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4258 - val_loss: 1.4959\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4565 - val_loss: 1.5078\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4847 - val_loss: 1.4922\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4372 - val_loss: 1.4823\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3564 - val_loss: 1.4684\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4006 - val_loss: 1.4772\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3638 - val_loss: 1.5159\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4216 - val_loss: 1.4982\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3787 - val_loss: 1.4716\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4203 - val_loss: 1.4653\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3691 - val_loss: 1.4917\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3360 - val_loss: 1.4601\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 3 fold 3 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 2.0970 - val_loss: 1.5183\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8928 - val_loss: 1.4722\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8174 - val_loss: 1.5019\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7685 - val_loss: 1.5044\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6780 - val_loss: 1.5215\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7429 - val_loss: 1.4896\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7560 - val_loss: 1.4996\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6227 - val_loss: 1.4908\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6424 - val_loss: 1.4981\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6586 - val_loss: 1.4975\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6610 - val_loss: 1.4927\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6212 - val_loss: 1.5123\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5442 - val_loss: 1.5147\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6198 - val_loss: 1.5322\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5280 - val_loss: 1.5360\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5149 - val_loss: 1.5288\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5188 - val_loss: 1.5206\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5701 - val_loss: 1.5195\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5094 - val_loss: 1.5310\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5310 - val_loss: 1.5436\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5345 - val_loss: 1.5463\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5313 - val_loss: 1.5449\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4775 - val_loss: 1.5257\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5119 - val_loss: 1.5252\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5182 - val_loss: 1.5253\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5194 - val_loss: 1.5573\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4294 - val_loss: 1.5906\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4807 - val_loss: 1.5587\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4466 - val_loss: 1.5819\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4054 - val_loss: 1.5885\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4743 - val_loss: 1.5780\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4198 - val_loss: 1.6110\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3984 - val_loss: 1.6156\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3962 - val_loss: 1.5894\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4995 - val_loss: 1.5695\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3083 - val_loss: 1.5897\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4030 - val_loss: 1.5912\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3953 - val_loss: 1.6018\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3888 - val_loss: 1.6237\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3877 - val_loss: 1.6215\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3323 - val_loss: 1.5998\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 3 fold 4 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 2.2649 - val_loss: 1.3922\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8724 - val_loss: 1.3665\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8618 - val_loss: 1.3588\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7088 - val_loss: 1.3722\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7022 - val_loss: 1.3798\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8114 - val_loss: 1.3816\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7340 - val_loss: 1.3752\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6469 - val_loss: 1.3624\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6378 - val_loss: 1.3506\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6987 - val_loss: 1.3519\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6615 - val_loss: 1.3627\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6685 - val_loss: 1.3688\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6234 - val_loss: 1.3813\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5836 - val_loss: 1.3960\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6483 - val_loss: 1.3970\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6068 - val_loss: 1.3882\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5892 - val_loss: 1.3574\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6642 - val_loss: 1.3808\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5839 - val_loss: 1.3846\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5471 - val_loss: 1.3655\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5716 - val_loss: 1.3536\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5059 - val_loss: 1.3288\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6372 - val_loss: 1.3595\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5583 - val_loss: 1.4276\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5381 - val_loss: 1.4237\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6298 - val_loss: 1.4160\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5480 - val_loss: 1.4123\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5468 - val_loss: 1.3939\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5962 - val_loss: 1.3792\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5165 - val_loss: 1.3950\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5043 - val_loss: 1.4205\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5031 - val_loss: 1.3924\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5598 - val_loss: 1.3719\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5111 - val_loss: 1.3697\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5677 - val_loss: 1.4510\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5582 - val_loss: 1.4619\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4764 - val_loss: 1.4578\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5407 - val_loss: 1.4420\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4806 - val_loss: 1.4097\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5099 - val_loss: 1.4085\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4732 - val_loss: 1.3936\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4479 - val_loss: 1.3958\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4319 - val_loss: 1.4022\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4300 - val_loss: 1.4038\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4259 - val_loss: 1.4000\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3751 - val_loss: 1.4004\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4498 - val_loss: 1.3840\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4318 - val_loss: 1.3905\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3570 - val_loss: 1.3621\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3599 - val_loss: 1.3356\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4206 - val_loss: 1.3253\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4048 - val_loss: 1.3154\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4153 - val_loss: 1.3034\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3980 - val_loss: 1.2990\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3078 - val_loss: 1.2970\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4260 - val_loss: 1.2925\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4004 - val_loss: 1.2970\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3536 - val_loss: 1.2907\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4097 - val_loss: 1.2617\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3847 - val_loss: 1.2807\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3903 - val_loss: 1.3070\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3099 - val_loss: 1.3080\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3492 - val_loss: 1.3076\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3705 - val_loss: 1.2908\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3723 - val_loss: 1.3030\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3541 - val_loss: 1.2931\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2913 - val_loss: 1.2833\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3114 - val_loss: 1.2972\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3406 - val_loss: 1.2774\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3025 - val_loss: 1.2654\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3288 - val_loss: 1.2823\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2865 - val_loss: 1.2686\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2079 - val_loss: 1.2593\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2603 - val_loss: 1.2856\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2585 - val_loss: 1.3223\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3591 - val_loss: 1.3005\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2293 - val_loss: 1.3116\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3069 - val_loss: 1.3695\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2550 - val_loss: 1.3673\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2050 - val_loss: 1.3458\n",
      "Epoch 81/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2685 - val_loss: 1.3227\n",
      "Epoch 82/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2423 - val_loss: 1.3218\n",
      "Epoch 83/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2416 - val_loss: 1.3315\n",
      "Epoch 84/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2653 - val_loss: 1.3679\n",
      "Epoch 85/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2344 - val_loss: 1.3585\n",
      "Epoch 86/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2503 - val_loss: 1.3286\n",
      "Epoch 87/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2407 - val_loss: 1.3377\n",
      "Epoch 88/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2454 - val_loss: 1.3328\n",
      "Epoch 89/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1746 - val_loss: 1.3441\n",
      "Epoch 90/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1886 - val_loss: 1.3357\n",
      "Epoch 91/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1548 - val_loss: 1.3527\n",
      "Epoch 92/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1943 - val_loss: 1.3724\n",
      "Epoch 93/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1898 - val_loss: 1.4192\n",
      "Epoch 94/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1908 - val_loss: 1.4042\n",
      "Epoch 95/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1838 - val_loss: 1.4497\n",
      "Epoch 96/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1140 - val_loss: 1.4402\n",
      "Epoch 97/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1297 - val_loss: 1.4507\n",
      "Epoch 98/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1506 - val_loss: 1.4415\n",
      "Epoch 99/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1976 - val_loss: 1.4174\n",
      "Epoch 100/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1728 - val_loss: 1.3926\n",
      "Epoch 101/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1410 - val_loss: 1.3629\n",
      "Epoch 102/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1184 - val_loss: 1.3851\n",
      "Epoch 103/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1944 - val_loss: 1.4080\n",
      "Epoch 103: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 5 gamma= 3\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.2650 - val_loss: 1.6163\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0420 - val_loss: 1.5993\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8840 - val_loss: 1.5958\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7503 - val_loss: 1.6018\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7765 - val_loss: 1.6027\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7933 - val_loss: 1.6203\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6926 - val_loss: 1.6383\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7383 - val_loss: 1.6526\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6969 - val_loss: 1.6493\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7525 - val_loss: 1.6605\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7576 - val_loss: 1.6750\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6263 - val_loss: 1.6886\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6591 - val_loss: 1.7233\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6345 - val_loss: 1.7261\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5621 - val_loss: 1.7114\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5830 - val_loss: 1.7147\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5517 - val_loss: 1.7652\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5574 - val_loss: 1.7610\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5338 - val_loss: 1.7917\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4897 - val_loss: 1.8417\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5179 - val_loss: 1.8221\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4768 - val_loss: 1.8587\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5091 - val_loss: 1.8639\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4322 - val_loss: 1.8396\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4325 - val_loss: 1.7993\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5043 - val_loss: 1.8658\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4511 - val_loss: 1.9132\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4291 - val_loss: 1.8210\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4804 - val_loss: 1.8647\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4426 - val_loss: 1.8995\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3542 - val_loss: 2.0788\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4014 - val_loss: 2.1076\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3823 - val_loss: 2.1141\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3796 - val_loss: 2.1313\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3125 - val_loss: 2.1008\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3497 - val_loss: 2.1547\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3128 - val_loss: 2.1639\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3557 - val_loss: 2.0881\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2913 - val_loss: 2.1920\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3049 - val_loss: 2.2026\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2701 - val_loss: 2.0575\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 2.2698 - val_loss: 1.6037\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9281 - val_loss: 1.5572\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8581 - val_loss: 1.5650\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8688 - val_loss: 1.5913\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7465 - val_loss: 1.5768\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7802 - val_loss: 1.5658\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8093 - val_loss: 1.5595\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8279 - val_loss: 1.5552\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6782 - val_loss: 1.5529\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6406 - val_loss: 1.5421\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6986 - val_loss: 1.5807\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7041 - val_loss: 1.5721\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7156 - val_loss: 1.5711\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6138 - val_loss: 1.5616\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6118 - val_loss: 1.5264\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7010 - val_loss: 1.5290\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6516 - val_loss: 1.5245\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5451 - val_loss: 1.5191\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6624 - val_loss: 1.5091\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5866 - val_loss: 1.4960\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5896 - val_loss: 1.5424\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5145 - val_loss: 1.5482\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4553 - val_loss: 1.5299\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5230 - val_loss: 1.5254\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5253 - val_loss: 1.5054\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5123 - val_loss: 1.5186\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5621 - val_loss: 1.5526\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5205 - val_loss: 1.5440\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5649 - val_loss: 1.5502\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4625 - val_loss: 1.5481\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4897 - val_loss: 1.5482\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4410 - val_loss: 1.5487\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4306 - val_loss: 1.5441\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4505 - val_loss: 1.5378\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4533 - val_loss: 1.5543\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3983 - val_loss: 1.5687\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4249 - val_loss: 1.5588\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3871 - val_loss: 1.5633\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3729 - val_loss: 1.5852\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4354 - val_loss: 1.5762\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3824 - val_loss: 1.5574\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3669 - val_loss: 1.5587\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3998 - val_loss: 1.5690\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3326 - val_loss: 1.6039\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4040 - val_loss: 1.6356\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3629 - val_loss: 1.6090\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3020 - val_loss: 1.5772\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3437 - val_loss: 1.5647\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3975 - val_loss: 1.5438\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3468 - val_loss: 1.5503\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.2828 - val_loss: 1.4023\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9127 - val_loss: 1.4342\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8347 - val_loss: 1.4419\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7483 - val_loss: 1.4301\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7889 - val_loss: 1.4169\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7538 - val_loss: 1.4102\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7587 - val_loss: 1.4224\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7531 - val_loss: 1.4330\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6488 - val_loss: 1.4126\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7839 - val_loss: 1.4315\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6926 - val_loss: 1.4410\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6136 - val_loss: 1.4535\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6216 - val_loss: 1.4707\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6072 - val_loss: 1.4722\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6062 - val_loss: 1.4741\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5686 - val_loss: 1.4688\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6014 - val_loss: 1.4715\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5612 - val_loss: 1.4625\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5586 - val_loss: 1.4373\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5584 - val_loss: 1.4749\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5388 - val_loss: 1.4689\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5620 - val_loss: 1.4680\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5438 - val_loss: 1.4739\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5382 - val_loss: 1.4698\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5160 - val_loss: 1.4634\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5618 - val_loss: 1.4685\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4726 - val_loss: 1.4464\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5719 - val_loss: 1.4395\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5810 - val_loss: 1.4430\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5200 - val_loss: 1.4583\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5142 - val_loss: 1.4424\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4423 - val_loss: 1.4430\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4533 - val_loss: 1.4869\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4688 - val_loss: 1.4851\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4555 - val_loss: 1.4860\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4380 - val_loss: 1.4641\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4963 - val_loss: 1.4619\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4099 - val_loss: 1.4615\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4065 - val_loss: 1.4535\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5303 - val_loss: 1.4679\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4106 - val_loss: 1.4940\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4558 - val_loss: 1.4812\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4020 - val_loss: 1.4874\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4785 - val_loss: 1.4871\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3590 - val_loss: 1.5069\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4068 - val_loss: 1.5333\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4227 - val_loss: 1.5446\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3822 - val_loss: 1.5289\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4230 - val_loss: 1.5211\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 3 fold 3 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.1109 - val_loss: 1.5290\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8174 - val_loss: 1.5425\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7084 - val_loss: 1.5394\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7035 - val_loss: 1.5372\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6924 - val_loss: 1.5467\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6099 - val_loss: 1.5385\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6791 - val_loss: 1.5145\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6005 - val_loss: 1.5136\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6398 - val_loss: 1.5134\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6380 - val_loss: 1.5161\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6080 - val_loss: 1.5227\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6281 - val_loss: 1.5022\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6111 - val_loss: 1.4905\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5711 - val_loss: 1.5222\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5804 - val_loss: 1.5201\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5127 - val_loss: 1.5264\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5261 - val_loss: 1.5319\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5595 - val_loss: 1.5197\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5050 - val_loss: 1.5168\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5841 - val_loss: 1.5240\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5056 - val_loss: 1.5291\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5693 - val_loss: 1.5227\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5187 - val_loss: 1.5171\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5189 - val_loss: 1.5096\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4557 - val_loss: 1.5169\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4560 - val_loss: 1.4970\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5120 - val_loss: 1.5160\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5425 - val_loss: 1.4948\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4367 - val_loss: 1.5023\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4979 - val_loss: 1.5209\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4885 - val_loss: 1.5356\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4086 - val_loss: 1.5728\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4257 - val_loss: 1.5744\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4027 - val_loss: 1.5718\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4421 - val_loss: 1.5917\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3834 - val_loss: 1.5945\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3998 - val_loss: 1.5896\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4356 - val_loss: 1.5698\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3276 - val_loss: 1.5640\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3417 - val_loss: 1.5342\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4434 - val_loss: 1.5435\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3970 - val_loss: 1.5499\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3767 - val_loss: 1.5636\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 3 fold 4 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 2.2212 - val_loss: 1.4140\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8605 - val_loss: 1.4365\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8252 - val_loss: 1.4335\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7355 - val_loss: 1.4308\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7636 - val_loss: 1.3908\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7828 - val_loss: 1.4126\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6723 - val_loss: 1.4168\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6576 - val_loss: 1.4217\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7176 - val_loss: 1.3968\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5637 - val_loss: 1.3934\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6287 - val_loss: 1.4125\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7249 - val_loss: 1.4144\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6157 - val_loss: 1.3899\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5912 - val_loss: 1.3942\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5678 - val_loss: 1.3958\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6508 - val_loss: 1.3989\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5631 - val_loss: 1.4114\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5695 - val_loss: 1.4668\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5170 - val_loss: 1.4687\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5168 - val_loss: 1.4287\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5228 - val_loss: 1.4322\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5520 - val_loss: 1.4256\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4969 - val_loss: 1.4321\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5347 - val_loss: 1.3962\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5902 - val_loss: 1.3979\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5579 - val_loss: 1.3981\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4574 - val_loss: 1.3699\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4961 - val_loss: 1.3773\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4968 - val_loss: 1.3930\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5255 - val_loss: 1.4027\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5178 - val_loss: 1.3991\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4202 - val_loss: 1.4089\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4635 - val_loss: 1.4081\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4897 - val_loss: 1.4088\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4502 - val_loss: 1.4152\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4545 - val_loss: 1.4421\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4166 - val_loss: 1.4329\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3851 - val_loss: 1.3959\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4614 - val_loss: 1.3750\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3538 - val_loss: 1.3745\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4274 - val_loss: 1.3927\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3826 - val_loss: 1.4122\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4323 - val_loss: 1.4048\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3968 - val_loss: 1.4207\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3560 - val_loss: 1.4109\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3691 - val_loss: 1.4077\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3538 - val_loss: 1.3862\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3619 - val_loss: 1.3586\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3650 - val_loss: 1.3644\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3054 - val_loss: 1.3692\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3819 - val_loss: 1.3908\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3669 - val_loss: 1.3883\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3921 - val_loss: 1.3964\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3126 - val_loss: 1.3956\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3515 - val_loss: 1.4101\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3067 - val_loss: 1.4046\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2763 - val_loss: 1.4270\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2728 - val_loss: 1.3842\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2723 - val_loss: 1.3997\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2947 - val_loss: 1.4153\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2781 - val_loss: 1.4270\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2972 - val_loss: 1.4595\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3213 - val_loss: 1.4454\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2813 - val_loss: 1.4053\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2491 - val_loss: 1.4026\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2376 - val_loss: 1.4210\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1670 - val_loss: 1.3910\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 1.2653 - val_loss: 1.5358\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2476 - val_loss: 1.4519\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2554 - val_loss: 1.4346\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.2184 - val_loss: 1.4310\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.2596 - val_loss: 1.4141\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.2427 - val_loss: 1.4349\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2034 - val_loss: 1.4011\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.1837 - val_loss: 1.3889\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.1850 - val_loss: 1.4346\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1.1833 - val_loss: 1.4506\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1956 - val_loss: 1.4416\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Real LSTM seed 3 fold 5 gamma= 4\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 2.0562 - val_loss: 1.5697\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8366 - val_loss: 1.5513\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7876 - val_loss: 1.5527\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7250 - val_loss: 1.5412\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7426 - val_loss: 1.6311\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6460 - val_loss: 1.6444\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6784 - val_loss: 1.6009\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6157 - val_loss: 1.6976\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6939 - val_loss: 1.6947\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5794 - val_loss: 1.7076\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6158 - val_loss: 1.7225\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5972 - val_loss: 1.7177\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5203 - val_loss: 1.7260\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5796 - val_loss: 1.7170\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5648 - val_loss: 1.7318\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5710 - val_loss: 1.7475\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5094 - val_loss: 1.7528\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5650 - val_loss: 1.7591\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4967 - val_loss: 1.7901\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4486 - val_loss: 1.7873\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4494 - val_loss: 1.8104\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4422 - val_loss: 1.7951\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4633 - val_loss: 1.7196\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3933 - val_loss: 1.7240\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4050 - val_loss: 1.7559\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3965 - val_loss: 1.8752\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3649 - val_loss: 1.8720\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3725 - val_loss: 1.9209\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3644 - val_loss: 1.9358\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3985 - val_loss: 1.9174\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3965 - val_loss: 1.9358\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3926 - val_loss: 1.9401\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3047 - val_loss: 1.9437\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3513 - val_loss: 1.9477\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3127 - val_loss: 2.0223\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3276 - val_loss: 2.0407\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3558 - val_loss: 2.0092\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2707 - val_loss: 2.0229\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3146 - val_loss: 2.0372\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2694 - val_loss: 2.0800\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3103 - val_loss: 2.0968\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2522 - val_loss: 2.1273\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2457 - val_loss: 2.1805\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1780 - val_loss: 2.1527\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 2.4519 - val_loss: 1.4453\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9499 - val_loss: 1.4512\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8690 - val_loss: 1.4576\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7316 - val_loss: 1.4772\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7488 - val_loss: 1.5011\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7574 - val_loss: 1.4880\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7150 - val_loss: 1.4642\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7265 - val_loss: 1.4898\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7293 - val_loss: 1.4962\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7270 - val_loss: 1.4913\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5360 - val_loss: 1.5083\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6101 - val_loss: 1.4997\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6994 - val_loss: 1.5107\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6674 - val_loss: 1.4995\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6689 - val_loss: 1.5374\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5616 - val_loss: 1.5392\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5412 - val_loss: 1.5673\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5810 - val_loss: 1.5819\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5695 - val_loss: 1.5698\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6411 - val_loss: 1.5692\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6124 - val_loss: 1.5454\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4978 - val_loss: 1.5535\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6033 - val_loss: 1.5302\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5354 - val_loss: 1.5203\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4391 - val_loss: 1.5196\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6056 - val_loss: 1.5131\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5960 - val_loss: 1.5152\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5467 - val_loss: 1.5168\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5115 - val_loss: 1.5076\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5236 - val_loss: 1.5101\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4937 - val_loss: 1.5317\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5293 - val_loss: 1.4959\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5323 - val_loss: 1.4918\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4942 - val_loss: 1.5148\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4500 - val_loss: 1.5165\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4820 - val_loss: 1.5105\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4463 - val_loss: 1.5104\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4859 - val_loss: 1.5015\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4421 - val_loss: 1.5260\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4152 - val_loss: 1.5153\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3818 - val_loss: 1.5051\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4485 - val_loss: 1.5034\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4974 - val_loss: 1.5202\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3863 - val_loss: 1.5109\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4130 - val_loss: 1.5436\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3952 - val_loss: 1.5458\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3964 - val_loss: 1.5454\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3880 - val_loss: 1.5416\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4129 - val_loss: 1.5421\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4117 - val_loss: 1.5096\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4116 - val_loss: 1.5438\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3562 - val_loss: 1.5705\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3576 - val_loss: 1.5658\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4088 - val_loss: 1.5441\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3687 - val_loss: 1.5685\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3241 - val_loss: 1.5707\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3258 - val_loss: 1.5263\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3180 - val_loss: 1.5791\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3455 - val_loss: 1.6140\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3262 - val_loss: 1.6210\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3387 - val_loss: 1.5950\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2754 - val_loss: 1.5924\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3548 - val_loss: 1.5714\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.2780 - val_loss: 1.7041\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9997 - val_loss: 1.6717\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8639 - val_loss: 1.6032\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7606 - val_loss: 1.6014\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7837 - val_loss: 1.6243\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7803 - val_loss: 1.6980\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7410 - val_loss: 1.6679\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7418 - val_loss: 1.7272\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7317 - val_loss: 1.6780\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7150 - val_loss: 1.6530\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6667 - val_loss: 1.6532\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6618 - val_loss: 1.6374\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6356 - val_loss: 1.6466\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6915 - val_loss: 1.6723\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6493 - val_loss: 1.6640\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5225 - val_loss: 1.6657\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6229 - val_loss: 1.6545\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5994 - val_loss: 1.6576\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6660 - val_loss: 1.6556\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5131 - val_loss: 1.7148\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5691 - val_loss: 1.6739\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5559 - val_loss: 1.6793\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5672 - val_loss: 1.6390\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4974 - val_loss: 1.6411\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5509 - val_loss: 1.6335\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4634 - val_loss: 1.6353\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5225 - val_loss: 1.6380\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4599 - val_loss: 1.6331\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4854 - val_loss: 1.6297\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5134 - val_loss: 1.6460\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4124 - val_loss: 1.6180\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4705 - val_loss: 1.5851\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4276 - val_loss: 1.5976\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4166 - val_loss: 1.5911\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4311 - val_loss: 1.5716\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3333 - val_loss: 1.5668\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4652 - val_loss: 1.5824\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3509 - val_loss: 1.5647\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4643 - val_loss: 1.5597\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3878 - val_loss: 1.5738\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4580 - val_loss: 1.5738\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3532 - val_loss: 1.5714\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4096 - val_loss: 1.5656\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3936 - val_loss: 1.5786\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3688 - val_loss: 1.5804\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3229 - val_loss: 1.6021\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3525 - val_loss: 1.6014\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3779 - val_loss: 1.6361\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3737 - val_loss: 1.6409\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2768 - val_loss: 1.7115\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3083 - val_loss: 1.7687\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3218 - val_loss: 1.7424\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3783 - val_loss: 1.7351\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2710 - val_loss: 1.6850\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3175 - val_loss: 1.6343\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3152 - val_loss: 1.6289\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2546 - val_loss: 1.6482\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2937 - val_loss: 1.6673\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2462 - val_loss: 1.6672\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2656 - val_loss: 1.6781\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2154 - val_loss: 1.6819\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2457 - val_loss: 1.6984\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2200 - val_loss: 1.6953\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2262 - val_loss: 1.7092\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1973 - val_loss: 1.7249\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2837 - val_loss: 1.7545\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1502 - val_loss: 1.7452\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1931 - val_loss: 1.7337\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1637 - val_loss: 1.7451\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.6500 - val_loss: 1.4966\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2758 - val_loss: 1.5364\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9799 - val_loss: 1.5363\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9618 - val_loss: 1.5411\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0303 - val_loss: 1.5507\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8711 - val_loss: 1.5297\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9142 - val_loss: 1.5770\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8790 - val_loss: 1.5401\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9556 - val_loss: 1.5549\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9194 - val_loss: 1.5519\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7659 - val_loss: 1.5415\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7683 - val_loss: 1.5238\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8375 - val_loss: 1.5389\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7752 - val_loss: 1.5485\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7781 - val_loss: 1.5863\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7300 - val_loss: 1.5942\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7708 - val_loss: 1.5820\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6950 - val_loss: 1.6269\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7146 - val_loss: 1.5716\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7025 - val_loss: 1.5483\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7538 - val_loss: 1.5494\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7559 - val_loss: 1.5516\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6731 - val_loss: 1.5746\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7776 - val_loss: 1.6027\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6582 - val_loss: 1.5893\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6982 - val_loss: 1.5744\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6832 - val_loss: 1.5769\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6146 - val_loss: 1.5884\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6683 - val_loss: 1.6158\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6898 - val_loss: 1.5834\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6757 - val_loss: 1.6003\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5657 - val_loss: 1.6697\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6329 - val_loss: 1.6480\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5643 - val_loss: 1.6649\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5431 - val_loss: 1.6791\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6166 - val_loss: 1.6941\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5776 - val_loss: 1.6843\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5262 - val_loss: 1.6590\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6549 - val_loss: 1.6490\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4991 - val_loss: 1.6325\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5297 - val_loss: 1.6164\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5294 - val_loss: 1.6310\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.2634 - val_loss: 1.4807\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9995 - val_loss: 1.6018\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9744 - val_loss: 1.6120\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8904 - val_loss: 1.5614\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7666 - val_loss: 1.6509\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7836 - val_loss: 1.6294\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8052 - val_loss: 1.5570\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6956 - val_loss: 1.5049\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7830 - val_loss: 1.4829\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7360 - val_loss: 1.4645\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6508 - val_loss: 1.4536\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6952 - val_loss: 1.4350\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6502 - val_loss: 1.4528\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6710 - val_loss: 1.4472\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7257 - val_loss: 1.4666\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6898 - val_loss: 1.4987\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6819 - val_loss: 1.4825\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6562 - val_loss: 1.4774\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5734 - val_loss: 1.4637\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6394 - val_loss: 1.4587\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5940 - val_loss: 1.4574\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5733 - val_loss: 1.4637\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6649 - val_loss: 1.4501\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6195 - val_loss: 1.4437\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5766 - val_loss: 1.4430\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6063 - val_loss: 1.4429\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6087 - val_loss: 1.4335\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5396 - val_loss: 1.4354\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5788 - val_loss: 1.4434\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5969 - val_loss: 1.4434\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5920 - val_loss: 1.4496\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6134 - val_loss: 1.4502\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5590 - val_loss: 1.4612\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5736 - val_loss: 1.4586\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5385 - val_loss: 1.4695\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5399 - val_loss: 1.4575\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5292 - val_loss: 1.4811\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5122 - val_loss: 1.5038\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5086 - val_loss: 1.5004\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4879 - val_loss: 1.5118\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5556 - val_loss: 1.5084\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5182 - val_loss: 1.4936\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5468 - val_loss: 1.4467\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4932 - val_loss: 1.4821\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4862 - val_loss: 1.5013\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5345 - val_loss: 1.5007\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5000 - val_loss: 1.4873\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4890 - val_loss: 1.5121\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4770 - val_loss: 1.5047\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4464 - val_loss: 1.5076\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5079 - val_loss: 1.5281\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4640 - val_loss: 1.5314\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3929 - val_loss: 1.5410\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4548 - val_loss: 1.5185\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4046 - val_loss: 1.5359\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4461 - val_loss: 1.5599\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4206 - val_loss: 1.5725\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= 0\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 2.2786 - val_loss: 1.4005\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9785 - val_loss: 1.4583\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8682 - val_loss: 1.5338\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8383 - val_loss: 1.5508\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7220 - val_loss: 1.5395\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7814 - val_loss: 1.5459\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6975 - val_loss: 1.5461\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7087 - val_loss: 1.5310\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6264 - val_loss: 1.5295\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6084 - val_loss: 1.5167\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7154 - val_loss: 1.5317\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6330 - val_loss: 1.5544\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6205 - val_loss: 1.5180\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5785 - val_loss: 1.5145\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6287 - val_loss: 1.4590\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6181 - val_loss: 1.4548\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6064 - val_loss: 1.4647\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6517 - val_loss: 1.5534\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5633 - val_loss: 1.5334\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6247 - val_loss: 1.5222\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5901 - val_loss: 1.5168\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5695 - val_loss: 1.5136\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5006 - val_loss: 1.5322\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5584 - val_loss: 1.5211\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5659 - val_loss: 1.5251\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5486 - val_loss: 1.5278\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5823 - val_loss: 1.5273\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5003 - val_loss: 1.5700\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5386 - val_loss: 1.5152\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5878 - val_loss: 1.5166\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4776 - val_loss: 1.5419\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5445 - val_loss: 1.5417\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4732 - val_loss: 1.5211\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4846 - val_loss: 1.4830\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4842 - val_loss: 1.4356\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5109 - val_loss: 1.4508\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4240 - val_loss: 1.4370\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4250 - val_loss: 1.4508\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4288 - val_loss: 1.4716\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4294 - val_loss: 1.4814\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4785 - val_loss: 1.4788\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4353 - val_loss: 1.4761\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4526 - val_loss: 1.4630\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4275 - val_loss: 1.4538\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3990 - val_loss: 1.4445\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4598 - val_loss: 1.4434\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3987 - val_loss: 1.4309\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3971 - val_loss: 1.4088\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3592 - val_loss: 1.4137\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3520 - val_loss: 1.4691\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3320 - val_loss: 1.4780\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3888 - val_loss: 1.5682\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3876 - val_loss: 1.5573\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3653 - val_loss: 1.5622\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2815 - val_loss: 1.5360\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3505 - val_loss: 1.4787\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3273 - val_loss: 1.5012\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2903 - val_loss: 1.5352\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2689 - val_loss: 1.5770\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2310 - val_loss: 1.4883\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2098 - val_loss: 1.5334\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2455 - val_loss: 1.5432\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3127 - val_loss: 1.5910\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2345 - val_loss: 1.5990\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1989 - val_loss: 1.6094\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1862 - val_loss: 1.6234\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2313 - val_loss: 1.6402\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1960 - val_loss: 1.5850\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2229 - val_loss: 1.6039\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1699 - val_loss: 1.5502\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2051 - val_loss: 1.5948\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2258 - val_loss: 1.6086\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2165 - val_loss: 1.6250\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1830 - val_loss: 1.6367\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1782 - val_loss: 1.6231\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1485 - val_loss: 1.6223\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2029 - val_loss: 1.6429\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0916 - val_loss: 1.6814\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 2.3745 - val_loss: 1.4985\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0233 - val_loss: 1.4744\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8762 - val_loss: 1.4644\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8169 - val_loss: 1.4712\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7687 - val_loss: 1.4596\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7774 - val_loss: 1.5076\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7778 - val_loss: 1.5289\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6780 - val_loss: 1.5159\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7022 - val_loss: 1.5310\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6518 - val_loss: 1.5283\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5900 - val_loss: 1.5133\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5921 - val_loss: 1.5439\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6154 - val_loss: 1.5438\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6003 - val_loss: 1.5626\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6008 - val_loss: 1.5500\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5706 - val_loss: 1.5348\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5576 - val_loss: 1.5526\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5487 - val_loss: 1.5623\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4881 - val_loss: 1.5759\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5295 - val_loss: 1.5864\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5048 - val_loss: 1.6113\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5101 - val_loss: 1.6236\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4723 - val_loss: 1.5856\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5402 - val_loss: 1.5722\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4841 - val_loss: 1.5828\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4847 - val_loss: 1.5974\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4526 - val_loss: 1.5947\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4548 - val_loss: 1.5885\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4886 - val_loss: 1.6123\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4757 - val_loss: 1.6204\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4564 - val_loss: 1.6465\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4448 - val_loss: 1.6148\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4219 - val_loss: 1.5837\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3591 - val_loss: 1.6177\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4726 - val_loss: 1.6372\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4185 - val_loss: 1.6284\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3774 - val_loss: 1.6132\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4024 - val_loss: 1.6162\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3158 - val_loss: 1.6286\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3210 - val_loss: 1.6069\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3220 - val_loss: 1.5817\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.3428 - val_loss: 1.6998\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0654 - val_loss: 1.6640\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9623 - val_loss: 1.6322\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7988 - val_loss: 1.5740\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7258 - val_loss: 1.5757\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7409 - val_loss: 1.5809\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7485 - val_loss: 1.5911\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6486 - val_loss: 1.6022\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7139 - val_loss: 1.5624\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5497 - val_loss: 1.5709\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6337 - val_loss: 1.6540\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5928 - val_loss: 1.6101\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6073 - val_loss: 1.6322\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5556 - val_loss: 1.5958\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6082 - val_loss: 1.6161\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7182 - val_loss: 1.6158\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5989 - val_loss: 1.6100\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5090 - val_loss: 1.6134\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5503 - val_loss: 1.6138\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5405 - val_loss: 1.5886\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5118 - val_loss: 1.5682\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5572 - val_loss: 1.5716\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5560 - val_loss: 1.5669\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5531 - val_loss: 1.6191\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4706 - val_loss: 1.6117\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4776 - val_loss: 1.6078\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4671 - val_loss: 1.6018\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4649 - val_loss: 1.6731\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4248 - val_loss: 1.6758\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4355 - val_loss: 1.6600\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4898 - val_loss: 1.6404\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3809 - val_loss: 1.6233\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4214 - val_loss: 1.6231\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4230 - val_loss: 1.5850\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4111 - val_loss: 1.5973\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4363 - val_loss: 1.5979\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4367 - val_loss: 1.5788\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4137 - val_loss: 1.5770\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3276 - val_loss: 1.5889\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3543 - val_loss: 1.5934\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3701 - val_loss: 1.5971\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3306 - val_loss: 1.5978\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3536 - val_loss: 1.5464\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3321 - val_loss: 1.5636\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3018 - val_loss: 1.5532\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3088 - val_loss: 1.5342\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3326 - val_loss: 1.5695\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2676 - val_loss: 1.5758\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2575 - val_loss: 1.5820\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2820 - val_loss: 1.5460\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3220 - val_loss: 1.6411\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2258 - val_loss: 1.6076\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2667 - val_loss: 1.5913\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2247 - val_loss: 1.6093\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2449 - val_loss: 1.6227\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2474 - val_loss: 1.6070\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2197 - val_loss: 1.5960\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1937 - val_loss: 1.6238\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2182 - val_loss: 1.6777\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2424 - val_loss: 1.6490\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1426 - val_loss: 1.6014\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1540 - val_loss: 1.6148\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1719 - val_loss: 1.6204\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1474 - val_loss: 1.6133\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2136 - val_loss: 1.6049\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2123 - val_loss: 1.6551\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1552 - val_loss: 1.6657\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1327 - val_loss: 1.6477\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1730 - val_loss: 1.6950\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1827 - val_loss: 1.6862\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0913 - val_loss: 1.7117\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1163 - val_loss: 1.6943\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1449 - val_loss: 1.7234\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1174 - val_loss: 1.7136\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0514 - val_loss: 1.7196\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0356 - val_loss: 1.7227\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 2.3558 - val_loss: 1.5186\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8298 - val_loss: 1.5340\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8075 - val_loss: 1.5403\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7900 - val_loss: 1.5356\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6994 - val_loss: 1.5523\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7029 - val_loss: 1.5570\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6621 - val_loss: 1.5628\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5877 - val_loss: 1.5557\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6417 - val_loss: 1.5532\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6374 - val_loss: 1.5509\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6296 - val_loss: 1.5606\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5384 - val_loss: 1.5980\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6512 - val_loss: 1.6056\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5677 - val_loss: 1.5836\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5625 - val_loss: 1.5717\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6080 - val_loss: 1.5771\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4610 - val_loss: 1.5648\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5727 - val_loss: 1.5843\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5340 - val_loss: 1.6200\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5308 - val_loss: 1.6049\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5321 - val_loss: 1.6103\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4904 - val_loss: 1.6057\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5038 - val_loss: 1.5454\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4996 - val_loss: 1.5838\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4605 - val_loss: 1.5782\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3738 - val_loss: 1.5897\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4674 - val_loss: 1.6038\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3791 - val_loss: 1.6457\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4402 - val_loss: 1.6287\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4262 - val_loss: 1.6179\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4415 - val_loss: 1.6431\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3930 - val_loss: 1.6795\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4571 - val_loss: 1.6694\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3836 - val_loss: 1.5839\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4754 - val_loss: 1.6008\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4429 - val_loss: 1.6517\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3720 - val_loss: 1.6894\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3936 - val_loss: 1.6072\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3783 - val_loss: 1.6562\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3206 - val_loss: 1.6929\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3320 - val_loss: 1.6985\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3567 - val_loss: 1.6477\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3540 - val_loss: 1.5741\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3228 - val_loss: 1.5467\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3106 - val_loss: 1.5872\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2538 - val_loss: 1.6258\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3139 - val_loss: 1.6031\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3120 - val_loss: 1.6379\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2841 - val_loss: 1.7108\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2713 - val_loss: 1.7065\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2907 - val_loss: 1.7286\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2327 - val_loss: 1.7697\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2905 - val_loss: 1.6602\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 2.2040 - val_loss: 1.4968\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9221 - val_loss: 1.5291\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7301 - val_loss: 1.5255\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7006 - val_loss: 1.5119\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6306 - val_loss: 1.5048\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7378 - val_loss: 1.4973\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7290 - val_loss: 1.4869\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6955 - val_loss: 1.5078\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5679 - val_loss: 1.5209\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6917 - val_loss: 1.5081\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6868 - val_loss: 1.5151\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5962 - val_loss: 1.5416\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6952 - val_loss: 1.5501\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6456 - val_loss: 1.5558\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5681 - val_loss: 1.5586\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6619 - val_loss: 1.5504\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5246 - val_loss: 1.5599\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5061 - val_loss: 1.5817\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5241 - val_loss: 1.6047\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5684 - val_loss: 1.6077\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5197 - val_loss: 1.5960\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4801 - val_loss: 1.5242\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5620 - val_loss: 1.5359\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5358 - val_loss: 1.5617\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5760 - val_loss: 1.5618\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4867 - val_loss: 1.5914\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4471 - val_loss: 1.6068\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4629 - val_loss: 1.6077\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4675 - val_loss: 1.6120\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4237 - val_loss: 1.6486\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4473 - val_loss: 1.6240\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3905 - val_loss: 1.6531\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4027 - val_loss: 1.6895\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3915 - val_loss: 1.7124\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4191 - val_loss: 1.7768\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3276 - val_loss: 1.7562\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3533 - val_loss: 1.7581\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3750 - val_loss: 1.7665\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4284 - val_loss: 1.7688\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3289 - val_loss: 1.7488\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3325 - val_loss: 1.7424\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= 1\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.4286 - val_loss: 1.4396\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9551 - val_loss: 1.4514\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9103 - val_loss: 1.5296\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8809 - val_loss: 1.5136\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8462 - val_loss: 1.5422\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7506 - val_loss: 1.5409\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7429 - val_loss: 1.5393\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7167 - val_loss: 1.5326\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6548 - val_loss: 1.5303\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6443 - val_loss: 1.5339\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5862 - val_loss: 1.5312\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6631 - val_loss: 1.5462\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5839 - val_loss: 1.5502\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6964 - val_loss: 1.5492\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5159 - val_loss: 1.5649\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6096 - val_loss: 1.5663\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5201 - val_loss: 1.5194\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5311 - val_loss: 1.5309\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5042 - val_loss: 1.5082\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5068 - val_loss: 1.5329\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5547 - val_loss: 1.5420\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5004 - val_loss: 1.5418\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4918 - val_loss: 1.5358\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5485 - val_loss: 1.5290\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4856 - val_loss: 1.5229\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5346 - val_loss: 1.5189\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4332 - val_loss: 1.5384\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4684 - val_loss: 1.5550\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5084 - val_loss: 1.5264\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4434 - val_loss: 1.5562\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4266 - val_loss: 1.5569\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4598 - val_loss: 1.5532\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5216 - val_loss: 1.5914\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4472 - val_loss: 1.4994\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4022 - val_loss: 1.5686\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4195 - val_loss: 1.5369\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3577 - val_loss: 1.5439\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4216 - val_loss: 1.6074\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3535 - val_loss: 1.5124\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3069 - val_loss: 1.5955\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3594 - val_loss: 1.5743\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3081 - val_loss: 1.5726\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3489 - val_loss: 1.5828\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2984 - val_loss: 1.5745\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2726 - val_loss: 1.6230\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3064 - val_loss: 1.5723\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3284 - val_loss: 1.6643\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3089 - val_loss: 1.5613\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2417 - val_loss: 1.7183\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2276 - val_loss: 1.7361\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3239 - val_loss: 1.7484\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2853 - val_loss: 1.7639\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2344 - val_loss: 1.7195\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1842 - val_loss: 1.6827\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1946 - val_loss: 1.7011\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2030 - val_loss: 1.7109\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2276 - val_loss: 1.7072\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1898 - val_loss: 1.7097\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2161 - val_loss: 1.6871\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1943 - val_loss: 1.7546\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1058 - val_loss: 1.8103\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1226 - val_loss: 1.8650\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1949 - val_loss: 1.9139\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1542 - val_loss: 1.8548\n",
      "Epoch 64: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 2.3588 - val_loss: 1.4863\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0287 - val_loss: 1.5041\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8115 - val_loss: 1.5114\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6922 - val_loss: 1.4994\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7175 - val_loss: 1.4709\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6777 - val_loss: 1.4802\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7556 - val_loss: 1.4851\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6612 - val_loss: 1.4832\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6846 - val_loss: 1.4838\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6715 - val_loss: 1.4744\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5801 - val_loss: 1.4806\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5650 - val_loss: 1.4972\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5289 - val_loss: 1.5209\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5810 - val_loss: 1.5227\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5171 - val_loss: 1.5087\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5929 - val_loss: 1.4820\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5646 - val_loss: 1.4774\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5066 - val_loss: 1.4586\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5363 - val_loss: 1.4627\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5025 - val_loss: 1.4560\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4808 - val_loss: 1.4415\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5116 - val_loss: 1.4388\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4678 - val_loss: 1.4410\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5093 - val_loss: 1.4418\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4842 - val_loss: 1.4582\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4737 - val_loss: 1.4486\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4916 - val_loss: 1.4640\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4785 - val_loss: 1.5072\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5449 - val_loss: 1.4935\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4477 - val_loss: 1.5208\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3595 - val_loss: 1.5086\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4616 - val_loss: 1.5238\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3450 - val_loss: 1.5284\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3844 - val_loss: 1.5357\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4549 - val_loss: 1.5286\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3557 - val_loss: 1.5366\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3611 - val_loss: 1.5525\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3606 - val_loss: 1.5306\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3794 - val_loss: 1.5313\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3768 - val_loss: 1.5136\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3003 - val_loss: 1.5331\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3625 - val_loss: 1.5309\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3082 - val_loss: 1.5039\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3660 - val_loss: 1.5151\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3766 - val_loss: 1.5175\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3295 - val_loss: 1.5069\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3347 - val_loss: 1.5289\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3425 - val_loss: 1.5112\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3026 - val_loss: 1.5089\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3150 - val_loss: 1.5162\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2656 - val_loss: 1.5151\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3269 - val_loss: 1.5378\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.7150 - val_loss: 1.6709\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0877 - val_loss: 1.6500\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0080 - val_loss: 1.6434\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0797 - val_loss: 1.6012\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8598 - val_loss: 1.6098\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7189 - val_loss: 1.6800\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8290 - val_loss: 1.6452\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8560 - val_loss: 1.6717\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8358 - val_loss: 1.6231\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7633 - val_loss: 1.6301\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8262 - val_loss: 1.6459\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7202 - val_loss: 1.7191\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7626 - val_loss: 1.7090\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6244 - val_loss: 1.6922\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7918 - val_loss: 1.6748\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6840 - val_loss: 1.6492\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7846 - val_loss: 1.6270\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7208 - val_loss: 1.5747\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7075 - val_loss: 1.5791\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6872 - val_loss: 1.6020\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6120 - val_loss: 1.6820\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6254 - val_loss: 1.7095\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6272 - val_loss: 1.7232\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7377 - val_loss: 1.7114\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6009 - val_loss: 1.6758\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5528 - val_loss: 1.6796\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6051 - val_loss: 1.6768\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6336 - val_loss: 1.6356\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5737 - val_loss: 1.6542\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6344 - val_loss: 1.6386\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5524 - val_loss: 1.6213\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5861 - val_loss: 1.6250\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5556 - val_loss: 1.6342\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6017 - val_loss: 1.6490\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5209 - val_loss: 1.6131\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5802 - val_loss: 1.6192\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5619 - val_loss: 1.6298\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5528 - val_loss: 1.6192\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4711 - val_loss: 1.6293\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4583 - val_loss: 1.6270\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4998 - val_loss: 1.6181\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4596 - val_loss: 1.6109\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4879 - val_loss: 1.6017\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4880 - val_loss: 1.6302\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4652 - val_loss: 1.6386\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5689 - val_loss: 1.6233\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4467 - val_loss: 1.6425\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3832 - val_loss: 1.6226\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.3959 - val_loss: 1.5125\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9366 - val_loss: 1.5214\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8305 - val_loss: 1.5639\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7134 - val_loss: 1.5305\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7215 - val_loss: 1.5576\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7371 - val_loss: 1.5420\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6884 - val_loss: 1.5435\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6376 - val_loss: 1.5374\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6825 - val_loss: 1.5444\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6380 - val_loss: 1.5433\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6447 - val_loss: 1.5437\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5480 - val_loss: 1.5255\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5653 - val_loss: 1.5342\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5572 - val_loss: 1.5388\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5739 - val_loss: 1.5300\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5915 - val_loss: 1.5275\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4937 - val_loss: 1.5259\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6048 - val_loss: 1.5386\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5800 - val_loss: 1.5627\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5364 - val_loss: 1.5660\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4473 - val_loss: 1.5604\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5582 - val_loss: 1.5535\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5450 - val_loss: 1.5627\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5635 - val_loss: 1.6047\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5408 - val_loss: 1.5683\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5614 - val_loss: 1.5736\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4760 - val_loss: 1.5699\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4852 - val_loss: 1.5714\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4609 - val_loss: 1.5688\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5201 - val_loss: 1.5596\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4695 - val_loss: 1.5679\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4326 - val_loss: 1.5719\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4487 - val_loss: 1.5721\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3940 - val_loss: 1.5854\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3749 - val_loss: 1.5592\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4323 - val_loss: 1.5898\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3940 - val_loss: 1.6108\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4377 - val_loss: 1.6221\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3112 - val_loss: 1.6172\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3577 - val_loss: 1.5761\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3859 - val_loss: 1.6086\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3872 - val_loss: 1.6101\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.1052 - val_loss: 1.4979\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8195 - val_loss: 1.4846\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7867 - val_loss: 1.4859\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6973 - val_loss: 1.4838\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6973 - val_loss: 1.4694\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6581 - val_loss: 1.4768\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6082 - val_loss: 1.4687\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6227 - val_loss: 1.4752\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5844 - val_loss: 1.4734\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5185 - val_loss: 1.5024\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5910 - val_loss: 1.5038\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5139 - val_loss: 1.4978\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5209 - val_loss: 1.5049\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5590 - val_loss: 1.4977\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4983 - val_loss: 1.5117\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5223 - val_loss: 1.5104\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5200 - val_loss: 1.5181\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4344 - val_loss: 1.5260\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4782 - val_loss: 1.5411\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3821 - val_loss: 1.5609\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5238 - val_loss: 1.5537\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4604 - val_loss: 1.5887\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4112 - val_loss: 1.6043\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3959 - val_loss: 1.6388\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4839 - val_loss: 1.6326\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4063 - val_loss: 1.6443\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4105 - val_loss: 1.6791\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3717 - val_loss: 1.7917\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.3719 - val_loss: 1.7003\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3420 - val_loss: 1.6687\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3580 - val_loss: 1.6765\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3753 - val_loss: 1.6603\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3626 - val_loss: 1.6744\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2967 - val_loss: 1.7164\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2679 - val_loss: 1.7465\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3440 - val_loss: 1.7637\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2687 - val_loss: 1.7629\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2818 - val_loss: 1.7638\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3138 - val_loss: 1.7717\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2865 - val_loss: 1.7701\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1983 - val_loss: 1.7974\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2978 - val_loss: 1.8259\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2091 - val_loss: 1.8359\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2275 - val_loss: 1.8457\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= 2\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.3440 - val_loss: 1.4676\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1199 - val_loss: 1.4696\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8876 - val_loss: 1.5063\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6933 - val_loss: 1.5190\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7139 - val_loss: 1.5302\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6995 - val_loss: 1.5386\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6410 - val_loss: 1.5566\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5605 - val_loss: 1.5472\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5803 - val_loss: 1.5402\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6248 - val_loss: 1.5561\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5323 - val_loss: 1.5520\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7189 - val_loss: 1.5462\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5882 - val_loss: 1.6063\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5170 - val_loss: 1.6317\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5548 - val_loss: 1.6570\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4976 - val_loss: 1.6609\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5790 - val_loss: 1.5434\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5050 - val_loss: 1.5696\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5413 - val_loss: 1.5580\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4999 - val_loss: 1.5491\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5503 - val_loss: 1.5535\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4844 - val_loss: 1.5980\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4694 - val_loss: 1.5922\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4753 - val_loss: 1.6068\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4025 - val_loss: 1.6209\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4406 - val_loss: 1.6160\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4024 - val_loss: 1.6183\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3995 - val_loss: 1.6318\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4098 - val_loss: 1.6132\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3882 - val_loss: 1.5952\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3803 - val_loss: 1.7130\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2868 - val_loss: 1.7376\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3751 - val_loss: 1.7520\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3276 - val_loss: 1.7351\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3349 - val_loss: 1.7757\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2705 - val_loss: 1.6911\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3188 - val_loss: 1.6730\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2436 - val_loss: 1.6906\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2684 - val_loss: 1.7248\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2770 - val_loss: 1.8656\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2820 - val_loss: 1.8560\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1982 - val_loss: 1.8910\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2591 - val_loss: 1.8207\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1933 - val_loss: 1.6675\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2808 - val_loss: 1.6723\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1933 - val_loss: 1.7042\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2163 - val_loss: 1.7431\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 2.3835 - val_loss: 1.5046\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0307 - val_loss: 1.4928\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8351 - val_loss: 1.4885\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7525 - val_loss: 1.5024\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7820 - val_loss: 1.5092\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7661 - val_loss: 1.5081\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6395 - val_loss: 1.5007\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6733 - val_loss: 1.5008\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7037 - val_loss: 1.5177\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6434 - val_loss: 1.5199\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6460 - val_loss: 1.5146\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6502 - val_loss: 1.5210\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5611 - val_loss: 1.5112\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6284 - val_loss: 1.4908\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5441 - val_loss: 1.5070\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6107 - val_loss: 1.5150\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5548 - val_loss: 1.5313\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5752 - val_loss: 1.5653\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5446 - val_loss: 1.5586\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6724 - val_loss: 1.5481\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4768 - val_loss: 1.5562\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5685 - val_loss: 1.5545\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5472 - val_loss: 1.5565\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5256 - val_loss: 1.5455\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4811 - val_loss: 1.5534\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4530 - val_loss: 1.4997\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4319 - val_loss: 1.5379\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4906 - val_loss: 1.5189\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4307 - val_loss: 1.5404\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4478 - val_loss: 1.5409\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4508 - val_loss: 1.5505\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4404 - val_loss: 1.5384\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4260 - val_loss: 1.5604\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4158 - val_loss: 1.5827\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4029 - val_loss: 1.6137\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3892 - val_loss: 1.5844\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3973 - val_loss: 1.5684\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3101 - val_loss: 1.6105\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3848 - val_loss: 1.6155\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3990 - val_loss: 1.6051\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3656 - val_loss: 1.5887\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3167 - val_loss: 1.6078\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3431 - val_loss: 1.5832\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3526 - val_loss: 1.5902\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.5361 - val_loss: 1.6303\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0080 - val_loss: 1.6965\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9090 - val_loss: 1.6794\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8443 - val_loss: 1.6606\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7738 - val_loss: 1.6509\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7906 - val_loss: 1.6503\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7594 - val_loss: 1.6317\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6809 - val_loss: 1.6244\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7156 - val_loss: 1.6306\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6563 - val_loss: 1.6542\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6743 - val_loss: 1.5846\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6818 - val_loss: 1.6335\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5834 - val_loss: 1.6486\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5958 - val_loss: 1.6536\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6827 - val_loss: 1.6538\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5449 - val_loss: 1.6430\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5637 - val_loss: 1.6160\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6479 - val_loss: 1.6817\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5882 - val_loss: 1.6614\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5027 - val_loss: 1.6628\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5773 - val_loss: 1.6360\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5203 - val_loss: 1.5799\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5266 - val_loss: 1.6168\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5553 - val_loss: 1.6052\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4797 - val_loss: 1.6150\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4586 - val_loss: 1.6072\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4934 - val_loss: 1.6095\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4990 - val_loss: 1.6076\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5000 - val_loss: 1.6291\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4881 - val_loss: 1.6661\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4539 - val_loss: 1.6455\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4737 - val_loss: 1.6508\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4199 - val_loss: 1.6660\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4186 - val_loss: 1.6752\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4597 - val_loss: 1.6742\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3836 - val_loss: 1.7011\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3867 - val_loss: 1.6365\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4162 - val_loss: 1.6906\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3810 - val_loss: 1.6574\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3818 - val_loss: 1.6584\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4407 - val_loss: 1.6375\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4060 - val_loss: 1.6276\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4151 - val_loss: 1.6049\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3141 - val_loss: 1.5933\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3672 - val_loss: 1.6014\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3339 - val_loss: 1.6247\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3362 - val_loss: 1.6088\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3334 - val_loss: 1.5946\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3123 - val_loss: 1.5987\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3791 - val_loss: 1.5616\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2643 - val_loss: 1.5792\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2720 - val_loss: 1.6221\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3575 - val_loss: 1.6394\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3149 - val_loss: 1.6306\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3176 - val_loss: 1.6043\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2906 - val_loss: 1.6109\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2385 - val_loss: 1.5959\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3013 - val_loss: 1.6386\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2790 - val_loss: 1.6359\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2925 - val_loss: 1.6495\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2458 - val_loss: 1.6173\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2778 - val_loss: 1.6155\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2705 - val_loss: 1.7175\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2279 - val_loss: 1.7635\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2101 - val_loss: 1.8044\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2110 - val_loss: 1.8286\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2382 - val_loss: 1.8129\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2079 - val_loss: 1.8016\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2447 - val_loss: 1.8134\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2010 - val_loss: 1.7869\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1936 - val_loss: 1.8057\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1433 - val_loss: 1.8284\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1117 - val_loss: 1.8597\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1743 - val_loss: 1.8420\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0963 - val_loss: 1.8160\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1562 - val_loss: 1.7629\n",
      "Epoch 77/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1256 - val_loss: 1.7574\n",
      "Epoch 78/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0844 - val_loss: 1.8271\n",
      "Epoch 79/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0937 - val_loss: 1.8999\n",
      "Epoch 80/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2126 - val_loss: 1.8218\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 2.2304 - val_loss: 1.4075\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9339 - val_loss: 1.5702\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8490 - val_loss: 1.5484\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8410 - val_loss: 1.5475\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7385 - val_loss: 1.5147\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8059 - val_loss: 1.5247\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7644 - val_loss: 1.5000\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7299 - val_loss: 1.5001\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5922 - val_loss: 1.4964\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6206 - val_loss: 1.5213\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6245 - val_loss: 1.5139\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6139 - val_loss: 1.5562\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6555 - val_loss: 1.5260\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6074 - val_loss: 1.5252\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6434 - val_loss: 1.5105\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5572 - val_loss: 1.5203\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5916 - val_loss: 1.5216\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5781 - val_loss: 1.5224\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5942 - val_loss: 1.5398\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6042 - val_loss: 1.5490\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5748 - val_loss: 1.5538\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5799 - val_loss: 1.5501\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5581 - val_loss: 1.5381\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5515 - val_loss: 1.5240\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5311 - val_loss: 1.5225\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5870 - val_loss: 1.5318\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5352 - val_loss: 1.5423\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5383 - val_loss: 1.5276\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4520 - val_loss: 1.5001\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5263 - val_loss: 1.4895\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4788 - val_loss: 1.5302\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4464 - val_loss: 1.5291\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4620 - val_loss: 1.5168\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4468 - val_loss: 1.5213\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4133 - val_loss: 1.5293\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4660 - val_loss: 1.5241\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4431 - val_loss: 1.5271\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4713 - val_loss: 1.5374\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4294 - val_loss: 1.5667\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4383 - val_loss: 1.5759\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4836 - val_loss: 1.5722\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4322 - val_loss: 1.5929\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4570 - val_loss: 1.5636\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4181 - val_loss: 1.5363\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4069 - val_loss: 1.4849\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4092 - val_loss: 1.4728\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3917 - val_loss: 1.4825\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3963 - val_loss: 1.4749\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4031 - val_loss: 1.4763\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3780 - val_loss: 1.5077\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3863 - val_loss: 1.4941\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3194 - val_loss: 1.4754\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3819 - val_loss: 1.4844\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4281 - val_loss: 1.4748\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3815 - val_loss: 1.4795\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3788 - val_loss: 1.4862\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3260 - val_loss: 1.5026\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3167 - val_loss: 1.5067\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3378 - val_loss: 1.5099\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3577 - val_loss: 1.6009\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3080 - val_loss: 1.5612\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3308 - val_loss: 1.5678\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3166 - val_loss: 1.5640\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2557 - val_loss: 1.5670\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2749 - val_loss: 1.5679\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2974 - val_loss: 1.5658\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2102 - val_loss: 1.6372\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3173 - val_loss: 1.5483\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2165 - val_loss: 1.5486\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2332 - val_loss: 1.5422\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2721 - val_loss: 1.5667\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2022 - val_loss: 1.5981\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2524 - val_loss: 1.6098\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2180 - val_loss: 1.6071\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2542 - val_loss: 1.6508\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2064 - val_loss: 1.6108\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 2.4346 - val_loss: 1.4752\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9119 - val_loss: 1.4538\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8159 - val_loss: 1.4598\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8500 - val_loss: 1.4687\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9651 - val_loss: 1.4663\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7884 - val_loss: 1.4969\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7002 - val_loss: 1.5016\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7105 - val_loss: 1.5099\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6187 - val_loss: 1.5080\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6915 - val_loss: 1.5289\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6401 - val_loss: 1.5345\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6439 - val_loss: 1.5284\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6431 - val_loss: 1.5085\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6284 - val_loss: 1.5065\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5677 - val_loss: 1.5065\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5776 - val_loss: 1.5396\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5999 - val_loss: 1.5245\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6205 - val_loss: 1.5339\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5727 - val_loss: 1.6050\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5771 - val_loss: 1.5524\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5884 - val_loss: 1.5179\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5690 - val_loss: 1.4909\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5387 - val_loss: 1.5007\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5591 - val_loss: 1.5198\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6481 - val_loss: 1.5450\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5570 - val_loss: 1.5039\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5449 - val_loss: 1.5126\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5373 - val_loss: 1.5229\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5159 - val_loss: 1.5284\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5336 - val_loss: 1.5284\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5390 - val_loss: 1.5261\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4882 - val_loss: 1.5466\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4717 - val_loss: 1.5421\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4740 - val_loss: 1.5322\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5369 - val_loss: 1.5418\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4573 - val_loss: 1.5418\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4526 - val_loss: 1.5135\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4481 - val_loss: 1.5369\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4155 - val_loss: 1.5662\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5355 - val_loss: 1.5497\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4411 - val_loss: 1.5477\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4154 - val_loss: 1.5613\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3986 - val_loss: 1.5733\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4642 - val_loss: 1.5689\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4171 - val_loss: 1.5699\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3543 - val_loss: 1.5890\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3891 - val_loss: 1.5810\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4505 - val_loss: 1.6097\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3536 - val_loss: 1.6193\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4685 - val_loss: 1.6206\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3747 - val_loss: 1.6222\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3487 - val_loss: 1.6334\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= 3\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 2.4762 - val_loss: 1.4642\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0479 - val_loss: 1.4296\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8194 - val_loss: 1.4438\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9331 - val_loss: 1.4513\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8520 - val_loss: 1.4525\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7253 - val_loss: 1.4667\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7075 - val_loss: 1.4642\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7491 - val_loss: 1.4858\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7188 - val_loss: 1.5044\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7059 - val_loss: 1.5184\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6507 - val_loss: 1.5161\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6533 - val_loss: 1.5047\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7262 - val_loss: 1.5186\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5664 - val_loss: 1.5329\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6987 - val_loss: 1.5456\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5536 - val_loss: 1.5359\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5955 - val_loss: 1.5298\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5709 - val_loss: 1.5457\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5148 - val_loss: 1.5730\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5813 - val_loss: 1.5845\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4603 - val_loss: 1.5919\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5139 - val_loss: 1.5869\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5156 - val_loss: 1.6334\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4356 - val_loss: 1.6101\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4879 - val_loss: 1.6209\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5056 - val_loss: 1.6708\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4843 - val_loss: 1.6161\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4493 - val_loss: 1.6045\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4216 - val_loss: 1.6501\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4293 - val_loss: 1.6349\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4485 - val_loss: 1.5798\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4203 - val_loss: 1.5778\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4341 - val_loss: 1.5591\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3627 - val_loss: 1.6079\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4108 - val_loss: 1.5282\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3724 - val_loss: 1.5874\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3289 - val_loss: 1.5501\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3242 - val_loss: 1.5882\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3601 - val_loss: 1.6037\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3348 - val_loss: 1.5946\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3160 - val_loss: 1.5582\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2327 - val_loss: 1.6846\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 2.1168 - val_loss: 1.4612\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0111 - val_loss: 1.4720\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7422 - val_loss: 1.4685\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6760 - val_loss: 1.4602\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7393 - val_loss: 1.4705\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7604 - val_loss: 1.4581\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7134 - val_loss: 1.4561\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5961 - val_loss: 1.4752\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5821 - val_loss: 1.4938\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6232 - val_loss: 1.4959\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5731 - val_loss: 1.4784\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5457 - val_loss: 1.4732\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5457 - val_loss: 1.4849\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4652 - val_loss: 1.5011\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5810 - val_loss: 1.4655\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4875 - val_loss: 1.4766\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4918 - val_loss: 1.4667\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4763 - val_loss: 1.4497\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4430 - val_loss: 1.4499\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4352 - val_loss: 1.4517\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4874 - val_loss: 1.4390\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4412 - val_loss: 1.4510\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4793 - val_loss: 1.4312\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4413 - val_loss: 1.4382\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3848 - val_loss: 1.4739\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5129 - val_loss: 1.4625\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3900 - val_loss: 1.4776\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4933 - val_loss: 1.4549\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3924 - val_loss: 1.4559\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4003 - val_loss: 1.4597\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4596 - val_loss: 1.4620\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4124 - val_loss: 1.4855\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3818 - val_loss: 1.4795\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4344 - val_loss: 1.4711\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3993 - val_loss: 1.4834\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3700 - val_loss: 1.4729\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3958 - val_loss: 1.4916\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3860 - val_loss: 1.4744\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3434 - val_loss: 1.4773\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3477 - val_loss: 1.5014\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3766 - val_loss: 1.5129\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3352 - val_loss: 1.5080\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3321 - val_loss: 1.4967\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3579 - val_loss: 1.5015\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3219 - val_loss: 1.4646\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3314 - val_loss: 1.4731\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2972 - val_loss: 1.4712\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2801 - val_loss: 1.4751\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2758 - val_loss: 1.4723\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2821 - val_loss: 1.4894\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3138 - val_loss: 1.4895\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1923 - val_loss: 1.5223\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2172 - val_loss: 1.6241\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.3550 - val_loss: 1.6669\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9484 - val_loss: 1.6742\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7999 - val_loss: 1.6584\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7239 - val_loss: 1.6566\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7447 - val_loss: 1.6416\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6571 - val_loss: 1.6435\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6494 - val_loss: 1.6237\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6214 - val_loss: 1.6488\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7807 - val_loss: 1.6489\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6161 - val_loss: 1.6643\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5961 - val_loss: 1.6570\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7101 - val_loss: 1.6493\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5915 - val_loss: 1.6784\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6793 - val_loss: 1.6332\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5651 - val_loss: 1.6359\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5831 - val_loss: 1.6682\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5568 - val_loss: 1.6171\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5343 - val_loss: 1.6463\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5860 - val_loss: 1.6637\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5576 - val_loss: 1.6888\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5223 - val_loss: 1.6336\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4859 - val_loss: 1.6400\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4995 - val_loss: 1.6313\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4478 - val_loss: 1.6153\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4940 - val_loss: 1.6416\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4130 - val_loss: 1.6516\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4911 - val_loss: 1.6411\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3978 - val_loss: 1.6172\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4392 - val_loss: 1.6400\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4375 - val_loss: 1.6224\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4170 - val_loss: 1.5972\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3710 - val_loss: 1.5965\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4082 - val_loss: 1.5927\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3916 - val_loss: 1.6633\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4589 - val_loss: 1.6894\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3565 - val_loss: 1.6575\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3950 - val_loss: 1.6264\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3437 - val_loss: 1.6304\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3651 - val_loss: 1.6070\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3273 - val_loss: 1.6571\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3279 - val_loss: 1.6632\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3767 - val_loss: 1.6418\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3154 - val_loss: 1.6243\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3466 - val_loss: 1.6455\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3381 - val_loss: 1.6339\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2765 - val_loss: 1.7117\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3393 - val_loss: 1.6954\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3801 - val_loss: 1.6850\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2748 - val_loss: 1.7285\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2823 - val_loss: 1.7324\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2544 - val_loss: 1.7453\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2505 - val_loss: 1.7714\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2345 - val_loss: 1.7663\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2821 - val_loss: 1.7859\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2401 - val_loss: 1.7792\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2395 - val_loss: 1.7646\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2092 - val_loss: 1.7807\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1949 - val_loss: 1.7982\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2114 - val_loss: 1.7851\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2709 - val_loss: 1.7614\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1736 - val_loss: 1.7591\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2032 - val_loss: 1.7166\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1607 - val_loss: 1.7337\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 2.2386 - val_loss: 1.6355\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0121 - val_loss: 1.5617\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8525 - val_loss: 1.5726\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8512 - val_loss: 1.5578\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7934 - val_loss: 1.5543\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7793 - val_loss: 1.5649\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8899 - val_loss: 1.5680\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8255 - val_loss: 1.5256\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7090 - val_loss: 1.5926\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6902 - val_loss: 1.5955\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6691 - val_loss: 1.6015\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6533 - val_loss: 1.6111\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7218 - val_loss: 1.5939\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5649 - val_loss: 1.6414\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6502 - val_loss: 1.6487\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6339 - val_loss: 1.6454\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5901 - val_loss: 1.6547\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6521 - val_loss: 1.6528\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5529 - val_loss: 1.6109\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6026 - val_loss: 1.6031\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5739 - val_loss: 1.6024\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5760 - val_loss: 1.6260\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5839 - val_loss: 1.6189\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5580 - val_loss: 1.6058\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5517 - val_loss: 1.6322\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5120 - val_loss: 1.6382\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4925 - val_loss: 1.6848\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5443 - val_loss: 1.7110\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4074 - val_loss: 1.6742\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4906 - val_loss: 1.6758\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5538 - val_loss: 1.6769\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4976 - val_loss: 1.6875\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5179 - val_loss: 1.6952\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4507 - val_loss: 1.6858\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5445 - val_loss: 1.6464\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3957 - val_loss: 1.6294\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4393 - val_loss: 1.6213\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4411 - val_loss: 1.6269\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4000 - val_loss: 1.6030\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4264 - val_loss: 1.5890\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4369 - val_loss: 1.6667\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3813 - val_loss: 1.6646\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4242 - val_loss: 1.6443\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4164 - val_loss: 1.6069\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4443 - val_loss: 1.5906\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4138 - val_loss: 1.5998\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3953 - val_loss: 1.6126\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4441 - val_loss: 1.6217\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3748 - val_loss: 1.6337\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4293 - val_loss: 1.6421\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3891 - val_loss: 1.6494\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3526 - val_loss: 1.6534\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3506 - val_loss: 1.6682\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3377 - val_loss: 1.6610\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3016 - val_loss: 1.6587\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3227 - val_loss: 1.6720\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3540 - val_loss: 1.6953\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3509 - val_loss: 1.6916\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3484 - val_loss: 1.6869\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3154 - val_loss: 1.6899\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2821 - val_loss: 1.6922\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3079 - val_loss: 1.6921\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2666 - val_loss: 1.7452\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3304 - val_loss: 1.7336\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2781 - val_loss: 1.7100\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3245 - val_loss: 1.6979\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2760 - val_loss: 1.7716\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2835 - val_loss: 1.7613\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2545 - val_loss: 1.7184\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2477 - val_loss: 1.6275\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 2.4164 - val_loss: 1.4905\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8661 - val_loss: 1.5083\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9139 - val_loss: 1.5187\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8428 - val_loss: 1.5238\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8742 - val_loss: 1.5230\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7557 - val_loss: 1.5046\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7691 - val_loss: 1.5140\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7597 - val_loss: 1.5229\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6799 - val_loss: 1.4954\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6588 - val_loss: 1.5278\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6571 - val_loss: 1.5301\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7291 - val_loss: 1.5416\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7038 - val_loss: 1.5480\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6770 - val_loss: 1.5511\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5677 - val_loss: 1.5583\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7188 - val_loss: 1.5663\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6734 - val_loss: 1.5782\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6162 - val_loss: 1.5530\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6535 - val_loss: 1.5825\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5652 - val_loss: 1.5943\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6387 - val_loss: 1.5977\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6218 - val_loss: 1.6204\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5455 - val_loss: 1.6040\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5938 - val_loss: 1.5892\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5780 - val_loss: 1.6003\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5324 - val_loss: 1.6170\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6179 - val_loss: 1.6254\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6266 - val_loss: 1.6288\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5539 - val_loss: 1.6041\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5577 - val_loss: 1.6019\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5001 - val_loss: 1.5943\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5350 - val_loss: 1.6081\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5707 - val_loss: 1.5929\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5090 - val_loss: 1.5801\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4688 - val_loss: 1.6085\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4979 - val_loss: 1.6277\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4824 - val_loss: 1.6159\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4178 - val_loss: 1.6469\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4800 - val_loss: 1.6653\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4664 - val_loss: 1.6633\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4618 - val_loss: 1.6619\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= 4\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 2.7544 - val_loss: 1.4825\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1659 - val_loss: 1.4971\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8171 - val_loss: 1.4944\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8914 - val_loss: 1.4203\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8080 - val_loss: 1.4958\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8266 - val_loss: 1.5026\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6845 - val_loss: 1.4959\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7238 - val_loss: 1.5029\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6141 - val_loss: 1.5730\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6490 - val_loss: 1.6010\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6505 - val_loss: 1.5965\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6648 - val_loss: 1.6090\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6786 - val_loss: 1.6143\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5559 - val_loss: 1.6220\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6494 - val_loss: 1.6263\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5432 - val_loss: 1.5858\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4646 - val_loss: 1.6185\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5012 - val_loss: 1.6277\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5155 - val_loss: 1.6824\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6050 - val_loss: 1.6927\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4754 - val_loss: 1.6960\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4970 - val_loss: 1.6904\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5963 - val_loss: 1.6770\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4897 - val_loss: 1.6888\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4736 - val_loss: 1.7315\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4253 - val_loss: 1.7245\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4548 - val_loss: 1.7265\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4416 - val_loss: 1.6670\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4255 - val_loss: 1.6946\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4421 - val_loss: 1.6289\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3787 - val_loss: 1.6685\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4338 - val_loss: 1.7587\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3805 - val_loss: 1.7466\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3838 - val_loss: 1.7660\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3633 - val_loss: 1.6721\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2536 - val_loss: 1.7767\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3765 - val_loss: 1.7508\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3431 - val_loss: 1.7544\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3023 - val_loss: 1.6671\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3243 - val_loss: 1.8050\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2798 - val_loss: 1.7892\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2845 - val_loss: 1.8521\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2797 - val_loss: 1.8898\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2649 - val_loss: 1.8708\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2340 - val_loss: 1.8933\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2657 - val_loss: 1.7361\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 2.3122 - val_loss: 1.4538\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1238 - val_loss: 1.4199\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0789 - val_loss: 1.4422\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8116 - val_loss: 1.4306\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8382 - val_loss: 1.4352\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7278 - val_loss: 1.4063\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7746 - val_loss: 1.3857\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8185 - val_loss: 1.4043\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7124 - val_loss: 1.3807\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6828 - val_loss: 1.3999\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6982 - val_loss: 1.3935\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6805 - val_loss: 1.4131\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6208 - val_loss: 1.3692\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5671 - val_loss: 1.3916\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5254 - val_loss: 1.4293\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6289 - val_loss: 1.4237\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6837 - val_loss: 1.3904\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7075 - val_loss: 1.3765\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5036 - val_loss: 1.3708\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.6333 - val_loss: 1.4049\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5686 - val_loss: 1.4034\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5795 - val_loss: 1.3807\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5494 - val_loss: 1.3774\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5487 - val_loss: 1.3852\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5426 - val_loss: 1.3906\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5306 - val_loss: 1.3965\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5298 - val_loss: 1.3744\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5429 - val_loss: 1.3650\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5828 - val_loss: 1.3554\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5283 - val_loss: 1.3523\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5337 - val_loss: 1.3593\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5259 - val_loss: 1.3948\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5247 - val_loss: 1.3568\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4789 - val_loss: 1.3621\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5152 - val_loss: 1.3979\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4966 - val_loss: 1.3502\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4626 - val_loss: 1.3587\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4147 - val_loss: 1.3573\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4322 - val_loss: 1.3508\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.4304 - val_loss: 1.3320\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4158 - val_loss: 1.4192\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4430 - val_loss: 1.4056\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4729 - val_loss: 1.3948\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3746 - val_loss: 1.3672\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4511 - val_loss: 1.3372\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3846 - val_loss: 1.3647\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4285 - val_loss: 1.4105\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4087 - val_loss: 1.4191\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4921 - val_loss: 1.4030\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3593 - val_loss: 1.4158\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4398 - val_loss: 1.4379\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3751 - val_loss: 1.4436\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3850 - val_loss: 1.4368\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3935 - val_loss: 1.4376\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3380 - val_loss: 1.4479\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3598 - val_loss: 1.4332\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3395 - val_loss: 1.4244\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3153 - val_loss: 1.4228\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3589 - val_loss: 1.4192\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3191 - val_loss: 1.4225\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2864 - val_loss: 1.4270\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3640 - val_loss: 1.4624\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3216 - val_loss: 1.4463\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3247 - val_loss: 1.4059\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3197 - val_loss: 1.4132\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3207 - val_loss: 1.4066\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2716 - val_loss: 1.3904\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.3207 - val_loss: 1.4188\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3323 - val_loss: 1.4116\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2895 - val_loss: 1.4247\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 2.2932 - val_loss: 1.6187\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2.0641 - val_loss: 1.6661\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9593 - val_loss: 1.6635\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8140 - val_loss: 1.6363\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7368 - val_loss: 1.6457\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.7604 - val_loss: 1.6474\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.7902 - val_loss: 1.6606\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.7493 - val_loss: 1.6495\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6888 - val_loss: 1.6662\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.6612 - val_loss: 1.6967\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.6965 - val_loss: 1.6909\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.6566 - val_loss: 1.6574\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6606 - val_loss: 1.6465\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.4993 - val_loss: 1.6618\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.6634 - val_loss: 1.6918\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.5324 - val_loss: 1.6876\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.6030 - val_loss: 1.6958\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.5916 - val_loss: 1.6941\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5334 - val_loss: 1.6782\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.6074 - val_loss: 1.6916\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5675 - val_loss: 1.6838\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6052 - val_loss: 1.6989\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5457 - val_loss: 1.6997\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5050 - val_loss: 1.6946\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5944 - val_loss: 1.6785\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.5821 - val_loss: 1.7089\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.5199 - val_loss: 1.7205\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4876 - val_loss: 1.7117\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.5425 - val_loss: 1.6944\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4733 - val_loss: 1.7348\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4613 - val_loss: 1.7285\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4671 - val_loss: 1.7487\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4919 - val_loss: 1.7461\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4557 - val_loss: 1.7312\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.4149 - val_loss: 1.7411\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4714 - val_loss: 1.7551\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4219 - val_loss: 1.8386\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4537 - val_loss: 1.8375\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.3997 - val_loss: 1.8150\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3986 - val_loss: 1.8515\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4167 - val_loss: 1.8402\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3891 - val_loss: 1.8558\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3566 - val_loss: 1.8689\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 3 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 2.1566 - val_loss: 1.6404\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8813 - val_loss: 1.5779\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8419 - val_loss: 1.5582\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8447 - val_loss: 1.5662\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.7459 - val_loss: 1.5589\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.7420 - val_loss: 1.5205\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6431 - val_loss: 1.5533\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7121 - val_loss: 1.5644\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6961 - val_loss: 1.5604\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6741 - val_loss: 1.5697\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5957 - val_loss: 1.5943\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5701 - val_loss: 1.5997\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6153 - val_loss: 1.5720\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5179 - val_loss: 1.6070\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.5680 - val_loss: 1.5999\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5787 - val_loss: 1.6336\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.5304 - val_loss: 1.6686\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.4951 - val_loss: 1.6586\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5177 - val_loss: 1.6902\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6136 - val_loss: 1.6769\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5898 - val_loss: 1.6372\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4957 - val_loss: 1.6299\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5605 - val_loss: 1.6286\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5486 - val_loss: 1.6344\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4703 - val_loss: 1.6463\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4988 - val_loss: 1.6414\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - loss: 1.5372 - val_loss: 1.6263\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5130 - val_loss: 1.6342\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4435 - val_loss: 1.6337\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4617 - val_loss: 1.6449\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3876 - val_loss: 1.6545\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4586 - val_loss: 1.6514\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4192 - val_loss: 1.6586\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4627 - val_loss: 1.6536\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4367 - val_loss: 1.6435\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4224 - val_loss: 1.6347\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4671 - val_loss: 1.5871\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4193 - val_loss: 1.5957\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4850 - val_loss: 1.6110\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3829 - val_loss: 1.6079\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3926 - val_loss: 1.6224\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4422 - val_loss: 1.6216\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3489 - val_loss: 1.6507\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 5 fold 4 gamma= 0\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.1716 - val_loss: 1.5882\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9156 - val_loss: 1.5543\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7422 - val_loss: 1.5543\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7690 - val_loss: 1.5510\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7489 - val_loss: 1.5382\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7597 - val_loss: 1.5713\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7162 - val_loss: 1.5423\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6431 - val_loss: 1.5495\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6693 - val_loss: 1.5434\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6315 - val_loss: 1.5484\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6328 - val_loss: 1.5523\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6274 - val_loss: 1.5869\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5954 - val_loss: 1.6080\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6078 - val_loss: 1.6011\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6254 - val_loss: 1.5994\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5798 - val_loss: 1.5801\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5198 - val_loss: 1.6006\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6088 - val_loss: 1.6063\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5750 - val_loss: 1.6002\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5803 - val_loss: 1.6032\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5438 - val_loss: 1.6139\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5573 - val_loss: 1.6182\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5595 - val_loss: 1.6223\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5833 - val_loss: 1.6261\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.4908 - val_loss: 1.6119\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5433 - val_loss: 1.5898\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4966 - val_loss: 1.5546\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5012 - val_loss: 1.5770\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4715 - val_loss: 1.5682\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4978 - val_loss: 1.5593\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4671 - val_loss: 1.5854\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4825 - val_loss: 1.5835\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4323 - val_loss: 1.5947\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4550 - val_loss: 1.5910\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5165 - val_loss: 1.6065\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.4411 - val_loss: 1.5769\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3416 - val_loss: 1.5970\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3779 - val_loss: 1.6355\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4421 - val_loss: 1.6463\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.4280 - val_loss: 1.6413\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3842 - val_loss: 1.6245\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 5 gamma= 0\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 2.2172 - val_loss: 1.3966\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9549 - val_loss: 1.3966\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8176 - val_loss: 1.3869\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7821 - val_loss: 1.4065\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7301 - val_loss: 1.4231\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7157 - val_loss: 1.4101\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7118 - val_loss: 1.3766\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6282 - val_loss: 1.3718\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6844 - val_loss: 1.3683\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6591 - val_loss: 1.3816\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6468 - val_loss: 1.3842\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6596 - val_loss: 1.4016\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6162 - val_loss: 1.3767\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5830 - val_loss: 1.3750\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5994 - val_loss: 1.3904\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5298 - val_loss: 1.4199\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4842 - val_loss: 1.4208\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.5415 - val_loss: 1.4061\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4896 - val_loss: 1.3998\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5586 - val_loss: 1.4165\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4916 - val_loss: 1.4299\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4571 - val_loss: 1.4618\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4803 - val_loss: 1.4544\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5003 - val_loss: 1.4828\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.4271 - val_loss: 1.4528\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3595 - val_loss: 1.4524\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4426 - val_loss: 1.4356\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.3932 - val_loss: 1.4588\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3471 - val_loss: 1.5127\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3918 - val_loss: 1.5314\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3279 - val_loss: 1.5323\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 866ms/step - loss: 1.3681 - val_loss: 1.5321\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2760 - val_loss: 1.5022\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.2823 - val_loss: 1.5635\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.3415 - val_loss: 1.5455\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3188 - val_loss: 1.5657\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.2909 - val_loss: 1.5908\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.2842 - val_loss: 1.5526\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2809 - val_loss: 1.5637\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2370 - val_loss: 1.5459\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2636 - val_loss: 1.5745\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2539 - val_loss: 1.5588\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2822 - val_loss: 1.5470\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1426 - val_loss: 1.5458\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 2.3029 - val_loss: 1.4427\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8498 - val_loss: 1.4047\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9116 - val_loss: 1.4225\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8052 - val_loss: 1.3868\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6953 - val_loss: 1.3972\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7944 - val_loss: 1.4127\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6803 - val_loss: 1.3950\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7151 - val_loss: 1.4336\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6958 - val_loss: 1.4213\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6259 - val_loss: 1.3829\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6991 - val_loss: 1.4038\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6458 - val_loss: 1.3819\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6214 - val_loss: 1.4061\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6093 - val_loss: 1.3951\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6367 - val_loss: 1.4098\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6011 - val_loss: 1.4034\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5793 - val_loss: 1.4104\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5557 - val_loss: 1.4106\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5664 - val_loss: 1.3974\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5558 - val_loss: 1.4023\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6095 - val_loss: 1.3934\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5583 - val_loss: 1.3970\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5666 - val_loss: 1.4226\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5772 - val_loss: 1.4196\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4985 - val_loss: 1.4162\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5318 - val_loss: 1.4039\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5191 - val_loss: 1.4215\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5435 - val_loss: 1.4330\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5167 - val_loss: 1.4353\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4349 - val_loss: 1.4464\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5025 - val_loss: 1.4377\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4337 - val_loss: 1.4443\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4673 - val_loss: 1.4583\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5002 - val_loss: 1.4552\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4743 - val_loss: 1.4773\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4439 - val_loss: 1.4643\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4510 - val_loss: 1.4470\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3912 - val_loss: 1.4404\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4061 - val_loss: 1.4441\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3926 - val_loss: 1.4286\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4067 - val_loss: 1.4206\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3440 - val_loss: 1.4328\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.0493 - val_loss: 1.6466\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7024 - val_loss: 1.6906\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6976 - val_loss: 1.7004\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7272 - val_loss: 1.7068\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7061 - val_loss: 1.6722\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6179 - val_loss: 1.6774\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6452 - val_loss: 1.6804\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7269 - val_loss: 1.6837\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6251 - val_loss: 1.6827\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6170 - val_loss: 1.6798\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5864 - val_loss: 1.6854\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5994 - val_loss: 1.6725\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5630 - val_loss: 1.6726\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6171 - val_loss: 1.6868\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5502 - val_loss: 1.6581\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5710 - val_loss: 1.6512\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5910 - val_loss: 1.6605\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.5772 - val_loss: 1.6503\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - loss: 1.5195 - val_loss: 1.6605\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5293 - val_loss: 1.6581\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5514 - val_loss: 1.6590\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.4773 - val_loss: 1.6884\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4224 - val_loss: 1.6598\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.4677 - val_loss: 1.6610\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4649 - val_loss: 1.7068\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.4892 - val_loss: 1.7098\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.3574 - val_loss: 1.7187\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4070 - val_loss: 1.7178\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4220 - val_loss: 1.7047\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4220 - val_loss: 1.7138\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3897 - val_loss: 1.7392\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3390 - val_loss: 1.7247\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.3087 - val_loss: 1.7226\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3399 - val_loss: 1.7659\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.3947 - val_loss: 1.7854\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3025 - val_loss: 1.7907\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3267 - val_loss: 1.8075\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3114 - val_loss: 1.8119\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.2682 - val_loss: 1.8230\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2956 - val_loss: 1.8409\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2795 - val_loss: 1.8488\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2546 - val_loss: 1.9452\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2494 - val_loss: 1.9197\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3266 - val_loss: 1.9578\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2612 - val_loss: 1.9631\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.2473 - val_loss: 1.9683\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2483 - val_loss: 1.9613\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2019 - val_loss: 1.9174\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Real LSTM seed 5 fold 3 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.4529 - val_loss: 1.6516\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9274 - val_loss: 1.6247\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8834 - val_loss: 1.6134\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7448 - val_loss: 1.6137\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7857 - val_loss: 1.6194\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7972 - val_loss: 1.6367\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7340 - val_loss: 1.6455\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7046 - val_loss: 1.6443\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6439 - val_loss: 1.6538\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6591 - val_loss: 1.6602\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6077 - val_loss: 1.6670\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6472 - val_loss: 1.6255\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7045 - val_loss: 1.6037\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6744 - val_loss: 1.6085\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6676 - val_loss: 1.5906\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6065 - val_loss: 1.5730\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6567 - val_loss: 1.5775\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6759 - val_loss: 1.5813\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6096 - val_loss: 1.5804\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6818 - val_loss: 1.5844\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6504 - val_loss: 1.5845\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6039 - val_loss: 1.5909\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6028 - val_loss: 1.5975\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.6657 - val_loss: 1.5900\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5784 - val_loss: 1.6153\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5006 - val_loss: 1.6128\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5204 - val_loss: 1.6092\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.5604 - val_loss: 1.5912\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5564 - val_loss: 1.5918\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5782 - val_loss: 1.6315\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5186 - val_loss: 1.6235\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4925 - val_loss: 1.6047\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5179 - val_loss: 1.6137\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5061 - val_loss: 1.6261\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5082 - val_loss: 1.6308\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5192 - val_loss: 1.6432\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4933 - val_loss: 1.6357\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4676 - val_loss: 1.6491\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4639 - val_loss: 1.6611\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4827 - val_loss: 1.6630\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4765 - val_loss: 1.6600\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4043 - val_loss: 1.6429\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4417 - val_loss: 1.6614\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4043 - val_loss: 1.6504\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4201 - val_loss: 1.6295\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5016 - val_loss: 1.6438\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 4 gamma= 1\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 2.2237 - val_loss: 1.5205\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9968 - val_loss: 1.5045\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8117 - val_loss: 1.5109\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7392 - val_loss: 1.5110\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7039 - val_loss: 1.5202\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7544 - val_loss: 1.5434\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7211 - val_loss: 1.5488\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6437 - val_loss: 1.5511\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7041 - val_loss: 1.5413\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6610 - val_loss: 1.5255\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6826 - val_loss: 1.5349\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5968 - val_loss: 1.5479\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 15s/step - loss: 1.6050 - val_loss: 1.5446\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.5872 - val_loss: 1.5256\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6120 - val_loss: 1.5122\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5297 - val_loss: 1.5031\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5916 - val_loss: 1.4956\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6048 - val_loss: 1.5262\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5847 - val_loss: 1.5073\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.5385 - val_loss: 1.5395\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.5783 - val_loss: 1.5589\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5463 - val_loss: 1.5385\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5400 - val_loss: 1.5303\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5023 - val_loss: 1.5272\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5131 - val_loss: 1.5495\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5119 - val_loss: 1.5318\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4884 - val_loss: 1.5159\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.5042 - val_loss: 1.5248\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4287 - val_loss: 1.5412\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4509 - val_loss: 1.5441\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4251 - val_loss: 1.5601\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4517 - val_loss: 1.5563\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4608 - val_loss: 1.5775\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4154 - val_loss: 1.5866\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4411 - val_loss: 1.5658\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4382 - val_loss: 1.5771\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4328 - val_loss: 1.5834\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5084 - val_loss: 1.5945\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3812 - val_loss: 1.5937\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3801 - val_loss: 1.5521\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.3627 - val_loss: 1.5597\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3604 - val_loss: 1.5360\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4360 - val_loss: 1.5519\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3720 - val_loss: 1.5264\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3679 - val_loss: 1.5166\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3340 - val_loss: 1.5690\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4075 - val_loss: 1.5863\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 5 gamma= 1\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.3963 - val_loss: 1.4135\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9207 - val_loss: 1.4241\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0140 - val_loss: 1.4272\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8171 - val_loss: 1.4828\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7764 - val_loss: 1.4311\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7735 - val_loss: 1.4019\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6694 - val_loss: 1.4325\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7162 - val_loss: 1.3987\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6415 - val_loss: 1.3806\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6585 - val_loss: 1.4005\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6649 - val_loss: 1.4099\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5956 - val_loss: 1.4149\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6248 - val_loss: 1.4044\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.5604 - val_loss: 1.4046\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5445 - val_loss: 1.4241\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5757 - val_loss: 1.4418\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5302 - val_loss: 1.4182\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4858 - val_loss: 1.4060\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5681 - val_loss: 1.4249\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4260 - val_loss: 1.4126\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5308 - val_loss: 1.4537\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4775 - val_loss: 1.4838\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4455 - val_loss: 1.4422\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4228 - val_loss: 1.4645\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4458 - val_loss: 1.3987\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3875 - val_loss: 1.4160\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.3947 - val_loss: 1.4151\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3803 - val_loss: 1.4573\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3883 - val_loss: 1.4573\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4217 - val_loss: 1.4470\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3616 - val_loss: 1.4624\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3576 - val_loss: 1.4297\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3389 - val_loss: 1.4312\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.3819 - val_loss: 1.4439\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3360 - val_loss: 1.4393\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3368 - val_loss: 1.5274\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3012 - val_loss: 1.5382\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3747 - val_loss: 1.5347\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3498 - val_loss: 1.4507\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3207 - val_loss: 1.4834\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2843 - val_loss: 1.5256\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.2593 - val_loss: 1.4983\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2660 - val_loss: 1.4995\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2552 - val_loss: 1.5056\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2128 - val_loss: 1.5137\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2116 - val_loss: 1.4957\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2318 - val_loss: 1.5007\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.2233 - val_loss: 1.4789\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2686 - val_loss: 1.5790\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2398 - val_loss: 1.4350\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2490 - val_loss: 1.4912\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1725 - val_loss: 1.4692\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2234 - val_loss: 1.5388\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1843 - val_loss: 1.5145\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.1515 - val_loss: 1.5413\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.3741 - val_loss: 1.4192\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8886 - val_loss: 1.4471\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8282 - val_loss: 1.4044\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7877 - val_loss: 1.4137\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7705 - val_loss: 1.4110\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7245 - val_loss: 1.4139\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6458 - val_loss: 1.4043\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6677 - val_loss: 1.4220\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6572 - val_loss: 1.4349\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6302 - val_loss: 1.4202\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7043 - val_loss: 1.4321\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5580 - val_loss: 1.4388\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6928 - val_loss: 1.4240\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6044 - val_loss: 1.4177\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5830 - val_loss: 1.4453\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5072 - val_loss: 1.4320\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5653 - val_loss: 1.4265\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5027 - val_loss: 1.4085\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5891 - val_loss: 1.3964\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5604 - val_loss: 1.4123\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4975 - val_loss: 1.4003\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5660 - val_loss: 1.3960\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5680 - val_loss: 1.4007\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5062 - val_loss: 1.4107\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4007 - val_loss: 1.4217\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4845 - val_loss: 1.4311\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5088 - val_loss: 1.4421\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4422 - val_loss: 1.4484\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4807 - val_loss: 1.4312\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4844 - val_loss: 1.4303\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4712 - val_loss: 1.4247\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4013 - val_loss: 1.4309\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4906 - val_loss: 1.4138\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5152 - val_loss: 1.3932\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4753 - val_loss: 1.3832\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4549 - val_loss: 1.3779\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4577 - val_loss: 1.3812\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.5025 - val_loss: 1.3578\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.4140 - val_loss: 1.3720\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4040 - val_loss: 1.3682\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3614 - val_loss: 1.3739\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4068 - val_loss: 1.3657\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3765 - val_loss: 1.3737\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4064 - val_loss: 1.3822\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.3972 - val_loss: 1.3901\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3787 - val_loss: 1.3967\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3208 - val_loss: 1.4145\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3467 - val_loss: 1.4309\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3487 - val_loss: 1.4195\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2979 - val_loss: 1.4146\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3488 - val_loss: 1.3971\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3717 - val_loss: 1.4489\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3369 - val_loss: 1.4418\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3763 - val_loss: 1.4648\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2855 - val_loss: 1.4665\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3034 - val_loss: 1.4641\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2376 - val_loss: 1.4596\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2663 - val_loss: 1.4599\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2648 - val_loss: 1.4504\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2829 - val_loss: 1.4228\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2782 - val_loss: 1.4176\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2191 - val_loss: 1.4287\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3113 - val_loss: 1.4516\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2593 - val_loss: 1.4323\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2004 - val_loss: 1.4061\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2405 - val_loss: 1.4110\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2074 - val_loss: 1.4133\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2675 - val_loss: 1.4351\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 2.4158 - val_loss: 1.6381\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9350 - val_loss: 1.6165\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9722 - val_loss: 1.7144\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8882 - val_loss: 1.6986\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7653 - val_loss: 1.6829\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7091 - val_loss: 1.6638\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7235 - val_loss: 1.6808\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7127 - val_loss: 1.6448\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7213 - val_loss: 1.6382\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 1.6419 - val_loss: 1.6569\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.5991 - val_loss: 1.6144\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1.6450 - val_loss: 1.6290\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6306 - val_loss: 1.6541\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6089 - val_loss: 1.6288\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5615 - val_loss: 1.6433\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5693 - val_loss: 1.6375\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6115 - val_loss: 1.6491\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6079 - val_loss: 1.6688\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5979 - val_loss: 1.6811\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5037 - val_loss: 1.6799\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5076 - val_loss: 1.6865\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5271 - val_loss: 1.7031\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5007 - val_loss: 1.6743\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4651 - val_loss: 1.6923\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5164 - val_loss: 1.6949\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5380 - val_loss: 1.7226\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5178 - val_loss: 1.7078\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4577 - val_loss: 1.7123\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4389 - val_loss: 1.7022\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3825 - val_loss: 1.7151\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4315 - val_loss: 1.7032\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3693 - val_loss: 1.7122\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3892 - val_loss: 1.7855\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4615 - val_loss: 1.7313\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3811 - val_loss: 1.8045\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4136 - val_loss: 1.8216\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3515 - val_loss: 1.8117\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3330 - val_loss: 1.7744\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3759 - val_loss: 1.7337\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3504 - val_loss: 1.7726\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3355 - val_loss: 1.7678\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 3 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.0387 - val_loss: 1.5569\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9192 - val_loss: 1.5772\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8341 - val_loss: 1.5811\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7319 - val_loss: 1.5823\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6365 - val_loss: 1.5721\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7041 - val_loss: 1.6456\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6861 - val_loss: 1.5524\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6711 - val_loss: 1.5791\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6466 - val_loss: 1.5588\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6671 - val_loss: 1.5890\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6448 - val_loss: 1.5675\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6378 - val_loss: 1.5593\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5606 - val_loss: 1.5817\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5757 - val_loss: 1.5831\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.5625 - val_loss: 1.5794\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5876 - val_loss: 1.5624\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4549 - val_loss: 1.5773\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5336 - val_loss: 1.5740\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5837 - val_loss: 1.5585\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5381 - val_loss: 1.5715\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5363 - val_loss: 1.5525\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4709 - val_loss: 1.5585\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5347 - val_loss: 1.5684\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.5234 - val_loss: 1.5432\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4511 - val_loss: 1.5778\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4610 - val_loss: 1.5842\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4602 - val_loss: 1.5979\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4463 - val_loss: 1.5739\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.4601 - val_loss: 1.5866\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4236 - val_loss: 1.5805\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4717 - val_loss: 1.5873\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4106 - val_loss: 1.6092\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4270 - val_loss: 1.6233\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.4119 - val_loss: 1.6308\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3739 - val_loss: 1.6128\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.3399 - val_loss: 1.6081\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.4110 - val_loss: 1.5879\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3683 - val_loss: 1.6111\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.3231 - val_loss: 1.6248\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.3461 - val_loss: 1.6352\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.3163 - val_loss: 1.6578\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.3718 - val_loss: 1.6544\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3965 - val_loss: 1.6666\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3612 - val_loss: 1.7711\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4269 - val_loss: 1.8032\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3139 - val_loss: 1.7757\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3836 - val_loss: 1.7481\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3324 - val_loss: 1.7396\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3300 - val_loss: 1.7344\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3756 - val_loss: 1.7386\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3933 - val_loss: 1.7487\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3659 - val_loss: 1.7569\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2824 - val_loss: 1.7715\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2452 - val_loss: 1.7450\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Real LSTM seed 5 fold 4 gamma= 2\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 2.2640 - val_loss: 1.5728\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9840 - val_loss: 1.6198\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8906 - val_loss: 1.6362\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8661 - val_loss: 1.6637\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7994 - val_loss: 1.6328\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8443 - val_loss: 1.6364\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7581 - val_loss: 1.6493\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7400 - val_loss: 1.6622\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7796 - val_loss: 1.6263\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7762 - val_loss: 1.6176\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7255 - val_loss: 1.5869\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7102 - val_loss: 1.5736\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6534 - val_loss: 1.5889\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7289 - val_loss: 1.5274\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6327 - val_loss: 1.5876\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6390 - val_loss: 1.5930\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6145 - val_loss: 1.5835\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5719 - val_loss: 1.5770\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6138 - val_loss: 1.5940\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6478 - val_loss: 1.5769\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6253 - val_loss: 1.5964\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5898 - val_loss: 1.6105\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6372 - val_loss: 1.6326\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6716 - val_loss: 1.6167\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6930 - val_loss: 1.5377\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5675 - val_loss: 1.5585\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5718 - val_loss: 1.5280\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5816 - val_loss: 1.5488\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6375 - val_loss: 1.5627\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6004 - val_loss: 1.5808\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5553 - val_loss: 1.5724\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5609 - val_loss: 1.5854\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5537 - val_loss: 1.5851\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5301 - val_loss: 1.5580\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4893 - val_loss: 1.5727\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5644 - val_loss: 1.5966\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4873 - val_loss: 1.5698\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4665 - val_loss: 1.5698\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4890 - val_loss: 1.5750\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4772 - val_loss: 1.5653\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4755 - val_loss: 1.5696\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5849 - val_loss: 1.5932\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5212 - val_loss: 1.6230\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4514 - val_loss: 1.6783\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 5 gamma= 2\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 2.3994 - val_loss: 1.4691\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9107 - val_loss: 1.4345\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.8145 - val_loss: 1.4190\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8106 - val_loss: 1.4321\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7850 - val_loss: 1.4424\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6679 - val_loss: 1.4361\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7254 - val_loss: 1.4361\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6876 - val_loss: 1.4516\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6122 - val_loss: 1.4633\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7135 - val_loss: 1.4838\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6654 - val_loss: 1.4838\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6423 - val_loss: 1.4695\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5956 - val_loss: 1.5153\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6620 - val_loss: 1.5162\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5873 - val_loss: 1.5109\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5491 - val_loss: 1.5057\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5174 - val_loss: 1.4758\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5248 - val_loss: 1.4721\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4720 - val_loss: 1.4705\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5399 - val_loss: 1.4587\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5456 - val_loss: 1.4440\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5468 - val_loss: 1.4576\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5041 - val_loss: 1.4633\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4757 - val_loss: 1.4455\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5218 - val_loss: 1.4342\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4092 - val_loss: 1.4373\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4267 - val_loss: 1.4579\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4300 - val_loss: 1.4720\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4316 - val_loss: 1.4443\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3847 - val_loss: 1.4184\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3382 - val_loss: 1.4372\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4278 - val_loss: 1.4500\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3758 - val_loss: 1.4391\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3319 - val_loss: 1.4373\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3382 - val_loss: 1.4581\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3348 - val_loss: 1.4599\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2944 - val_loss: 1.4696\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3167 - val_loss: 1.4903\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3397 - val_loss: 1.5309\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2853 - val_loss: 1.4740\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2544 - val_loss: 1.4841\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2451 - val_loss: 1.4992\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2516 - val_loss: 1.4803\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2467 - val_loss: 1.4956\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2278 - val_loss: 1.4848\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1913 - val_loss: 1.4979\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1881 - val_loss: 1.4613\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2335 - val_loss: 1.5009\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1973 - val_loss: 1.4432\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2374 - val_loss: 1.4943\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2175 - val_loss: 1.5556\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1770 - val_loss: 1.4709\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1871 - val_loss: 1.4726\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2086 - val_loss: 1.4472\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2196 - val_loss: 1.4950\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1853 - val_loss: 1.4782\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1390 - val_loss: 1.4302\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1603 - val_loss: 1.4605\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1506 - val_loss: 1.4969\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2109 - val_loss: 1.5659\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 2.1318 - val_loss: 1.4196\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9723 - val_loss: 1.4041\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8503 - val_loss: 1.4088\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6524 - val_loss: 1.4172\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7013 - val_loss: 1.3972\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6442 - val_loss: 1.3899\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6567 - val_loss: 1.3848\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6077 - val_loss: 1.4049\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6393 - val_loss: 1.4106\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5556 - val_loss: 1.4087\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5840 - val_loss: 1.4034\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5412 - val_loss: 1.4041\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5709 - val_loss: 1.4083\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5143 - val_loss: 1.4147\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5742 - val_loss: 1.4057\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5919 - val_loss: 1.3987\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5501 - val_loss: 1.4029\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4788 - val_loss: 1.3977\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5424 - val_loss: 1.3934\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5149 - val_loss: 1.4075\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4986 - val_loss: 1.3987\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5127 - val_loss: 1.3790\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4160 - val_loss: 1.3579\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4274 - val_loss: 1.3607\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4307 - val_loss: 1.3852\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3757 - val_loss: 1.3796\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4132 - val_loss: 1.3995\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3746 - val_loss: 1.4080\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4365 - val_loss: 1.3748\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3901 - val_loss: 1.3679\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3796 - val_loss: 1.3968\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3274 - val_loss: 1.4238\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3354 - val_loss: 1.4403\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3792 - val_loss: 1.4521\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4279 - val_loss: 1.4495\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3841 - val_loss: 1.4693\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3611 - val_loss: 1.5063\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4360 - val_loss: 1.4288\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3268 - val_loss: 1.4039\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3554 - val_loss: 1.3939\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3519 - val_loss: 1.3707\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3205 - val_loss: 1.3657\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2968 - val_loss: 1.4061\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2995 - val_loss: 1.3677\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3016 - val_loss: 1.3776\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2534 - val_loss: 1.3822\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2393 - val_loss: 1.3936\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2548 - val_loss: 1.3932\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2503 - val_loss: 1.4020\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2526 - val_loss: 1.3720\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2718 - val_loss: 1.3956\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2708 - val_loss: 1.4036\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2462 - val_loss: 1.4325\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 2.2126 - val_loss: 1.5928\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0257 - val_loss: 1.5856\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9431 - val_loss: 1.6076\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8072 - val_loss: 1.6176\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8117 - val_loss: 1.6074\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7778 - val_loss: 1.6070\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7388 - val_loss: 1.6321\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1.6788 - val_loss: 1.6384\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1.7332 - val_loss: 1.6417\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6678 - val_loss: 1.6417\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6629 - val_loss: 1.6241\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6303 - val_loss: 1.6476\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.5823 - val_loss: 1.6517\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6207 - val_loss: 1.6590\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.6087 - val_loss: 1.6214\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.6138 - val_loss: 1.6250\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.6205 - val_loss: 1.6086\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5114 - val_loss: 1.6550\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6445 - val_loss: 1.6246\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5482 - val_loss: 1.6126\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.4663 - val_loss: 1.6040\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1.5839 - val_loss: 1.5881\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4808 - val_loss: 1.5553\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4683 - val_loss: 1.5347\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5542 - val_loss: 1.5713\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.4961 - val_loss: 1.5817\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.4748 - val_loss: 1.5713\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4804 - val_loss: 1.5974\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4105 - val_loss: 1.6151\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4283 - val_loss: 1.6370\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4447 - val_loss: 1.6291\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4496 - val_loss: 1.6295\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.4242 - val_loss: 1.6762\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4087 - val_loss: 1.6397\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.3825 - val_loss: 1.6604\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.3726 - val_loss: 1.6591\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1.2829 - val_loss: 1.6339\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.3650 - val_loss: 1.6338\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.3950 - val_loss: 1.6398\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.3758 - val_loss: 1.6024\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.3480 - val_loss: 1.5774\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3932 - val_loss: 1.6067\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3147 - val_loss: 1.6493\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2891 - val_loss: 1.6614\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3351 - val_loss: 1.6858\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3395 - val_loss: 1.6792\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2558 - val_loss: 1.6906\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3111 - val_loss: 1.7219\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3268 - val_loss: 1.6941\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2394 - val_loss: 1.6777\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3149 - val_loss: 1.7289\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2472 - val_loss: 1.6993\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3303 - val_loss: 1.7069\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2876 - val_loss: 1.7206\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 3 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 2.3622 - val_loss: 1.6285\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.0034 - val_loss: 1.6437\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8433 - val_loss: 1.6923\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8877 - val_loss: 1.6402\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.7702 - val_loss: 1.6458\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.7894 - val_loss: 1.6481\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.8576 - val_loss: 1.6253\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.8309 - val_loss: 1.6099\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.6600 - val_loss: 1.5738\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.6802 - val_loss: 1.6063\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.6804 - val_loss: 1.5866\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5708 - val_loss: 1.5719\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.6502 - val_loss: 1.5719\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6743 - val_loss: 1.5631\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.5922 - val_loss: 1.5718\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5944 - val_loss: 1.5729\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5516 - val_loss: 1.5947\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5827 - val_loss: 1.6042\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5270 - val_loss: 1.6272\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6443 - val_loss: 1.6277\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4916 - val_loss: 1.6102\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.5314 - val_loss: 1.6368\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5858 - val_loss: 1.6523\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.5047 - val_loss: 1.6333\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5021 - val_loss: 1.6340\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5168 - val_loss: 1.6454\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.4928 - val_loss: 1.6661\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1.4589 - val_loss: 1.6363\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5282 - val_loss: 1.6674\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4527 - val_loss: 1.6925\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4578 - val_loss: 1.6701\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.5127 - val_loss: 1.6596\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.3950 - val_loss: 1.6469\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4351 - val_loss: 1.6410\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4612 - val_loss: 1.6493\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4746 - val_loss: 1.7094\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3963 - val_loss: 1.6666\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3899 - val_loss: 1.6682\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5067 - val_loss: 1.6623\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3834 - val_loss: 1.6913\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4730 - val_loss: 1.6755\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3929 - val_loss: 1.6980\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4068 - val_loss: 1.7020\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3838 - val_loss: 1.6904\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 5 fold 4 gamma= 3\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - loss: 2.1708 - val_loss: 1.5732\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.9391 - val_loss: 1.6384\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 1.7297 - val_loss: 1.5792\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.8025 - val_loss: 1.5556\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.7466 - val_loss: 1.5810\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.6564 - val_loss: 1.5355\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6760 - val_loss: 1.5533\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.6086 - val_loss: 1.5518\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.6968 - val_loss: 1.5945\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1.6009 - val_loss: 1.6014\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1.6561 - val_loss: 1.5882\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.6705 - val_loss: 1.5897\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.6263 - val_loss: 1.5740\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1.6187 - val_loss: 1.5580\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6057 - val_loss: 1.5951\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5522 - val_loss: 1.5908\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.5950 - val_loss: 1.5936\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.5845 - val_loss: 1.5870\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.5818 - val_loss: 1.5771\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5908 - val_loss: 1.5688\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.5685 - val_loss: 1.5770\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1.5159 - val_loss: 1.5877\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.5454 - val_loss: 1.5898\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 1.5550 - val_loss: 1.6054\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.5506 - val_loss: 1.5943\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1.5090 - val_loss: 1.5870\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.5266 - val_loss: 1.6138\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.5150 - val_loss: 1.6296\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.4909 - val_loss: 1.5816\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1.5052 - val_loss: 1.6021\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 1.5246 - val_loss: 1.6057\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.4569 - val_loss: 1.6118\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.4272 - val_loss: 1.6128\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4943 - val_loss: 1.6188\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4742 - val_loss: 1.5868\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4957 - val_loss: 1.5932\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5724 - val_loss: 1.5676\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4682 - val_loss: 1.5838\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4973 - val_loss: 1.5841\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4649 - val_loss: 1.5793\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3983 - val_loss: 1.5698\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4577 - val_loss: 1.6003\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4307 - val_loss: 1.6169\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4206 - val_loss: 1.6186\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 5 fold 5 gamma= 3\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 2.6278 - val_loss: 1.4813\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.1579 - val_loss: 1.4747\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 2.0691 - val_loss: 1.4485\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8942 - val_loss: 1.4460\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.8999 - val_loss: 1.4668\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.7574 - val_loss: 1.4573\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.7714 - val_loss: 1.4529\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.8444 - val_loss: 1.4587\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.7898 - val_loss: 1.4443\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1.7351 - val_loss: 1.4605\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6975 - val_loss: 1.4801\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7420 - val_loss: 1.4714\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7944 - val_loss: 1.4431\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6040 - val_loss: 1.4081\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6250 - val_loss: 1.4057\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5739 - val_loss: 1.4171\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.6012 - val_loss: 1.4546\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6081 - val_loss: 1.4466\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6131 - val_loss: 1.4349\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6498 - val_loss: 1.4421\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5718 - val_loss: 1.4474\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6170 - val_loss: 1.4311\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6314 - val_loss: 1.4165\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5865 - val_loss: 1.4324\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.5552 - val_loss: 1.4319\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5448 - val_loss: 1.4338\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5543 - val_loss: 1.4378\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5544 - val_loss: 1.4243\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5512 - val_loss: 1.4380\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4939 - val_loss: 1.4458\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5031 - val_loss: 1.4490\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5189 - val_loss: 1.4393\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5137 - val_loss: 1.4243\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.4178 - val_loss: 1.4158\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4201 - val_loss: 1.4029\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4237 - val_loss: 1.4046\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3906 - val_loss: 1.4125\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3581 - val_loss: 1.4174\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3547 - val_loss: 1.3971\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.3892 - val_loss: 1.4205\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.3757 - val_loss: 1.3631\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3427 - val_loss: 1.4141\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3223 - val_loss: 1.3884\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3533 - val_loss: 1.3791\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3610 - val_loss: 1.3989\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3433 - val_loss: 1.4028\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3053 - val_loss: 1.4446\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2468 - val_loss: 1.4616\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3237 - val_loss: 1.4501\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2916 - val_loss: 1.4861\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.2623 - val_loss: 1.4539\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2462 - val_loss: 1.5052\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2026 - val_loss: 1.5110\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2930 - val_loss: 1.5707\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2651 - val_loss: 1.4715\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2142 - val_loss: 1.4671\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2442 - val_loss: 1.5120\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2518 - val_loss: 1.5237\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1965 - val_loss: 1.5137\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2409 - val_loss: 1.5318\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1715 - val_loss: 1.4850\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1853 - val_loss: 1.5157\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1972 - val_loss: 1.5469\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1424 - val_loss: 1.5075\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2207 - val_loss: 1.5305\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.1883 - val_loss: 1.5798\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1373 - val_loss: 1.5713\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1394 - val_loss: 1.5904\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0976 - val_loss: 1.6171\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.0934 - val_loss: 1.6348\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0692 - val_loss: 1.6614\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.4093 - val_loss: 1.4313\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9482 - val_loss: 1.4076\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.8979 - val_loss: 1.3830\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7993 - val_loss: 1.4168\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8710 - val_loss: 1.4124\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7936 - val_loss: 1.4106\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7689 - val_loss: 1.3838\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7812 - val_loss: 1.4311\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7302 - val_loss: 1.4110\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7308 - val_loss: 1.4228\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6356 - val_loss: 1.4053\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.7045 - val_loss: 1.4070\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.7282 - val_loss: 1.4014\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.7062 - val_loss: 1.4153\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1.6417 - val_loss: 1.4306\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.6182 - val_loss: 1.3994\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.6577 - val_loss: 1.3971\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5816 - val_loss: 1.3880\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5896 - val_loss: 1.3917\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6192 - val_loss: 1.3759\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5364 - val_loss: 1.3683\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5183 - val_loss: 1.3614\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.6271 - val_loss: 1.3404\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.4957 - val_loss: 1.3444\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.5096 - val_loss: 1.4085\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5638 - val_loss: 1.3959\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.5004 - val_loss: 1.4120\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5129 - val_loss: 1.3952\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5094 - val_loss: 1.4041\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4443 - val_loss: 1.3842\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4707 - val_loss: 1.4020\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.4514 - val_loss: 1.3996\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4666 - val_loss: 1.4047\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.4736 - val_loss: 1.4144\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5108 - val_loss: 1.4473\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.5072 - val_loss: 1.4608\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.3906 - val_loss: 1.4611\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4269 - val_loss: 1.4667\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3786 - val_loss: 1.4576\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4121 - val_loss: 1.4240\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.3920 - val_loss: 1.4191\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.4334 - val_loss: 1.4489\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3775 - val_loss: 1.4583\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3621 - val_loss: 1.4389\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.3865 - val_loss: 1.4523\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3516 - val_loss: 1.4689\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.3541 - val_loss: 1.4818\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3531 - val_loss: 1.4758\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3801 - val_loss: 1.4741\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.2825 - val_loss: 1.4643\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3098 - val_loss: 1.4339\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2870 - val_loss: 1.4251\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3372 - val_loss: 1.4462\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 2.5437 - val_loss: 1.5762\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0639 - val_loss: 1.5826\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8662 - val_loss: 1.5792\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8945 - val_loss: 1.5891\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8526 - val_loss: 1.5808\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7569 - val_loss: 1.5848\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7660 - val_loss: 1.5820\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7443 - val_loss: 1.5859\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7002 - val_loss: 1.5748\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.8098 - val_loss: 1.5729\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.7018 - val_loss: 1.5758\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1.6915 - val_loss: 1.5738\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6564 - val_loss: 1.5885\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5878 - val_loss: 1.5984\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.6955 - val_loss: 1.6018\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6927 - val_loss: 1.5877\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6663 - val_loss: 1.6114\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6668 - val_loss: 1.6076\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7102 - val_loss: 1.5895\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5852 - val_loss: 1.5821\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5313 - val_loss: 1.5872\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5540 - val_loss: 1.5777\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5085 - val_loss: 1.6050\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5362 - val_loss: 1.6184\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5743 - val_loss: 1.6042\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5142 - val_loss: 1.5930\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6178 - val_loss: 1.6077\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5201 - val_loss: 1.6176\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.5997 - val_loss: 1.6380\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5651 - val_loss: 1.6236\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.4966 - val_loss: 1.6176\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.5163 - val_loss: 1.6127\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4759 - val_loss: 1.6095\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5334 - val_loss: 1.6272\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5477 - val_loss: 1.6399\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4380 - val_loss: 1.6523\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4374 - val_loss: 1.6355\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5239 - val_loss: 1.6314\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4643 - val_loss: 1.5702\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.5069 - val_loss: 1.5782\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.4844 - val_loss: 1.5754\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.4292 - val_loss: 1.5697\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4350 - val_loss: 1.5552\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.4931 - val_loss: 1.5619\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.4270 - val_loss: 1.6001\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4960 - val_loss: 1.5763\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4651 - val_loss: 1.5736\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.4615 - val_loss: 1.6119\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4111 - val_loss: 1.5727\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.4556 - val_loss: 1.5838\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4538 - val_loss: 1.6203\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4200 - val_loss: 1.6058\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.4214 - val_loss: 1.5799\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4428 - val_loss: 1.6483\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3770 - val_loss: 1.6263\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3970 - val_loss: 1.6078\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.3274 - val_loss: 1.5911\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.3665 - val_loss: 1.5977\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.3689 - val_loss: 1.6080\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3294 - val_loss: 1.6209\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3746 - val_loss: 1.5901\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3583 - val_loss: 1.5814\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3558 - val_loss: 1.6018\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.3217 - val_loss: 1.6041\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2862 - val_loss: 1.6231\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3417 - val_loss: 1.6242\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3379 - val_loss: 1.6234\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2630 - val_loss: 1.6213\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2911 - val_loss: 1.5815\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2596 - val_loss: 1.5869\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2821 - val_loss: 1.6190\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.2708 - val_loss: 1.6436\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2363 - val_loss: 1.6384\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Real LSTM seed 5 fold 3 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 78ms/step - loss: 2.4677 - val_loss: 1.5802\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 2.0289 - val_loss: 1.5099\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.8319 - val_loss: 1.4998\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8178 - val_loss: 1.5057\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8683 - val_loss: 1.5116\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.6660 - val_loss: 1.5145\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7289 - val_loss: 1.5295\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.8100 - val_loss: 1.5417\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.7044 - val_loss: 1.5734\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7591 - val_loss: 1.6184\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.6499 - val_loss: 1.6068\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6896 - val_loss: 1.5870\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.7499 - val_loss: 1.5910\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.6093 - val_loss: 1.5797\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6867 - val_loss: 1.5725\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.6996 - val_loss: 1.5728\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.5827 - val_loss: 1.5948\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1.6945 - val_loss: 1.5795\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.6219 - val_loss: 1.5869\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.5604 - val_loss: 1.5877\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.5922 - val_loss: 1.5913\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5591 - val_loss: 1.5852\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6044 - val_loss: 1.5876\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6415 - val_loss: 1.5936\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1.5745 - val_loss: 1.5898\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6260 - val_loss: 1.5905\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.5808 - val_loss: 1.5844\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6393 - val_loss: 1.5913\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6103 - val_loss: 1.5987\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5003 - val_loss: 1.6230\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5307 - val_loss: 1.6220\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.5349 - val_loss: 1.6295\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.4473 - val_loss: 1.6340\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5240 - val_loss: 1.6309\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4824 - val_loss: 1.6434\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5212 - val_loss: 1.6653\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4773 - val_loss: 1.6824\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5039 - val_loss: 1.6719\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4970 - val_loss: 1.6579\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4404 - val_loss: 1.6431\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4729 - val_loss: 1.6346\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4849 - val_loss: 1.6445\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.4962 - val_loss: 1.6135\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5022 - val_loss: 1.6249\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.4924 - val_loss: 1.6241\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Real LSTM seed 5 fold 4 gamma= 4\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - loss: 2.1487 - val_loss: 1.5295\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.9451 - val_loss: 1.5313\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8934 - val_loss: 1.5452\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.8770 - val_loss: 1.5483\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.8650 - val_loss: 1.5591\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1.8515 - val_loss: 1.5623\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 1.8449 - val_loss: 1.5918\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7317 - val_loss: 1.5826\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8373 - val_loss: 1.5633\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7486 - val_loss: 1.5904\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7911 - val_loss: 1.5998\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6342 - val_loss: 1.5995\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7453 - val_loss: 1.6074\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6442 - val_loss: 1.6087\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6239 - val_loss: 1.6187\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6378 - val_loss: 1.6092\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6860 - val_loss: 1.6018\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5819 - val_loss: 1.5852\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6198 - val_loss: 1.6047\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6234 - val_loss: 1.6009\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5667 - val_loss: 1.5850\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6050 - val_loss: 1.5657\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5633 - val_loss: 1.5788\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5407 - val_loss: 1.5813\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5289 - val_loss: 1.6054\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5393 - val_loss: 1.5504\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5149 - val_loss: 1.5605\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4754 - val_loss: 1.5892\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5040 - val_loss: 1.6063\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5133 - val_loss: 1.5938\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5123 - val_loss: 1.6281\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4312 - val_loss: 1.6313\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4481 - val_loss: 1.6356\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4867 - val_loss: 1.6599\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4345 - val_loss: 1.6625\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4505 - val_loss: 1.6608\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4300 - val_loss: 1.6838\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4445 - val_loss: 1.7222\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3877 - val_loss: 1.7251\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4489 - val_loss: 1.6996\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4528 - val_loss: 1.7169\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3608 - val_loss: 1.7155\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3961 - val_loss: 1.7178\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3982 - val_loss: 1.7034\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3420 - val_loss: 1.7202\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3328 - val_loss: 1.7478\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3173 - val_loss: 1.7493\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3494 - val_loss: 1.7350\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3263 - val_loss: 1.7468\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2787 - val_loss: 1.8132\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2829 - val_loss: 1.7684\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3425 - val_loss: 1.7111\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3015 - val_loss: 1.7483\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3102 - val_loss: 1.7604\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2189 - val_loss: 1.7811\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2704 - val_loss: 1.8380\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Real LSTM seed 5 fold 5 gamma= 4\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 2.2223 - val_loss: 1.3587\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8427 - val_loss: 1.3975\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7513 - val_loss: 1.4128\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7283 - val_loss: 1.4228\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6705 - val_loss: 1.4216\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6061 - val_loss: 1.4234\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6352 - val_loss: 1.4245\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6681 - val_loss: 1.4393\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6323 - val_loss: 1.4536\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5964 - val_loss: 1.4528\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6358 - val_loss: 1.4657\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5816 - val_loss: 1.4067\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5479 - val_loss: 1.4155\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5359 - val_loss: 1.4227\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5258 - val_loss: 1.4600\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4205 - val_loss: 1.4351\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4940 - val_loss: 1.4365\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4437 - val_loss: 1.4302\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4717 - val_loss: 1.3958\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4526 - val_loss: 1.4113\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4593 - val_loss: 1.4086\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4298 - val_loss: 1.4262\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4317 - val_loss: 1.4622\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4522 - val_loss: 1.4643\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3923 - val_loss: 1.4986\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3794 - val_loss: 1.4980\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3623 - val_loss: 1.4948\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4202 - val_loss: 1.4909\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3362 - val_loss: 1.5227\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3455 - val_loss: 1.5434\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3749 - val_loss: 1.5470\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2929 - val_loss: 1.5199\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4121 - val_loss: 1.5115\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3062 - val_loss: 1.5195\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3343 - val_loss: 1.5058\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3339 - val_loss: 1.5895\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3213 - val_loss: 1.5780\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3276 - val_loss: 1.5521\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2816 - val_loss: 1.5603\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2302 - val_loss: 1.5382\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2341 - val_loss: 1.5708\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2402 - val_loss: 1.5215\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2251 - val_loss: 1.5216\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3087 - val_loss: 1.5601\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2269 - val_loss: 1.5800\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2400 - val_loss: 1.5905\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1378 - val_loss: 1.5724\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1897 - val_loss: 1.6104\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1263 - val_loss: 1.6184\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]])]}\n"
     ]
    }
   ],
   "source": [
    "f_scores_test = dict()\n",
    "p_scores_test = dict()\n",
    "r_scores_test = dict()\n",
    "y_test_predictions = dict()\n",
    "for cell in cell_list:\n",
    "    for real in ['Real']:#, 'Random']:\n",
    "        f_scores_test[f'{real} {cell}'] = []\n",
    "        p_scores_test[f'{real} {cell}'] = []\n",
    "        r_scores_test[f'{real} {cell}'] = []\n",
    "        y_test_predictions[f'{real} {cell}'] = []\n",
    "\n",
    "# f_scores_train = {k: [] for k in cell_list} #gets score distribution for diff cells across splits\n",
    "for seed in range(5): #range(len(bps)):\n",
    "    for gamma in range(5):\n",
    "        train_eval_RNNs(train=bps[seed][0], test=bps[seed][1], seed=seed, decision='threshmax', random_bl=False, sampling=None, gamma=gamma)\n",
    "    # train_eval_RNNs(train=bps[seed][0], test=bps[seed][1], seed=seed, decision='argmax', random_bl=True, sampling='dem_prev')\n",
    "\n",
    "f_score_arrays_test = {k: np.stack(v, axis=0) for k,v in f_scores_test.items()}\n",
    "p_score_arrays_test = {k: np.stack(v, axis=0) for k,v in p_scores_test.items()}\n",
    "r_score_arrays_test = {k: np.stack(v, axis=0) for k,v in r_scores_test.items()}\n",
    "# f_score_arrays_train = {k: np.stack(v, axis=0) for k,v in f_scores_train.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real LSTM seed 1 fold 1 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 1.4859 - val_loss: 1.0228\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2411 - val_loss: 1.0191\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2592 - val_loss: 1.0147\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1496 - val_loss: 1.0115\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1685 - val_loss: 1.0098\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1356 - val_loss: 1.0082\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1324 - val_loss: 1.0075\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2116 - val_loss: 1.0060\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0858 - val_loss: 1.0108\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1059 - val_loss: 1.0115\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1267 - val_loss: 1.0115\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0990 - val_loss: 1.0098\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1184 - val_loss: 1.0075\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0602 - val_loss: 1.0127\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1313 - val_loss: 1.0107\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0974 - val_loss: 1.0148\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0695 - val_loss: 1.0177\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0381 - val_loss: 1.0254\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0603 - val_loss: 1.0324\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0303 - val_loss: 1.0360\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0118 - val_loss: 1.0472\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0120 - val_loss: 1.0478\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0485 - val_loss: 1.0626\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9893 - val_loss: 1.0647\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9901 - val_loss: 1.0620\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0228 - val_loss: 1.0535\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0336 - val_loss: 1.0593\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9879 - val_loss: 1.0657\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9479 - val_loss: 1.0674\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0028 - val_loss: 1.0642\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9478 - val_loss: 1.0619\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9891 - val_loss: 1.0788\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9532 - val_loss: 1.1002\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9442 - val_loss: 1.1275\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9792 - val_loss: 1.1226\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9024 - val_loss: 1.1187\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9170 - val_loss: 1.1243\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9663 - val_loss: 1.1240\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9088 - val_loss: 1.1255\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8811 - val_loss: 1.1486\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8673 - val_loss: 1.1509\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8949 - val_loss: 1.1551\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8676 - val_loss: 1.1698\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 2 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 1.4594 - val_loss: 0.9585\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2780 - val_loss: 0.9609\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2055 - val_loss: 0.9558\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1865 - val_loss: 0.9612\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2132 - val_loss: 0.9656\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1235 - val_loss: 0.9596\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1333 - val_loss: 0.9546\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0966 - val_loss: 0.9579\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0834 - val_loss: 0.9649\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1297 - val_loss: 0.9665\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0863 - val_loss: 0.9715\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0582 - val_loss: 0.9759\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0679 - val_loss: 0.9722\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0852 - val_loss: 0.9742\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1210 - val_loss: 0.9652\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0733 - val_loss: 0.9674\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0364 - val_loss: 0.9647\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0681 - val_loss: 0.9656\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0182 - val_loss: 0.9629\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0475 - val_loss: 0.9614\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0238 - val_loss: 0.9516\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0603 - val_loss: 0.9548\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0182 - val_loss: 0.9591\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0235 - val_loss: 0.9395\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0267 - val_loss: 0.9301\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0296 - val_loss: 0.9228\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0336 - val_loss: 0.9429\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0164 - val_loss: 0.9360\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0022 - val_loss: 0.9148\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9718 - val_loss: 0.9274\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9815 - val_loss: 0.9253\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9791 - val_loss: 0.9369\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9787 - val_loss: 0.9385\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9530 - val_loss: 0.9391\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9347 - val_loss: 0.9452\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9528 - val_loss: 0.9750\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9478 - val_loss: 0.9626\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9401 - val_loss: 0.9772\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9063 - val_loss: 0.9905\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9096 - val_loss: 0.9821\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8768 - val_loss: 0.9750\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9220 - val_loss: 1.0126\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8991 - val_loss: 0.9766\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9110 - val_loss: 0.9465\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8955 - val_loss: 0.9609\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9110 - val_loss: 0.9615\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8996 - val_loss: 0.9658\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8749 - val_loss: 0.9699\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8880 - val_loss: 0.9859\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8292 - val_loss: 0.9798\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8794 - val_loss: 0.9910\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8478 - val_loss: 0.9991\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8486 - val_loss: 1.0076\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8084 - val_loss: 0.9976\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8292 - val_loss: 1.0231\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8345 - val_loss: 1.0360\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8343 - val_loss: 1.0077\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8462 - val_loss: 0.9872\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8479 - val_loss: 0.9880\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 1 fold 3 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 1.5640 - val_loss: 0.9742\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2887 - val_loss: 0.9709\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2352 - val_loss: 0.9715\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2217 - val_loss: 0.9695\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1939 - val_loss: 0.9668\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1030 - val_loss: 0.9615\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1403 - val_loss: 0.9582\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2036 - val_loss: 0.9596\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1280 - val_loss: 0.9609\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1357 - val_loss: 0.9571\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1512 - val_loss: 0.9568\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1523 - val_loss: 0.9563\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1106 - val_loss: 0.9699\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1428 - val_loss: 0.9881\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0901 - val_loss: 1.0053\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0754 - val_loss: 1.0100\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0911 - val_loss: 1.0067\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0751 - val_loss: 1.0030\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0766 - val_loss: 0.9988\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0572 - val_loss: 0.9853\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1180 - val_loss: 0.9880\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0588 - val_loss: 0.9983\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0938 - val_loss: 0.9950\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0185 - val_loss: 1.0050\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0760 - val_loss: 1.0201\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0413 - val_loss: 1.0171\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0641 - val_loss: 1.0599\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1035 - val_loss: 1.0486\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0711 - val_loss: 1.0420\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0875 - val_loss: 1.0350\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0586 - val_loss: 1.0285\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0480 - val_loss: 1.0329\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0536 - val_loss: 1.0353\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0241 - val_loss: 1.0333\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0311 - val_loss: 1.0389\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9991 - val_loss: 1.0468\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0049 - val_loss: 1.0373\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0737 - val_loss: 1.0323\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9943 - val_loss: 1.0245\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9869 - val_loss: 1.0304\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0086 - val_loss: 1.0228\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9683 - val_loss: 1.0196\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Real LSTM seed 1 fold 4 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 1.4924 - val_loss: 1.0962\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3208 - val_loss: 1.0983\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2390 - val_loss: 1.0979\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1959 - val_loss: 1.0967\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2116 - val_loss: 1.0959\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1700 - val_loss: 1.0904\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1846 - val_loss: 1.0867\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1604 - val_loss: 1.0869\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2045 - val_loss: 1.0819\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1326 - val_loss: 1.0811\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1412 - val_loss: 1.0733\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0615 - val_loss: 1.0710\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1271 - val_loss: 1.0766\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0465 - val_loss: 1.0744\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0729 - val_loss: 1.0673\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0862 - val_loss: 1.0705\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1094 - val_loss: 1.0789\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1030 - val_loss: 1.0841\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1062 - val_loss: 1.0911\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0338 - val_loss: 1.0890\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0320 - val_loss: 1.0892\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0591 - val_loss: 1.0914\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0204 - val_loss: 1.0893\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0278 - val_loss: 1.0871\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0270 - val_loss: 1.0740\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0234 - val_loss: 1.1190\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0548 - val_loss: 1.1368\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0214 - val_loss: 1.1563\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0316 - val_loss: 1.1477\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9884 - val_loss: 1.1493\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0007 - val_loss: 1.1557\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9898 - val_loss: 1.1710\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0055 - val_loss: 1.1824\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9942 - val_loss: 1.1793\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9969 - val_loss: 1.1691\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9926 - val_loss: 1.1746\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9560 - val_loss: 1.1915\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9416 - val_loss: 1.1805\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9419 - val_loss: 1.1804\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9700 - val_loss: 1.1776\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9630 - val_loss: 1.1624\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9409 - val_loss: 1.1663\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9572 - val_loss: 1.1959\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9183 - val_loss: 1.2124\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9403 - val_loss: 1.1962\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Real LSTM seed 1 fold 5 gamma= none\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 1.5357 - val_loss: 0.9962\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2964 - val_loss: 0.9952\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2624 - val_loss: 0.9914\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1409 - val_loss: 0.9897\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1736 - val_loss: 0.9889\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2180 - val_loss: 0.9884\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1566 - val_loss: 0.9875\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1601 - val_loss: 0.9897\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1344 - val_loss: 0.9883\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1291 - val_loss: 0.9861\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1025 - val_loss: 0.9854\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0611 - val_loss: 0.9819\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1129 - val_loss: 0.9777\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0593 - val_loss: 0.9832\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0930 - val_loss: 0.9872\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0916 - val_loss: 0.9886\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0698 - val_loss: 0.9969\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1030 - val_loss: 1.0040\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0269 - val_loss: 1.0108\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0467 - val_loss: 1.0148\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0196 - val_loss: 1.0194\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0103 - val_loss: 1.0174\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0156 - val_loss: 1.0387\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9914 - val_loss: 1.0393\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0226 - val_loss: 1.0377\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9618 - val_loss: 1.0434\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9495 - val_loss: 1.0581\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9575 - val_loss: 1.0644\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9837 - val_loss: 1.0658\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9464 - val_loss: 1.0630\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9745 - val_loss: 1.0756\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9549 - val_loss: 1.0453\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9679 - val_loss: 1.0359\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9118 - val_loss: 1.0664\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9709 - val_loss: 1.0707\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9233 - val_loss: 1.0707\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8787 - val_loss: 1.1010\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8643 - val_loss: 1.1218\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8737 - val_loss: 1.1169\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8946 - val_loss: 1.0982\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8198 - val_loss: 1.0963\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8690 - val_loss: 1.0957\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8541 - val_loss: 1.1066\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]]), array([[0.47706422, 0.72392638, 0.02380952],\n",
      "       [0.46919431, 0.72040816, 0.04166667],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.48347107, 0.6056338 , 0.26315789]])]}\n",
      "Real LSTM seed 2 fold 1 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 1.3441 - val_loss: 1.2637\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2067 - val_loss: 1.2590\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2033 - val_loss: 1.2564\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1633 - val_loss: 1.2679\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1597 - val_loss: 1.2624\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1135 - val_loss: 1.2626\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1426 - val_loss: 1.2609\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0513 - val_loss: 1.2601\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1064 - val_loss: 1.2682\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0572 - val_loss: 1.2904\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0718 - val_loss: 1.2916\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0666 - val_loss: 1.3086\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0961 - val_loss: 1.3409\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0545 - val_loss: 1.3501\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0690 - val_loss: 1.3617\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0529 - val_loss: 1.3758\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0479 - val_loss: 1.3825\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0370 - val_loss: 1.3816\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0125 - val_loss: 1.3819\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0207 - val_loss: 1.3643\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9806 - val_loss: 1.3594\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9772 - val_loss: 1.3781\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9762 - val_loss: 1.3971\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9710 - val_loss: 1.4339\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9656 - val_loss: 1.4346\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9632 - val_loss: 1.4426\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9289 - val_loss: 1.4545\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9371 - val_loss: 1.4761\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8976 - val_loss: 1.4907\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9241 - val_loss: 1.5131\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9559 - val_loss: 1.5291\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9083 - val_loss: 1.5271\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8875 - val_loss: 1.5601\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8854 - val_loss: 1.5899\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8915 - val_loss: 1.6417\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9317 - val_loss: 1.6907\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8743 - val_loss: 1.6782\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8623 - val_loss: 1.7551\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8622 - val_loss: 1.7034\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9136 - val_loss: 1.7000\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8339 - val_loss: 1.7151\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Real LSTM seed 2 fold 2 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 1.6039 - val_loss: 1.0804\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3409 - val_loss: 1.0819\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2950 - val_loss: 1.0790\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1947 - val_loss: 1.0778\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1666 - val_loss: 1.0816\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1246 - val_loss: 1.0825\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1698 - val_loss: 1.0885\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1190 - val_loss: 1.0909\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0918 - val_loss: 1.0830\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1014 - val_loss: 1.0800\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1277 - val_loss: 1.0906\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1257 - val_loss: 1.0990\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1106 - val_loss: 1.1055\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0560 - val_loss: 1.1058\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1024 - val_loss: 1.1099\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0557 - val_loss: 1.1175\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0675 - val_loss: 1.1136\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0599 - val_loss: 1.1071\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0598 - val_loss: 1.1201\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0391 - val_loss: 1.1236\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0338 - val_loss: 1.1420\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0263 - val_loss: 1.1568\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0258 - val_loss: 1.1620\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0089 - val_loss: 1.1481\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9721 - val_loss: 1.1325\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9956 - val_loss: 1.1358\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9795 - val_loss: 1.1239\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9710 - val_loss: 1.1295\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9462 - val_loss: 1.1321\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9387 - val_loss: 1.1395\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9359 - val_loss: 1.1340\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9360 - val_loss: 1.1217\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9242 - val_loss: 1.1507\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9320 - val_loss: 1.1619\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9213 - val_loss: 1.1553\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9667 - val_loss: 1.1441\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8801 - val_loss: 1.1376\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9040 - val_loss: 1.1406\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8884 - val_loss: 1.1734\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9053 - val_loss: 1.1762\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8787 - val_loss: 1.1757\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 3 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 1.5292 - val_loss: 1.1527\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3460 - val_loss: 1.1479\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2079 - val_loss: 1.1495\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2504 - val_loss: 1.1487\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2107 - val_loss: 1.1490\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1804 - val_loss: 1.1532\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2446 - val_loss: 1.1497\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1776 - val_loss: 1.1440\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1279 - val_loss: 1.1386\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1208 - val_loss: 1.1308\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1926 - val_loss: 1.1329\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1231 - val_loss: 1.1337\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1753 - val_loss: 1.1280\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1679 - val_loss: 1.1353\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1069 - val_loss: 1.1320\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0647 - val_loss: 1.1270\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1169 - val_loss: 1.1275\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1133 - val_loss: 1.1289\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1013 - val_loss: 1.1306\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0675 - val_loss: 1.1250\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0653 - val_loss: 1.1221\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0667 - val_loss: 1.1313\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0398 - val_loss: 1.1356\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0480 - val_loss: 1.1367\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0686 - val_loss: 1.1407\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1386 - val_loss: 1.1353\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0268 - val_loss: 1.1332\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0429 - val_loss: 1.1368\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0435 - val_loss: 1.1430\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0507 - val_loss: 1.1382\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0437 - val_loss: 1.1392\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0535 - val_loss: 1.1403\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9919 - val_loss: 1.1375\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9943 - val_loss: 1.1347\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0165 - val_loss: 1.1062\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0084 - val_loss: 1.1150\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0624 - val_loss: 1.1093\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9758 - val_loss: 1.1171\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9928 - val_loss: 1.1294\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9514 - val_loss: 1.1414\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9780 - val_loss: 1.1439\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9703 - val_loss: 1.1447\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9577 - val_loss: 1.1539\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9820 - val_loss: 1.1423\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9772 - val_loss: 1.1452\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9466 - val_loss: 1.1547\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9575 - val_loss: 1.1817\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9749 - val_loss: 1.2092\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9254 - val_loss: 1.2256\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9328 - val_loss: 1.2433\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9435 - val_loss: 1.2553\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9225 - val_loss: 1.2414\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8539 - val_loss: 1.2142\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8496 - val_loss: 1.2305\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8694 - val_loss: 1.2321\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8648 - val_loss: 1.2397\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8813 - val_loss: 1.2485\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8889 - val_loss: 1.2431\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8518 - val_loss: 1.2627\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8542 - val_loss: 1.2604\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8344 - val_loss: 1.2718\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8460 - val_loss: 1.2895\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8300 - val_loss: 1.3417\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8391 - val_loss: 1.3475\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8193 - val_loss: 1.3239\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 4 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 1.4622 - val_loss: 1.1004\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3287 - val_loss: 1.0953\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1918 - val_loss: 1.0911\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2163 - val_loss: 1.0897\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1897 - val_loss: 1.0897\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1186 - val_loss: 1.0870\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1675 - val_loss: 1.0861\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1173 - val_loss: 1.0858\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1147 - val_loss: 1.0836\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1137 - val_loss: 1.0846\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1183 - val_loss: 1.0882\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1135 - val_loss: 1.0882\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1113 - val_loss: 1.0831\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1128 - val_loss: 1.0855\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0716 - val_loss: 1.0893\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0316 - val_loss: 1.1094\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0670 - val_loss: 1.0983\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0527 - val_loss: 1.0982\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0486 - val_loss: 1.1086\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0824 - val_loss: 1.1232\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0628 - val_loss: 1.1240\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0624 - val_loss: 1.1315\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0382 - val_loss: 1.1431\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0609 - val_loss: 1.1398\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0053 - val_loss: 1.1492\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9821 - val_loss: 1.1576\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0281 - val_loss: 1.1470\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0360 - val_loss: 1.1524\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0083 - val_loss: 1.1614\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0160 - val_loss: 1.1656\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9766 - val_loss: 1.1742\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9524 - val_loss: 1.2111\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0129 - val_loss: 1.2076\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9638 - val_loss: 1.1960\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9650 - val_loss: 1.1812\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9745 - val_loss: 1.2020\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9209 - val_loss: 1.2316\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9556 - val_loss: 1.2288\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9368 - val_loss: 1.2287\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9380 - val_loss: 1.2336\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9322 - val_loss: 1.2487\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9447 - val_loss: 1.2439\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9203 - val_loss: 1.2821\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 2 fold 5 gamma= none\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 1.6659 - val_loss: 1.1072\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3243 - val_loss: 1.1046\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2312 - val_loss: 1.1045\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2315 - val_loss: 1.1056\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.2944 - val_loss: 1.1045\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1772 - val_loss: 1.1014\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1813 - val_loss: 1.0976\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1559 - val_loss: 1.0990\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1521 - val_loss: 1.1022\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1257 - val_loss: 1.1015\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1290 - val_loss: 1.1012\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1697 - val_loss: 1.0996\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0821 - val_loss: 1.1004\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1201 - val_loss: 1.0915\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0705 - val_loss: 1.0933\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1318 - val_loss: 1.0947\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0580 - val_loss: 1.0928\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0546 - val_loss: 1.1016\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0741 - val_loss: 1.0882\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0539 - val_loss: 1.0774\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0301 - val_loss: 1.0681\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0652 - val_loss: 1.0749\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0304 - val_loss: 1.0692\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0353 - val_loss: 1.0610\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9986 - val_loss: 1.0768\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9868 - val_loss: 1.0766\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0165 - val_loss: 1.0903\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0181 - val_loss: 1.1166\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9498 - val_loss: 1.1179\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9635 - val_loss: 1.1273\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9337 - val_loss: 1.1322\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9554 - val_loss: 1.1299\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9527 - val_loss: 1.1163\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9311 - val_loss: 1.1213\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9530 - val_loss: 1.1093\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9375 - val_loss: 1.0997\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9539 - val_loss: 1.1178\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8962 - val_loss: 1.1691\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8915 - val_loss: 1.1452\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9081 - val_loss: 1.1298\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8775 - val_loss: 1.1275\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8978 - val_loss: 1.1210\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8590 - val_loss: 1.1067\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8530 - val_loss: 1.1223\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8269 - val_loss: 1.1443\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8325 - val_loss: 1.1582\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8230 - val_loss: 1.1700\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8630 - val_loss: 1.1595\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8096 - val_loss: 1.1684\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7955 - val_loss: 1.1875\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8146 - val_loss: 1.1946\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8102 - val_loss: 1.2183\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7746 - val_loss: 1.1992\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.8136 - val_loss: 1.1814\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]]), array([[0.47706422, 0.72392638, 0.02380952],\n",
      "       [0.46919431, 0.72040816, 0.04166667],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.48347107, 0.6056338 , 0.26315789]]), array([[0.48780488, 0.72579001, 0.15151515],\n",
      "       [0.48187633, 0.67826087, 0.05504587],\n",
      "       [0.45213849, 0.60353535, 0.14883721],\n",
      "       [0.48247423, 0.61044177, 0.13533835]])]}\n",
      "Real LSTM seed 3 fold 1 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 1.4157 - val_loss: 1.0678\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2029 - val_loss: 1.0634\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1531 - val_loss: 1.0611\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1249 - val_loss: 1.0584\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0729 - val_loss: 1.0550\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1307 - val_loss: 1.0523\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1049 - val_loss: 1.0517\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1083 - val_loss: 1.0523\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0855 - val_loss: 1.0513\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1302 - val_loss: 1.0523\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1259 - val_loss: 1.0543\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0790 - val_loss: 1.0568\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1124 - val_loss: 1.0610\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0621 - val_loss: 1.0714\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0456 - val_loss: 1.0627\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0667 - val_loss: 1.0708\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0005 - val_loss: 1.0747\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0380 - val_loss: 1.0778\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0398 - val_loss: 1.0844\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0046 - val_loss: 1.0723\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0635 - val_loss: 1.0684\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9582 - val_loss: 1.0753\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9927 - val_loss: 1.0819\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0364 - val_loss: 1.0891\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9805 - val_loss: 1.0911\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0087 - val_loss: 1.0974\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9571 - val_loss: 1.0877\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9442 - val_loss: 1.0966\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9321 - val_loss: 1.0940\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9713 - val_loss: 1.0800\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9592 - val_loss: 1.0757\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9155 - val_loss: 1.0783\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9272 - val_loss: 1.0983\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9287 - val_loss: 1.1107\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9354 - val_loss: 1.1081\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8882 - val_loss: 1.1105\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9330 - val_loss: 1.1017\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8804 - val_loss: 1.0993\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9012 - val_loss: 1.1013\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9121 - val_loss: 1.1209\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8706 - val_loss: 1.1414\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 2 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 1.4807 - val_loss: 1.0005\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2944 - val_loss: 0.9887\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2401 - val_loss: 0.9831\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2480 - val_loss: 0.9865\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1828 - val_loss: 0.9851\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1303 - val_loss: 0.9846\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1457 - val_loss: 0.9870\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0904 - val_loss: 0.9845\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1044 - val_loss: 0.9825\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1015 - val_loss: 0.9745\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1113 - val_loss: 0.9758\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1189 - val_loss: 0.9774\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0541 - val_loss: 0.9757\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0890 - val_loss: 0.9748\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0764 - val_loss: 0.9764\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0558 - val_loss: 0.9744\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1156 - val_loss: 0.9662\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0366 - val_loss: 0.9704\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0059 - val_loss: 0.9836\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0552 - val_loss: 0.9923\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9787 - val_loss: 0.9988\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0039 - val_loss: 0.9965\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0246 - val_loss: 0.9919\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9868 - val_loss: 0.9900\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9666 - val_loss: 0.9918\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0370 - val_loss: 0.9992\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9899 - val_loss: 1.0164\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9202 - val_loss: 1.0136\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9567 - val_loss: 1.0209\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9606 - val_loss: 1.0175\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9566 - val_loss: 1.0136\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9348 - val_loss: 1.0317\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9768 - val_loss: 1.0273\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9635 - val_loss: 1.0212\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9722 - val_loss: 1.0271\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9485 - val_loss: 1.0335\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9302 - val_loss: 1.0470\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9483 - val_loss: 1.0618\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9279 - val_loss: 1.0526\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9626 - val_loss: 1.0798\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8842 - val_loss: 1.0941\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9019 - val_loss: 1.0979\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8929 - val_loss: 1.1056\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8920 - val_loss: 1.1508\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8733 - val_loss: 1.1260\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8732 - val_loss: 1.1232\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8814 - val_loss: 1.1051\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 3 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 1.5661 - val_loss: 1.0813\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3693 - val_loss: 1.0774\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2554 - val_loss: 1.0742\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2085 - val_loss: 1.0700\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2176 - val_loss: 1.0706\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1903 - val_loss: 1.0672\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1686 - val_loss: 1.0632\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1553 - val_loss: 1.0606\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1642 - val_loss: 1.0630\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1160 - val_loss: 1.0620\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1566 - val_loss: 1.0587\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1627 - val_loss: 1.0609\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1057 - val_loss: 1.0678\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1323 - val_loss: 1.0675\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1146 - val_loss: 1.0749\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0857 - val_loss: 1.0624\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0736 - val_loss: 1.0570\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0703 - val_loss: 1.0545\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0853 - val_loss: 1.0531\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0542 - val_loss: 1.0517\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0080 - val_loss: 1.0595\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0185 - val_loss: 1.0748\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0255 - val_loss: 1.0684\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0044 - val_loss: 1.0704\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0374 - val_loss: 1.0646\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9792 - val_loss: 1.0820\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9874 - val_loss: 1.0792\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9738 - val_loss: 1.0885\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9854 - val_loss: 1.1012\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9523 - val_loss: 1.0810\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0284 - val_loss: 1.0903\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9989 - val_loss: 1.1100\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9668 - val_loss: 1.1513\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9691 - val_loss: 1.1526\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9693 - val_loss: 1.1383\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9742 - val_loss: 1.1443\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9502 - val_loss: 1.1398\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9359 - val_loss: 1.1566\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9390 - val_loss: 1.1661\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0235 - val_loss: 1.1624\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9323 - val_loss: 1.1355\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9107 - val_loss: 1.1286\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9050 - val_loss: 1.1374\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9207 - val_loss: 1.1699\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9324 - val_loss: 1.1707\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8852 - val_loss: 1.1721\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9044 - val_loss: 1.1754\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8830 - val_loss: 1.1686\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8952 - val_loss: 1.1869\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8795 - val_loss: 1.1944\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 4 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 1.5456 - val_loss: 0.9884\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3093 - val_loss: 0.9792\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1936 - val_loss: 0.9732\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1827 - val_loss: 0.9715\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1791 - val_loss: 0.9697\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1833 - val_loss: 0.9658\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1760 - val_loss: 0.9565\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1080 - val_loss: 0.9569\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1704 - val_loss: 0.9501\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1854 - val_loss: 0.9338\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1604 - val_loss: 0.9261\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1571 - val_loss: 0.9256\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1073 - val_loss: 0.9322\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1224 - val_loss: 0.9356\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0903 - val_loss: 0.9319\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1036 - val_loss: 0.9325\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0381 - val_loss: 0.9348\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0943 - val_loss: 0.9361\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0569 - val_loss: 0.9316\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0650 - val_loss: 0.9212\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0664 - val_loss: 0.9202\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0635 - val_loss: 0.9179\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0380 - val_loss: 0.9180\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0772 - val_loss: 0.9324\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0360 - val_loss: 0.9225\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0690 - val_loss: 0.9204\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0321 - val_loss: 0.9126\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0092 - val_loss: 0.9031\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0299 - val_loss: 0.8950\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9658 - val_loss: 0.9075\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0254 - val_loss: 0.9035\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0031 - val_loss: 0.8980\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0063 - val_loss: 0.8951\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9831 - val_loss: 0.9022\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9262 - val_loss: 0.9042\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9764 - val_loss: 0.8996\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9201 - val_loss: 0.8874\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9675 - val_loss: 0.8914\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9815 - val_loss: 0.9028\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9395 - val_loss: 0.8902\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9131 - val_loss: 0.8786\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9315 - val_loss: 0.8893\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9358 - val_loss: 0.8749\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9808 - val_loss: 0.8772\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9389 - val_loss: 0.8765\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9495 - val_loss: 0.8644\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9442 - val_loss: 0.9484\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9158 - val_loss: 0.9483\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9628 - val_loss: 0.9245\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9589 - val_loss: 0.9128\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9227 - val_loss: 0.9130\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8950 - val_loss: 0.9237\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9667 - val_loss: 0.9603\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9545 - val_loss: 0.9441\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9540 - val_loss: 0.9349\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9170 - val_loss: 0.9268\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9279 - val_loss: 1.0002\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9227 - val_loss: 0.9554\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9567 - val_loss: 0.9335\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9733 - val_loss: 0.9062\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9008 - val_loss: 0.8849\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9357 - val_loss: 0.8887\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9581 - val_loss: 0.8941\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8701 - val_loss: 0.8941\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9072 - val_loss: 0.8987\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8604 - val_loss: 0.8969\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9284 - val_loss: 0.8971\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8738 - val_loss: 0.8936\n",
      "Epoch 69/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8554 - val_loss: 0.8785\n",
      "Epoch 70/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8684 - val_loss: 0.8808\n",
      "Epoch 71/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8840 - val_loss: 0.8812\n",
      "Epoch 72/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8599 - val_loss: 0.8804\n",
      "Epoch 73/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8604 - val_loss: 0.8788\n",
      "Epoch 74/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8509 - val_loss: 0.8765\n",
      "Epoch 75/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7952 - val_loss: 0.8852\n",
      "Epoch 76/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8505 - val_loss: 0.9056\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 3 fold 5 gamma= none\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.5972 - val_loss: 1.0760\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3294 - val_loss: 1.0738\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2534 - val_loss: 1.0787\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2172 - val_loss: 1.0792\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2092 - val_loss: 1.0792\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2063 - val_loss: 1.0810\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1614 - val_loss: 1.0828\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1537 - val_loss: 1.0827\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1035 - val_loss: 1.0810\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1368 - val_loss: 1.0843\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1193 - val_loss: 1.0864\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0559 - val_loss: 1.0918\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0806 - val_loss: 1.1029\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0829 - val_loss: 1.1134\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0530 - val_loss: 1.1231\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0814 - val_loss: 1.1368\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0921 - val_loss: 1.1523\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0579 - val_loss: 1.1530\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0898 - val_loss: 1.1574\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0064 - val_loss: 1.1715\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0047 - val_loss: 1.1764\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0368 - val_loss: 1.1780\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0058 - val_loss: 1.2083\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9957 - val_loss: 1.2181\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0127 - val_loss: 1.2388\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9578 - val_loss: 1.2645\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9799 - val_loss: 1.2658\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9587 - val_loss: 1.2758\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9596 - val_loss: 1.2996\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9343 - val_loss: 1.3192\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9517 - val_loss: 1.2948\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9283 - val_loss: 1.2982\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9890 - val_loss: 1.3228\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9473 - val_loss: 1.3273\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9207 - val_loss: 1.3283\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9286 - val_loss: 1.3370\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9225 - val_loss: 1.3741\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9000 - val_loss: 1.3747\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8795 - val_loss: 1.3567\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8804 - val_loss: 1.3516\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8940 - val_loss: 1.3575\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]]), array([[0.47706422, 0.72392638, 0.02380952],\n",
      "       [0.46919431, 0.72040816, 0.04166667],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.48347107, 0.6056338 , 0.26315789]]), array([[0.48780488, 0.72579001, 0.15151515],\n",
      "       [0.48187633, 0.67826087, 0.05504587],\n",
      "       [0.45213849, 0.60353535, 0.14883721],\n",
      "       [0.48247423, 0.61044177, 0.13533835]]), array([[0.42512077, 0.74274662, 0.04      ],\n",
      "       [0.49186992, 0.66742081, 0.13114754],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45634921, 0.59334298, 0.17161716]])]}\n",
      "Real LSTM seed 4 fold 1 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 1.4996 - val_loss: 1.0608\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2472 - val_loss: 1.0669\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1740 - val_loss: 1.0673\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1639 - val_loss: 1.0685\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1298 - val_loss: 1.0661\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1779 - val_loss: 1.0575\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1219 - val_loss: 1.0496\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0761 - val_loss: 1.0456\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1280 - val_loss: 1.0461\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0927 - val_loss: 1.0458\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0782 - val_loss: 1.0473\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1052 - val_loss: 1.0431\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0599 - val_loss: 1.0408\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0783 - val_loss: 1.0352\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0426 - val_loss: 1.0354\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0569 - val_loss: 1.0351\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1001 - val_loss: 1.0365\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0389 - val_loss: 1.0363\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0517 - val_loss: 1.0434\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0176 - val_loss: 1.0434\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9976 - val_loss: 1.0509\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0244 - val_loss: 1.0487\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0466 - val_loss: 1.0553\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0417 - val_loss: 1.0618\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0107 - val_loss: 1.0538\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9978 - val_loss: 1.0568\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9978 - val_loss: 1.0519\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0100 - val_loss: 1.0448\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9609 - val_loss: 1.0455\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9937 - val_loss: 1.0387\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9852 - val_loss: 1.0387\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0280 - val_loss: 1.0389\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9681 - val_loss: 1.0335\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9661 - val_loss: 1.0342\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9927 - val_loss: 1.0376\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9689 - val_loss: 1.0364\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9822 - val_loss: 1.0324\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9790 - val_loss: 1.0307\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9627 - val_loss: 1.0333\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9393 - val_loss: 1.0409\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9326 - val_loss: 1.0455\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9251 - val_loss: 1.0466\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9391 - val_loss: 1.0551\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9274 - val_loss: 1.0582\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9013 - val_loss: 1.0686\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8977 - val_loss: 1.1164\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9103 - val_loss: 1.0754\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9157 - val_loss: 1.0416\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9392 - val_loss: 1.0313\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8858 - val_loss: 1.0626\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9110 - val_loss: 1.0540\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9032 - val_loss: 1.0534\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9009 - val_loss: 1.0592\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8850 - val_loss: 1.0658\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8662 - val_loss: 1.0851\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8902 - val_loss: 1.0947\n",
      "Epoch 57/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8367 - val_loss: 1.1027\n",
      "Epoch 58/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8698 - val_loss: 1.1089\n",
      "Epoch 59/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8493 - val_loss: 1.0691\n",
      "Epoch 60/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8716 - val_loss: 1.0827\n",
      "Epoch 61/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8366 - val_loss: 1.1015\n",
      "Epoch 62/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8780 - val_loss: 1.1409\n",
      "Epoch 63/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8258 - val_loss: 1.1316\n",
      "Epoch 64/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8437 - val_loss: 1.1300\n",
      "Epoch 65/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8196 - val_loss: 1.1338\n",
      "Epoch 66/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8505 - val_loss: 1.1186\n",
      "Epoch 67/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8046 - val_loss: 1.1317\n",
      "Epoch 68/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8328 - val_loss: 1.1494\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 2 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.3139 - val_loss: 1.1948\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3379 - val_loss: 1.1892\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2416 - val_loss: 1.1854\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1828 - val_loss: 1.1869\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1305 - val_loss: 1.1781\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1246 - val_loss: 1.1714\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1591 - val_loss: 1.1671\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1618 - val_loss: 1.1635\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1377 - val_loss: 1.1627\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1151 - val_loss: 1.1637\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0834 - val_loss: 1.1630\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0515 - val_loss: 1.1681\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0982 - val_loss: 1.1770\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1307 - val_loss: 1.1777\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0497 - val_loss: 1.1838\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0878 - val_loss: 1.1831\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0844 - val_loss: 1.1593\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0951 - val_loss: 1.1556\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0290 - val_loss: 1.1591\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0229 - val_loss: 1.1721\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0401 - val_loss: 1.1717\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0284 - val_loss: 1.1819\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0295 - val_loss: 1.1864\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0226 - val_loss: 1.1937\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0117 - val_loss: 1.1870\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0130 - val_loss: 1.1784\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0037 - val_loss: 1.1904\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9925 - val_loss: 1.1954\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9407 - val_loss: 1.1675\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9385 - val_loss: 1.1672\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9197 - val_loss: 1.1873\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9349 - val_loss: 1.1634\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9095 - val_loss: 1.1714\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9350 - val_loss: 1.2167\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9242 - val_loss: 1.2464\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9140 - val_loss: 1.2455\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9083 - val_loss: 1.1937\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9292 - val_loss: 1.1979\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9058 - val_loss: 1.2022\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8960 - val_loss: 1.2092\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8947 - val_loss: 1.2194\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8550 - val_loss: 1.2428\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8801 - val_loss: 1.2394\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8823 - val_loss: 1.2082\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8582 - val_loss: 1.2420\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8311 - val_loss: 1.2707\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8168 - val_loss: 1.2745\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8549 - val_loss: 1.2880\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 3 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 1.4394 - val_loss: 1.0628\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2508 - val_loss: 1.0609\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2136 - val_loss: 1.0612\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2037 - val_loss: 1.0595\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2038 - val_loss: 1.0599\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1694 - val_loss: 1.0581\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1625 - val_loss: 1.0591\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1377 - val_loss: 1.0570\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1800 - val_loss: 1.0564\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1176 - val_loss: 1.0545\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2003 - val_loss: 1.0567\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1206 - val_loss: 1.0658\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1088 - val_loss: 1.0679\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1273 - val_loss: 1.0709\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1089 - val_loss: 1.0713\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0578 - val_loss: 1.0742\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0664 - val_loss: 1.0709\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1291 - val_loss: 1.0859\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0909 - val_loss: 1.0885\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0609 - val_loss: 1.0877\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0894 - val_loss: 1.0841\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0645 - val_loss: 1.0847\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0875 - val_loss: 1.0741\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0506 - val_loss: 1.0811\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0699 - val_loss: 1.0819\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0379 - val_loss: 1.0809\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0650 - val_loss: 1.0797\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0604 - val_loss: 1.0717\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9994 - val_loss: 1.0810\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0377 - val_loss: 1.1000\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9955 - val_loss: 1.0985\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9856 - val_loss: 1.1069\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9872 - val_loss: 1.1148\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0104 - val_loss: 1.1370\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0056 - val_loss: 1.1558\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9815 - val_loss: 1.1694\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9512 - val_loss: 1.1966\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9885 - val_loss: 1.1686\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9380 - val_loss: 1.1676\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9614 - val_loss: 1.1727\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9486 - val_loss: 1.1649\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 4 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5535 - val_loss: 1.0780\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4113 - val_loss: 1.0729\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2465 - val_loss: 1.0724\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1665 - val_loss: 1.0689\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1287 - val_loss: 1.0664\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2034 - val_loss: 1.0722\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0860 - val_loss: 1.0692\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1270 - val_loss: 1.0636\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1275 - val_loss: 1.0649\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1353 - val_loss: 1.0663\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1181 - val_loss: 1.0629\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1168 - val_loss: 1.0718\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0993 - val_loss: 1.0732\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1039 - val_loss: 1.0869\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0713 - val_loss: 1.0976\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1045 - val_loss: 1.0944\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0631 - val_loss: 1.1284\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0775 - val_loss: 1.1373\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0399 - val_loss: 1.1103\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0523 - val_loss: 1.1145\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0258 - val_loss: 1.1958\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0283 - val_loss: 1.1827\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0536 - val_loss: 1.1671\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0743 - val_loss: 1.1587\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0468 - val_loss: 1.1560\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0297 - val_loss: 1.1485\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0556 - val_loss: 1.1519\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0132 - val_loss: 1.1235\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0260 - val_loss: 1.1210\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0172 - val_loss: 1.1404\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0491 - val_loss: 1.1273\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9894 - val_loss: 1.1390\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0109 - val_loss: 1.1534\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9748 - val_loss: 1.1608\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9864 - val_loss: 1.1624\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9313 - val_loss: 1.1617\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9289 - val_loss: 1.1653\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9296 - val_loss: 1.1672\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9321 - val_loss: 1.1992\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9609 - val_loss: 1.1563\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9287 - val_loss: 1.1498\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 4 fold 5 gamma= none\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 1.4708 - val_loss: 1.0377\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3362 - val_loss: 1.0361\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2410 - val_loss: 1.0369\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2305 - val_loss: 1.0298\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1980 - val_loss: 1.0246\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1861 - val_loss: 1.0239\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1849 - val_loss: 1.0234\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1377 - val_loss: 1.0220\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.1260 - val_loss: 1.0215\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2075 - val_loss: 1.0194\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1443 - val_loss: 1.0388\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1281 - val_loss: 1.0432\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1570 - val_loss: 1.0461\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0745 - val_loss: 1.0399\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0938 - val_loss: 1.0436\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0589 - val_loss: 1.0538\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0552 - val_loss: 1.0549\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0615 - val_loss: 1.0498\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0911 - val_loss: 1.0580\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.0784 - val_loss: 1.0621\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0495 - val_loss: 1.0577\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.0396 - val_loss: 1.0536\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0401 - val_loss: 1.0715\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0050 - val_loss: 1.0884\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.0012 - val_loss: 1.0921\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9511 - val_loss: 1.0927\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9638 - val_loss: 1.0830\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9592 - val_loss: 1.0832\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0135 - val_loss: 1.1148\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0012 - val_loss: 1.0998\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9374 - val_loss: 1.1209\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9532 - val_loss: 1.1127\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9456 - val_loss: 1.1080\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9243 - val_loss: 1.1269\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9251 - val_loss: 1.1515\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9389 - val_loss: 1.1644\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9394 - val_loss: 1.2099\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9137 - val_loss: 1.2475\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9278 - val_loss: 1.1961\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.8760 - val_loss: 1.2111\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8738 - val_loss: 1.2639\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]]), array([[0.47706422, 0.72392638, 0.02380952],\n",
      "       [0.46919431, 0.72040816, 0.04166667],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.48347107, 0.6056338 , 0.26315789]]), array([[0.48780488, 0.72579001, 0.15151515],\n",
      "       [0.48187633, 0.67826087, 0.05504587],\n",
      "       [0.45213849, 0.60353535, 0.14883721],\n",
      "       [0.48247423, 0.61044177, 0.13533835]]), array([[0.42512077, 0.74274662, 0.04      ],\n",
      "       [0.49186992, 0.66742081, 0.13114754],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45634921, 0.59334298, 0.17161716]]), array([[0.49040512, 0.70514166, 0.07894737],\n",
      "       [0.501002  , 0.68374165, 0.05940594],\n",
      "       [0.44731978, 0.51575931, 0.13899614],\n",
      "       [0.46492986, 0.62021858, 0.17977528]])]}\n",
      "Real LSTM seed 5 fold 1 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 1.4938 - val_loss: 1.0275\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2838 - val_loss: 1.0217\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2031 - val_loss: 1.0168\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1894 - val_loss: 1.0106\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1616 - val_loss: 1.0061\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1386 - val_loss: 0.9988\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1272 - val_loss: 0.9875\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1239 - val_loss: 0.9793\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1208 - val_loss: 0.9723\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1149 - val_loss: 0.9745\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1021 - val_loss: 0.9669\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1491 - val_loss: 0.9593\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0844 - val_loss: 0.9619\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1023 - val_loss: 0.9614\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1110 - val_loss: 0.9608\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0731 - val_loss: 0.9606\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0660 - val_loss: 0.9624\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1425 - val_loss: 0.9523\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0790 - val_loss: 0.9520\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0953 - val_loss: 0.9525\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0767 - val_loss: 0.9532\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1142 - val_loss: 0.9685\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0862 - val_loss: 0.9653\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1230 - val_loss: 0.9611\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0866 - val_loss: 0.9567\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0414 - val_loss: 0.9496\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1100 - val_loss: 0.9499\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9902 - val_loss: 0.9514\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0453 - val_loss: 0.9541\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0589 - val_loss: 0.9891\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0633 - val_loss: 0.9860\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0964 - val_loss: 0.9810\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0665 - val_loss: 1.0360\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0542 - val_loss: 1.0351\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0088 - val_loss: 1.0194\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0071 - val_loss: 1.0149\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0181 - val_loss: 1.0123\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0079 - val_loss: 1.0107\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0103 - val_loss: 1.0163\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0258 - val_loss: 1.0625\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0476 - val_loss: 1.0724\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9887 - val_loss: 1.0580\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9909 - val_loss: 1.0346\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0190 - val_loss: 1.0276\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9850 - val_loss: 1.0357\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0139 - val_loss: 1.0224\n",
      "Epoch 47/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9991 - val_loss: 1.0124\n",
      "Epoch 48/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0018 - val_loss: 1.0131\n",
      "Epoch 49/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9645 - val_loss: 1.0069\n",
      "Epoch 50/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9736 - val_loss: 1.0042\n",
      "Epoch 51/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9646 - val_loss: 0.9955\n",
      "Epoch 52/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9827 - val_loss: 0.9856\n",
      "Epoch 53/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9650 - val_loss: 0.9788\n",
      "Epoch 54/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9497 - val_loss: 0.9749\n",
      "Epoch 55/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9669 - val_loss: 0.9825\n",
      "Epoch 56/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9573 - val_loss: 0.9931\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Real LSTM seed 5 fold 2 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 1.6243 - val_loss: 1.1336\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3063 - val_loss: 1.1346\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2648 - val_loss: 1.1315\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2417 - val_loss: 1.1342\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2109 - val_loss: 1.1347\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1870 - val_loss: 1.1351\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1712 - val_loss: 1.1349\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1475 - val_loss: 1.1379\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1846 - val_loss: 1.1457\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1776 - val_loss: 1.1555\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1364 - val_loss: 1.1657\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1194 - val_loss: 1.1721\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1060 - val_loss: 1.1729\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1835 - val_loss: 1.1773\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0994 - val_loss: 1.1812\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0941 - val_loss: 1.1766\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1109 - val_loss: 1.1809\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1041 - val_loss: 1.1914\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0412 - val_loss: 1.1947\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0344 - val_loss: 1.2038\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0559 - val_loss: 1.2040\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0370 - val_loss: 1.2219\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0427 - val_loss: 1.2166\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0683 - val_loss: 1.2107\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0286 - val_loss: 1.2217\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0479 - val_loss: 1.2175\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0758 - val_loss: 1.2046\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0381 - val_loss: 1.2086\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0375 - val_loss: 1.2211\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0722 - val_loss: 1.2321\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0516 - val_loss: 1.2223\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0297 - val_loss: 1.2116\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0581 - val_loss: 1.1924\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0547 - val_loss: 1.1880\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0150 - val_loss: 1.1825\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0544 - val_loss: 1.1903\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0660 - val_loss: 1.2042\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0082 - val_loss: 1.2163\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9735 - val_loss: 1.2295\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9683 - val_loss: 1.2338\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9640 - val_loss: 1.2228\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 3 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 1.4364 - val_loss: 1.1458\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2230 - val_loss: 1.1377\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1582 - val_loss: 1.1327\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2044 - val_loss: 1.1289\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1831 - val_loss: 1.1218\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1760 - val_loss: 1.1211\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1289 - val_loss: 1.1220\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0857 - val_loss: 1.1198\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1149 - val_loss: 1.1186\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1003 - val_loss: 1.1183\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1077 - val_loss: 1.1133\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1180 - val_loss: 1.1156\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1165 - val_loss: 1.1181\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0669 - val_loss: 1.1116\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0618 - val_loss: 1.1157\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0655 - val_loss: 1.1207\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0888 - val_loss: 1.1209\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0710 - val_loss: 1.1211\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0408 - val_loss: 1.1299\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0164 - val_loss: 1.1401\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0376 - val_loss: 1.1523\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0357 - val_loss: 1.1687\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0129 - val_loss: 1.1673\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9941 - val_loss: 1.1626\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0327 - val_loss: 1.1412\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0100 - val_loss: 1.1443\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9926 - val_loss: 1.1496\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0358 - val_loss: 1.1539\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0225 - val_loss: 1.1712\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9806 - val_loss: 1.1865\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0089 - val_loss: 1.1980\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9700 - val_loss: 1.2119\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9397 - val_loss: 1.2119\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9101 - val_loss: 1.2161\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9251 - val_loss: 1.2276\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9104 - val_loss: 1.2609\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9461 - val_loss: 1.2482\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9341 - val_loss: 1.2569\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9146 - val_loss: 1.2480\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9532 - val_loss: 1.2314\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9014 - val_loss: 1.2371\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9119 - val_loss: 1.2431\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9358 - val_loss: 1.2834\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9076 - val_loss: 1.2595\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 4 gamma= none\n",
      "(545, 4, 240) (4, 240) (545, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 1.5147 - val_loss: 1.0807\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3746 - val_loss: 1.0771\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3322 - val_loss: 1.0754\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2450 - val_loss: 1.0730\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2227 - val_loss: 1.0754\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2257 - val_loss: 1.0736\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1859 - val_loss: 1.0738\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2588 - val_loss: 1.0713\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1703 - val_loss: 1.0708\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2036 - val_loss: 1.0720\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1432 - val_loss: 1.0728\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1283 - val_loss: 1.0746\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1301 - val_loss: 1.0764\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1639 - val_loss: 1.0753\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1027 - val_loss: 1.0763\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1086 - val_loss: 1.0820\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1150 - val_loss: 1.0920\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1021 - val_loss: 1.0974\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0966 - val_loss: 1.1005\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1420 - val_loss: 1.1016\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0987 - val_loss: 1.0965\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1047 - val_loss: 1.1003\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0922 - val_loss: 1.0949\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0596 - val_loss: 1.0974\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1057 - val_loss: 1.1097\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1091 - val_loss: 1.1123\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0953 - val_loss: 1.1095\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0477 - val_loss: 1.1140\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1126 - val_loss: 1.1128\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0781 - val_loss: 1.1154\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0876 - val_loss: 1.1231\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1248 - val_loss: 1.1210\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0940 - val_loss: 1.1250\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1308 - val_loss: 1.1314\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0724 - val_loss: 1.1297\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0486 - val_loss: 1.1295\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0651 - val_loss: 1.1123\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9958 - val_loss: 1.1130\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0495 - val_loss: 1.1135\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0473 - val_loss: 1.1166\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0096 - val_loss: 1.1199\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Real LSTM seed 5 fold 5 gamma= none\n",
      "(546, 4, 240) (4, 240) (546, 4, 240)\n",
      "Epoch 1/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 1.4268 - val_loss: 1.0185\n",
      "Epoch 2/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2801 - val_loss: 1.0142\n",
      "Epoch 3/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1967 - val_loss: 1.0087\n",
      "Epoch 4/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1948 - val_loss: 1.0047\n",
      "Epoch 5/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1261 - val_loss: 0.9997\n",
      "Epoch 6/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1747 - val_loss: 0.9955\n",
      "Epoch 7/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1401 - val_loss: 0.9945\n",
      "Epoch 8/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1250 - val_loss: 0.9919\n",
      "Epoch 9/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1235 - val_loss: 0.9969\n",
      "Epoch 10/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1337 - val_loss: 0.9974\n",
      "Epoch 11/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0948 - val_loss: 0.9975\n",
      "Epoch 12/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1037 - val_loss: 0.9997\n",
      "Epoch 13/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1346 - val_loss: 1.0014\n",
      "Epoch 14/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0366 - val_loss: 0.9988\n",
      "Epoch 15/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0513 - val_loss: 0.9937\n",
      "Epoch 16/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0462 - val_loss: 0.9927\n",
      "Epoch 17/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0457 - val_loss: 1.0093\n",
      "Epoch 18/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0314 - val_loss: 1.0107\n",
      "Epoch 19/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9904 - val_loss: 1.0279\n",
      "Epoch 20/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9744 - val_loss: 1.0234\n",
      "Epoch 21/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0108 - val_loss: 1.0230\n",
      "Epoch 22/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9839 - val_loss: 1.0367\n",
      "Epoch 23/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9852 - val_loss: 1.0066\n",
      "Epoch 24/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9675 - val_loss: 1.0238\n",
      "Epoch 25/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9613 - val_loss: 1.0335\n",
      "Epoch 26/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9541 - val_loss: 1.0435\n",
      "Epoch 27/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9178 - val_loss: 1.0438\n",
      "Epoch 28/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9260 - val_loss: 1.0741\n",
      "Epoch 29/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9313 - val_loss: 1.0883\n",
      "Epoch 30/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9310 - val_loss: 1.0872\n",
      "Epoch 31/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9398 - val_loss: 1.0798\n",
      "Epoch 32/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9066 - val_loss: 1.0918\n",
      "Epoch 33/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9266 - val_loss: 1.0946\n",
      "Epoch 34/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8913 - val_loss: 1.0891\n",
      "Epoch 35/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8652 - val_loss: 1.0889\n",
      "Epoch 36/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8794 - val_loss: 1.1264\n",
      "Epoch 37/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8624 - val_loss: 1.0961\n",
      "Epoch 38/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8977 - val_loss: 1.0568\n",
      "Epoch 39/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8452 - val_loss: 1.0765\n",
      "Epoch 40/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8770 - val_loss: 1.0771\n",
      "Epoch 41/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8362 - val_loss: 1.1410\n",
      "Epoch 42/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8222 - val_loss: 1.1214\n",
      "Epoch 43/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8558 - val_loss: 1.1168\n",
      "Epoch 44/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8252 - val_loss: 1.1173\n",
      "Epoch 45/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8283 - val_loss: 1.1127\n",
      "Epoch 46/2000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7972 - val_loss: 1.1491\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "{'Real LSTM': [array([[0.46741573, 0.71399594, 0.02985075],\n",
      "       [0.49186992, 0.67191011, 0.0862069 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46548323, 0.63129252, 0.171875  ]]), array([[0.36164384, 0.7497657 , 0.03030303],\n",
      "       [0.47032967, 0.69130435, 0.08130081],\n",
      "       [0.44214876, 0.59635417, 0.19512195],\n",
      "       [0.44906445, 0.57474601, 0.23780488]]), array([[0.36787565, 0.69813176, 0.02105263],\n",
      "       [0.44144144, 0.68660022, 0.18543046],\n",
      "       [0.46382979, 0.58201058, 0.21323529],\n",
      "       [0.41409692, 0.57687075, 0.14239482]]), array([[0.44665012, 0.7524558 , 0.07792208],\n",
      "       [0.46403712, 0.7126193 , 0.09677419],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.42798354, 0.5989011 , 0.16901408]]), array([[0.26229508, 0.760812  , 0.1       ],\n",
      "       [0.47844828, 0.65057471, 0.13414634],\n",
      "       [0.3982684 , 0.57800512, 0.1496063 ],\n",
      "       [0.43340858, 0.57182706, 0.23668639]]), array([[0.50224215, 0.74291498, 0.125     ],\n",
      "       [0.51380042, 0.70358306, 0.09433962],\n",
      "       [0.43738318, 0.5       , 0.21993127],\n",
      "       [0.47244094, 0.6091954 , 0.23129252]]), array([[0.37430168, 0.77209302, 0.09230769],\n",
      "       [0.51262136, 0.64105642, 0.13333333],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.46575342, 0.52631579, 0.1242236 ]]), array([[0.40203562, 0.70292044, 0.14285714],\n",
      "       [0.42424242, 0.66882416, 0.05633803],\n",
      "       [0.45322245, 0.59487179, 0.17721519],\n",
      "       [0.46185567, 0.5915493 , 0.22442244]]), array([[0.45255474, 0.73830846, 0.14634146],\n",
      "       [0.50205761, 0.64277457, 0.08163265],\n",
      "       [0.45773196, 0.56389987, 0.18897638],\n",
      "       [0.45986985, 0.62957938, 0.2       ]]), array([[0.32317073, 0.74884152, 0.10989011],\n",
      "       [0.48085106, 0.64064294, 0.11464968],\n",
      "       [0.43589744, 0.59709379, 0.1978022 ],\n",
      "       [0.42600897, 0.60082305, 0.15479876]]), array([[0.50101833, 0.71983211, 0.        ],\n",
      "       [0.50105263, 0.69946524, 0.04545455],\n",
      "       [0.48708487, 0.55807365, 0.216     ],\n",
      "       [0.46692607, 0.57979502, 0.20598007]]), array([[0.48614072, 0.72008325, 0.05882353],\n",
      "       [0.53543307, 0.69152542, 0.0952381 ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.4738806 , 0.6011396 , 0.19230769]]), array([[0.44041451, 0.77142857, 0.06451613],\n",
      "       [0.4626506 , 0.70781893, 0.10810811],\n",
      "       [0.45643154, 0.58567775, 0.17948718],\n",
      "       [0.46613546, 0.57571214, 0.2006079 ]]), array([[0.39779006, 0.77179963, 0.13793103],\n",
      "       [0.45647059, 0.68869936, 0.07407407],\n",
      "       [0.397463  , 0.56857855, 0.14349776],\n",
      "       [0.45867769, 0.59697387, 0.18815331]]), array([[0.3933518 , 0.75517891, 0.        ],\n",
      "       [0.46330275, 0.68122271, 0.10958904],\n",
      "       [0.45490196, 0.52750353, 0.27956989],\n",
      "       [0.42241379, 0.59060403, 0.17301038]]), array([[0.28938907, 0.77475898, 0.08695652],\n",
      "       [0.49890591, 0.66740823, 0.09859155],\n",
      "       [0.43942505, 0.54619565, 0.15272727],\n",
      "       [0.40528634, 0.5819209 , 0.19047619]]), array([[0.4180791 , 0.76448598, 0.02702703],\n",
      "       [0.48337029, 0.671875  , 0.1192053 ],\n",
      "       [0.44493392, 0.59846547, 0.19847328],\n",
      "       [0.44444444, 0.61728395, 0.21290323]]), array([[0.43309002, 0.71343874, 0.02666667],\n",
      "       [0.48861284, 0.66516854, 0.096     ],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45875252, 0.55014327, 0.15181518]]), array([[0.41509434, 0.66037736, 0.        ],\n",
      "       [0.49152542, 0.65834279, 0.13793103],\n",
      "       [0.406639  , 0.60025221, 0.13452915],\n",
      "       [0.45792564, 0.56801196, 0.22641509]]), array([[0.33333333, 0.71428571, 0.05263158],\n",
      "       [0.46188341, 0.65470852, 0.0875    ],\n",
      "       [0.40262582, 0.58701299, 0.20664207],\n",
      "       [0.41318681, 0.57222222, 0.16099071]]), array([[0.44907407, 0.72908367, 0.12903226],\n",
      "       [0.50678733, 0.73347107, 0.06818182],\n",
      "       [0.47037702, 0.54261364, 0.16033755],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.43069307, 0.75743049, 0.03921569],\n",
      "       [0.5078125 , 0.66359447, 0.13559322],\n",
      "       [0.45792564, 0.57105606, 0.14545455],\n",
      "       [0.44741874, 0.56925419, 0.22641509]]), array([[0.34929577, 0.74323063, 0.11111111],\n",
      "       [0.43822844, 0.69330454, 0.06993007],\n",
      "       [0.39662447, 0.57218543, 0.22304833],\n",
      "       [0.        , 0.64801444, 0.        ]]), array([[0.38968481, 0.76163873, 0.02666667],\n",
      "       [0.49684211, 0.65446224, 0.09395973],\n",
      "       [0.41616162, 0.57180501, 0.18032787],\n",
      "       [0.4924406 , 0.57301808, 0.2278481 ]]), array([[0.34733894, 0.73036897, 0.04761905],\n",
      "       [0.47795824, 0.70422535, 0.125     ],\n",
      "       [0.42857143, 0.56830601, 0.16666667],\n",
      "       [0.45175439, 0.61623109, 0.20952381]]), array([[0.47706422, 0.72392638, 0.02380952],\n",
      "       [0.46919431, 0.72040816, 0.04166667],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.48347107, 0.6056338 , 0.26315789]]), array([[0.48780488, 0.72579001, 0.15151515],\n",
      "       [0.48187633, 0.67826087, 0.05504587],\n",
      "       [0.45213849, 0.60353535, 0.14883721],\n",
      "       [0.48247423, 0.61044177, 0.13533835]]), array([[0.42512077, 0.74274662, 0.04      ],\n",
      "       [0.49186992, 0.66742081, 0.13114754],\n",
      "       [0.        , 0.68941382, 0.        ],\n",
      "       [0.45634921, 0.59334298, 0.17161716]]), array([[0.49040512, 0.70514166, 0.07894737],\n",
      "       [0.501002  , 0.68374165, 0.05940594],\n",
      "       [0.44731978, 0.51575931, 0.13899614],\n",
      "       [0.46492986, 0.62021858, 0.17977528]]), array([[0.4924406 , 0.70105263, 0.04705882],\n",
      "       [0.50446429, 0.6975764 , 0.03960396],\n",
      "       [0.44094488, 0.57986577, 0.1877551 ],\n",
      "       [0.45934959, 0.56975037, 0.19692308]])]}\n"
     ]
    }
   ],
   "source": [
    "f_scores_gamma = { f'gamma={gamma}': np.stack([item for index, item in enumerate(f_scores_test['Real LSTM']) if index % 5 == gamma], axis=0) for gamma in range(5)}\n",
    "p_scores_gamma = { f'gamma={gamma}': np.stack([item for index, item in enumerate(p_scores_test['Real LSTM']) if index % 5 == gamma], axis=0) for gamma in range(5)}\n",
    "r_scores_gamma = { f'gamma={gamma}': np.stack([item for index, item in enumerate(r_scores_test['Real LSTM']) if index % 5 == gamma], axis=0) for gamma in range(5)}\n",
    "\n",
    "for seed in range(5): #range(len(bps)):\n",
    "    train_eval_RNNs(train=bps[seed][0], test=bps[seed][1], seed=seed, decision='threshmax', random_bl=False, sampling=None, gamma='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scores_gamma['no gamma'] = np.stack(f_scores_test['Real LSTM'][-5:], axis=0)\n",
    "p_scores_gamma['no gamma'] = np.stack(p_scores_test['Real LSTM'][-5:], axis=0)\n",
    "r_scores_gamma['no gamma'] = np.stack(r_scores_test['Real LSTM'][-5:], axis=0)\n",
    "gamma_results = {'f': f_scores_gamma, 'p': p_scores_gamma, 'r': r_scores_gamma}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {'f': f_score_arrays_test, 'p': p_score_arrays_test, 'r': r_score_arrays_test}\n",
    "# with open(\"/Users/susmaa01/Documents/eipy/longitudinal_tadpole/results/EI_t2t_seq_plain_loss.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(obj=results, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_scores(score_dict, dict_name, class_to_plot='Dementia'):\n",
    "    # Assuming f_score_arrays is your dictionary of 2D arrays\n",
    "    # Example dictionary of 2D arrays\n",
    "    if class_to_plot == 'CN':\n",
    "        class_scores = {k: v[:,:,0] for k,v in score_dict.items()}\n",
    "    elif class_to_plot == 'MCI':\n",
    "        class_scores = {k: v[:,:,1] for k,v in score_dict.items()}\n",
    "    elif class_to_plot == 'Dementia':\n",
    "        class_scores = {k: v[:,:,-1] for k,v in score_dict.items()}\n",
    "    elif class_to_plot == 'all':\n",
    "        class_scores = {k: np.mean(v, axis=-1) for k,v in score_dict.items()}\n",
    "        \n",
    "    # Compute medians\n",
    "    medians = {key: np.median(arr, axis=0) for key, arr in class_scores.items()}\n",
    "\n",
    "    # Compute standard errors with respect to medians\n",
    "    std_errors = {\n",
    "        key: np.median(np.abs(arr - np.median(arr, axis=0)), axis=0) / np.sqrt(arr.shape[0])\n",
    "        for key, arr in class_scores.items()\n",
    "    }\n",
    "\n",
    "    # X ticks and labels\n",
    "    x_ticks = np.arange(4)\n",
    "    x_labels = ['up to bl vs m06', 'up to m06 vs m12', 'up to m12 vs m24', 'up to m24 vs m36']\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in score_dict:\n",
    "        plt.errorbar(x_ticks, medians[key], yerr=std_errors[key], label=key)\n",
    "\n",
    "    plt.xticks(x_ticks, x_labels)\n",
    "\n",
    "    if class_to_plot != 'all':\n",
    "        plt.title(f'{dict_name} scores on {class_to_plot} class from seq2seq baselines')\n",
    "    else:\n",
    "        plt.title(f'macro averaged {dict_name} scores from seq2seq long EI')\n",
    "    plt.xlabel('data up to time t matched with labels from time t+1')\n",
    "    plt.ylabel(f'median {dict_name} score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_class_scores(score_dict=f_scores_gamma, dict_name='f', class_to_plot='all')\n",
    "plot_class_scores(score_dict=f_scores_gamma, dict_name='f', class_to_plot='CN')\n",
    "plot_class_scores(score_dict=f_scores_gamma, dict_name='f', class_to_plot='MCI')\n",
    "plot_class_scores(score_dict=f_scores_gamma, dict_name='f', class_to_plot='Dementia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_scores(score_dict=p_scores_gamma_weighted, dict_name='p', class_to_plot='all')\n",
    "plot_class_scores(score_dict=r_scores_gamma_weighted, dict_name='r', class_to_plot='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/susmaa01/Documents/eipy/longitudinal_tadpole/results/gamma_tuning/no_sampling_argmax_EI_fixed.pkl\", \"wb\") as file:\n",
    "    pkl.dump(obj=gamma_results, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_scores(score_dict=p_scores_gamma, dict_name='precision', class_to_plot='all')\n",
    "plot_class_scores(score_dict=p_scores_gamma, dict_name='precision', class_to_plot='CN')\n",
    "plot_class_scores(score_dict=p_scores_gamma, dict_name='precision', class_to_plot='MCI')\n",
    "plot_class_scores(score_dict=p_scores_gamma, dict_name='precision', class_to_plot='Dementia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_scores(score_dict=r_scores_gamma, dict_name='recall', class_to_plot='all')\n",
    "plot_class_scores(score_dict=r_scores_gamma, dict_name='recall', class_to_plot='CN')\n",
    "plot_class_scores(score_dict=r_scores_gamma, dict_name='recall', class_to_plot='MCI')\n",
    "plot_class_scores(score_dict=r_scores_gamma, dict_name='recall', class_to_plot='Dementia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_score_arrays_train = {k: np.stack(v, axis=0) for k,v in f_scores_train.items()}\n",
    "# plot_class_scores(score_dicts=f_score_arrays_train, class_to_plot='all')\n",
    "# plot_class_scores(score_dicts=f_score_arrays_train,class_to_plot='CN')\n",
    "# plot_class_scores(score_dicts=f_score_arrays_train,class_to_plot='MCI')\n",
    "# plot_class_scores(score_dicts=f_score_arrays_train, class_to_plot='Dementia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_class_scores(score_dicts=f_scores_normal_loss, class_to_plot='all')\n",
    "# plot_class_scores(score_dicts=f_scores_normal_loss,class_to_plot='CN')\n",
    "# plot_class_scores(score_dicts=f_scores_normal_loss,class_to_plot='MCI')\n",
    "# plot_class_scores(score_dicts=f_scores_normal_loss, class_to_plot='Dementia')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
